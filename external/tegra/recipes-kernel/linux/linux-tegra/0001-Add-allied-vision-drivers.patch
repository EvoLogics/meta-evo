From 815dc9d0254ef3f9be781b2bb3dbf015f07e75af Mon Sep 17 00:00:00 2001
From: llewellyn-evo <llewellyn.fernandes@evologics.de>
Date: Tue, 31 Oct 2023 13:32:40 +0100
Subject: [PATCH] Add-allied-vision-drivers

---
 .../media/i2c/alliedvision,avt_csi2.txt       |   11 +
 .../devicetree/bindings/vendor-prefixes.txt   |    1 +
 drivers/i2c/i2c-mux.c                         |    1 +
 drivers/media/i2c/Kconfig                     |    9 +
 drivers/media/i2c/Makefile                    |    1 +
 drivers/media/i2c/adv7180.c                   |   12 +-
 drivers/media/i2c/alvium_helper.h             |  128 +
 drivers/media/i2c/alvium_regs.h               |  515 ++
 drivers/media/i2c/avt_csi2.c                  | 7249 +++++++++++++++++
 drivers/media/i2c/avt_csi2.h                  |  604 ++
 drivers/media/platform/rcar-vin/rcar-v4l2.c   |    2 +-
 drivers/media/v4l2-core/v4l2-dev.c            |   72 +-
 drivers/media/v4l2-core/v4l2-ioctl.c          |   21 +
 drivers/media/v4l2-core/videobuf2-core.c      |  247 +-
 drivers/media/v4l2-core/videobuf2-v4l2.c      |    4 +-
 include/media/avt_csi2_soc.h                  |   45 +
 include/media/v4l2-dev.h                      |    4 +
 include/media/v4l2-subdev.h                   |   10 +-
 include/media/videobuf2-core.h                |   17 +-
 include/media/videobuf2-v4l2.h                |    8 +
 include/uapi/linux/libcsi_ioctl.h             |  349 +
 include/uapi/linux/media-bus-format.h         |    3 +-
 include/uapi/linux/v4l2-subdev.h              |   24 +-
 include/uapi/linux/videodev2.h                |   24 +
 .../platform/tegra/camera/camera_common.c     |   10 +-
 .../media/platform/tegra/camera/csi/csi.c     |    3 +
 .../platform/tegra/camera/csi/csi2_fops.c     |   15 +-
 .../platform/tegra/camera/csi/csi4_fops.c     |   32 +-
 .../platform/tegra/camera/nvcsi/csi5_fops.c   |   24 +
 .../platform/tegra/camera/sensor_common.c     |   24 +-
 .../media/platform/tegra/camera/vi/capture.c  |   22 +-
 .../media/platform/tegra/camera/vi/channel.c  |  686 +-
 .../media/platform/tegra/camera/vi/graph.c    |   16 +
 .../media/platform/tegra/camera/vi/vi2_fops.c |  294 +-
 .../platform/tegra/camera/vi/vi2_formats.h    |   53 +-
 .../media/platform/tegra/camera/vi/vi4_fops.c |  246 +-
 .../platform/tegra/camera/vi/vi4_formats.h    |   63 +-
 .../media/platform/tegra/camera/vi/vi5_fops.c |   32 +-
 .../platform/tegra/camera/vi/vi5_formats.h    |   78 +-
 .../drivers/video/tegra/host/nvhost_syncpt.c  |  121 +-
 .../drivers/video/tegra/host/nvhost_syncpt.h  |    4 +-
 nvidia/include/linux/nvhost.h                 |    3 +
 nvidia/include/media/capture.h                |    1 +
 nvidia/include/media/csi.h                    |    3 +
 nvidia/include/media/mc_common.h              |   32 +-
 nvidia/include/media/tegra_camera_core.h      |    5 +
 nvidia/include/media/vi2_registers.h          |    2 +
 nvidia/include/media/vi4_registers.h          |    1 +
 48 files changed, 10684 insertions(+), 447 deletions(-)
 create mode 100644 Documentation/devicetree/bindings/media/i2c/alliedvision,avt_csi2.txt
 create mode 100644 drivers/media/i2c/alvium_helper.h
 create mode 100755 drivers/media/i2c/alvium_regs.h
 create mode 100644 drivers/media/i2c/avt_csi2.c
 create mode 100644 drivers/media/i2c/avt_csi2.h
 create mode 100644 include/media/avt_csi2_soc.h
 create mode 100644 include/uapi/linux/libcsi_ioctl.h

diff --git a/Documentation/devicetree/bindings/media/i2c/alliedvision,avt_csi2.txt b/Documentation/devicetree/bindings/media/i2c/alliedvision,avt_csi2.txt
new file mode 100644
index 000000000000..1a9d9dbb9c51
--- /dev/null
+++ b/Documentation/devicetree/bindings/media/i2c/alliedvision,avt_csi2.txt
@@ -0,0 +1,11 @@
+* Allied Vision 1 Camera
+
+Allied Vision 1 is a line of cameras based on ALVIUM chip which serves as a
+layer of abstraction between host device and image sensor providing unified
+interface to supported sensors.
+
+Required Properties:
+- compatible: Must be "alliedvision,avt_csi2"
+
+Optional Properties:
+- csi_clk_freq: Desired CSI clock frequency
diff --git a/Documentation/devicetree/bindings/vendor-prefixes.txt b/Documentation/devicetree/bindings/vendor-prefixes.txt
index d0526e05aea3..b449ff20a85b 100644
--- a/Documentation/devicetree/bindings/vendor-prefixes.txt
+++ b/Documentation/devicetree/bindings/vendor-prefixes.txt
@@ -16,6 +16,7 @@ al	Annapurna Labs
 allwinner	Allwinner Technology Co., Ltd.
 alphascale	AlphaScale Integrated Circuits Systems, Inc.
 altr	Altera Corp.
+alliedvision    Allied Vision Inc.
 amazon	Amazon.com, Inc.
 amcc	Applied Micro Circuits Corporation (APM, formally AMCC)
 amd	Advanced Micro Devices (AMD), Inc.
diff --git a/drivers/i2c/i2c-mux.c b/drivers/i2c/i2c-mux.c
index 2178266bca79..3aa70393f12a 100644
--- a/drivers/i2c/i2c-mux.c
+++ b/drivers/i2c/i2c-mux.c
@@ -328,6 +328,7 @@ int i2c_mux_add_adapter(struct i2c_mux_core *muxc,
 	priv->adap.retries = parent->retries;
 	priv->adap.timeout = parent->timeout;
 	priv->adap.quirks = parent->quirks;
+	priv->adap.bus_clk_rate = parent->bus_clk_rate;
 	if (muxc->mux_locked)
 		priv->adap.lock_ops = &i2c_mux_lock_ops;
 	else
diff --git a/drivers/media/i2c/Kconfig b/drivers/media/i2c/Kconfig
index 5a27bffa02fb..4f87360ad11d 100644
--- a/drivers/media/i2c/Kconfig
+++ b/drivers/media/i2c/Kconfig
@@ -38,6 +38,15 @@ config VIDEO_TVAUDIO
 	  To compile this driver as a module, choose M here: the
 	  module will be called tvaudio.
 
+config VIDEO_AVT_CSI2
+	tristate "Allied Vision CSI2 camera support"
+	depends on I2C
+	---help---
+	  This is a Video4Linux2 sensor-level driver for Allied Vision camera.
+
+	  To compile this driver as a module, choose M here: the
+	  module will be called avt_csi2.
+
 config VIDEO_TDA7432
 	tristate "Philips TDA7432 audio processor"
 	depends on VIDEO_V4L2 && I2C
diff --git a/drivers/media/i2c/Makefile b/drivers/media/i2c/Makefile
index bfe0afc209b8..ec28df289c6b 100644
--- a/drivers/media/i2c/Makefile
+++ b/drivers/media/i2c/Makefile
@@ -8,6 +8,7 @@ obj-y				+= soc_camera/
 
 obj-$(CONFIG_VIDEO_APTINA_PLL) += aptina-pll.o
 obj-$(CONFIG_VIDEO_TVAUDIO) += tvaudio.o
+obj-$(CONFIG_VIDEO_AVT_CSI2) += avt_csi2.o
 obj-$(CONFIG_VIDEO_TDA7432) += tda7432.o
 obj-$(CONFIG_VIDEO_SAA6588) += saa6588.o
 obj-$(CONFIG_VIDEO_TDA9840) += tda9840.o
diff --git a/drivers/media/i2c/adv7180.c b/drivers/media/i2c/adv7180.c
index cbed2bc29325..17e4837c5d17 100644
--- a/drivers/media/i2c/adv7180.c
+++ b/drivers/media/i2c/adv7180.c
@@ -763,16 +763,16 @@ static int adv7180_g_mbus_config(struct v4l2_subdev *sd,
 	return 0;
 }
 
-static int adv7180_g_pixelaspect(struct v4l2_subdev *sd, struct v4l2_fract *aspect)
+static int adv7180_cropcap(struct v4l2_subdev *sd, struct v4l2_cropcap *cropcap)
 {
 	struct adv7180_state *state = to_state(sd);
 
 	if (state->curr_norm & V4L2_STD_525_60) {
-		aspect->numerator = 11;
-		aspect->denominator = 10;
+		cropcap->pixelaspect.numerator = 11;
+		cropcap->pixelaspect.denominator = 10;
 	} else {
-		aspect->numerator = 54;
-		aspect->denominator = 59;
+		cropcap->pixelaspect.numerator = 54;
+		cropcap->pixelaspect.denominator = 59;
 	}
 
 	return 0;
@@ -825,7 +825,7 @@ static const struct v4l2_subdev_video_ops adv7180_video_ops = {
 	.g_input_status = adv7180_g_input_status,
 	.s_routing = adv7180_s_routing,
 	.g_mbus_config = adv7180_g_mbus_config,
-	.g_pixelaspect = adv7180_g_pixelaspect,
+	.cropcap = adv7180_cropcap,
 	.g_tvnorms = adv7180_g_tvnorms,
 	.s_stream = adv7180_s_stream,
 };
diff --git a/drivers/media/i2c/alvium_helper.h b/drivers/media/i2c/alvium_helper.h
new file mode 100644
index 000000000000..7e43eb52bbf8
--- /dev/null
+++ b/drivers/media/i2c/alvium_helper.h
@@ -0,0 +1,128 @@
+/*=============================================================================
+  Copyright (C) 2020 Allied Vision Technologies.  All Rights Reserved.
+
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+
+  -----------------------------------------------------------------------------
+
+File:        alvium_helper.h
+
+version:     1.0.0
+=============================================================================*/
+
+////////////////////////////////////////////////////////////////////////////////
+// INCLUDES
+////////////////////////////////////////////////////////////////////////////////
+#include "alvium_regs.h"
+
+////////////////////////////////////////////////////////////////////////////////
+// DEFINES
+////////////////////////////////////////////////////////////////////////////////
+#ifndef ALVIUM_HELPER_H
+#define ALVIUM_HELPER_H
+
+#define AV_CAM_SOFTWARE_TRIGGER 4
+
+////////////////////////////////////////////////////////////////////////////////
+// ENUMS
+////////////////////////////////////////////////////////////////////////////////
+enum CCI_REG_INFO {
+    CCI_REGISTER_LAYOUT_VERSION = 0,
+    RESERVED4BIT,
+    DEVICE_CAPABILITIES,
+    GCPRM_ADDRESS,
+    RESERVED2BIT,
+    BCRM_ADDRESS,
+    RESERVED2BIT_2,
+    DEVICE_GUID,
+    MANUFACTURER_NAME,
+    MODEL_NAME,
+    FAMILY_NAME,
+    DEVICE_VERSION,
+    MANUFACTURER_INFO,
+    SERIAL_NUMBER,
+    USER_DEFINED_NAME,
+    CHECKSUM,
+    CHANGE_MODE,
+    CURRENT_MODE,
+    SOFT_RESET,
+    HEARTBEAT,
+    MAX_CMD = HEARTBEAT
+};
+
+////////////////////////////////////////////////////////////////////////////////
+// STRUCTS
+////////////////////////////////////////////////////////////////////////////////
+struct cci_cmd {
+    __u8 command_index; /* diagnostc test name */
+    const __u32 address; /* NULL for no alias name */
+    __u32 byte_count;
+};
+
+static struct cci_cmd cci_cmd_tbl[MAX_CMD] = {
+    /* command index        address */
+    { CCI_REGISTER_LAYOUT_VERSION,  CCI_REG_LAYOUT_VER_32R, 4 },
+    { DEVICE_CAPABILITIES,          CCI_DEVICE_CAP_64R, 8 },
+    { GCPRM_ADDRESS,                CCI_GCPRM_16R, 2 },
+    { BCRM_ADDRESS,                 CCI_BCRM_16R, 2 },
+    { DEVICE_GUID,                  CCI_DEVICE_GUID_512R, 64 },
+    { MANUFACTURER_NAME,            CCI_MANUF_NAME_512R, 64 },
+    { MODEL_NAME,                   CCI_MODEL_NAME_512R, 64 },
+    { FAMILY_NAME,                  CCI_FAMILY_NAME_512R, 64 },
+    { DEVICE_VERSION,               CCI_DEVICE_VERSION_512R, 64 },
+    { MANUFACTURER_INFO,            CCI_MANUF_INFO_512R, 64 },
+    { SERIAL_NUMBER,                CCI_SERIAL_NUM_512R, 64 },
+    { USER_DEFINED_NAME,            CCI_USER_DEF_NAME_512R, 64 },
+    { CHECKSUM,                     CCI_CHECKSUM_32R, 4 },
+    { CHANGE_MODE,                  CCI_CHANGE_MODE_8W, 1 },
+    { CURRENT_MODE,                 CCI_CURRENT_MODE_8R, 1 },
+    { SOFT_RESET,                   CCI_SOFT_RESET_8W, 1 },
+    { HEARTBEAT,                    CCI_HEARTBEAT_8RW, 1 },
+};
+
+struct __attribute__((__packed__)) cci_reg {
+    __u32   layout_version;
+    __u32   reserved_4bit;
+    __u64   device_capabilities;
+    __u16   gcprm_address;
+    __u16   reserved_2bit;
+    __u16   bcrm_addr;
+    __u16   reserved_2bit_2;
+    char    device_guid[64];
+    char    manufacturer_name[64];
+    char    model_name[64];
+    char    family_name[64];
+    char    device_version[64];
+    char    manufacturer_info[64];
+    char    serial_number[64];
+    char    user_defined_name[64];
+    __u32   checksum;
+    __u8    change_mode;
+    __u8    current_mode;
+    __u8    soft_reset;
+    __u8    heartbeat;
+};
+
+struct __attribute__((__packed__)) gencp_reg {
+    __u32   gcprm_layout_version;
+    __u16   gencp_out_buffer_address;
+    __u16   reserved_2byte;
+    __u16   gencp_out_buffer_size;
+    __u16   reserved_2byte_1;
+    __u16   gencp_in_buffer_address;
+    __u16   reserved_2byte_2;
+    __u16   gencp_in_buffer_size;
+    __u16   reserved_2byte_3;
+    __u32   checksum;
+};
+
+
+#endif /* ALVIUM_HELPER_H */
diff --git a/drivers/media/i2c/alvium_regs.h b/drivers/media/i2c/alvium_regs.h
new file mode 100755
index 000000000000..5aecf2b49bdc
--- /dev/null
+++ b/drivers/media/i2c/alvium_regs.h
@@ -0,0 +1,515 @@
+/*=============================================================================
+  Copyright (C) 2022 Allied Vision Technologies.  All Rights Reserved.
+
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+
+  -----------------------------------------------------------------------------
+
+File:        alvium_regs.h
+
+version:     1.8.0
+=============================================================================*/
+
+////////////////////////////////////////////////////////////////////////////////
+// DEFINES
+////////////////////////////////////////////////////////////////////////////////
+#ifndef ALVIUM_REGS_H
+#define ALVIUM_REGS_H
+
+// Version of the GenCP over CSI spec
+#define GENCP_OVER_CCI_SPEC_VERSION_MAJOR           1
+#define GENCP_OVER_CCI_SPEC_VERSION_MINOR           1
+#define GENCP_OVER_CCI_SPEC_VERSION_PATCH           31
+
+// Version of the BCRM spec
+#define BCRM_SPEC_VERSION_MAJOR                     1
+#define BCRM_SPEC_VERSION_MINOR                     1
+#define BCRM_SPEC_VERSION_PATCH                     16
+
+// CCI registers
+#define CCI_REG_LAYOUT_VER_32R                      0x0000
+#define CCI_DEVICE_CAP_64R                          0x0008
+#define CCI_GCPRM_16R                               0x0010
+#define CCI_BCRM_16R                                0x0014
+#define CCI_DEVICE_GUID_512R                        0x0018
+#define CCI_MANUF_NAME_512R                         0x0058
+#define CCI_MODEL_NAME_512R                         0x0098
+#define CCI_FAMILY_NAME_512R                        0x00D8
+#define CCI_DEVICE_VERSION_512R                     0x0118
+#define CCI_MANUF_INFO_512R                         0x0158
+#define CCI_SERIAL_NUM_512R                         0x0198
+#define CCI_USER_DEF_NAME_512R                      0x01D8
+#define CCI_CHECKSUM_32R                            0x0218
+#define CCI_CHANGE_MODE_8W                          0x021C
+#define CCI_CURRENT_MODE_8R                         0x021D
+#define CCI_SOFT_RESET_8W                           0x021E
+#define CCI_HEARTBEAT_8RW                           0x021F
+#define CCI_CAMERA_I2C_ADDRESS_8RW                  0x0220
+
+// GCPRM register offsets
+#define GCPRM_LAYOUT_VERSION_32R                    0x0000
+#define GCPRM_GENCP_OUTBUF_ADDR_16R                 0x0004
+#define GCPRM_GENCP_OUTBUF_SIZE_16R                 0x0008
+#define GCPRM_GENCP_INBUF_ADDR_16R                  0x000C
+#define GCPRM_GENCP_INBUF_SIZE_16R                  0x0010
+#define GCPRM_GENCP_CHECKSUM_32R                    0x0014
+#define GCPRM_GENCP_OUTHANDSHAKE_8RW                0x0018
+#define GCPRM_GENCP_INHANDSHAKE_8RW                 0x001C
+#define GCPRM_GENCP_OUT_SIZE_W16                    0x0020
+#define GCPRM_GENCP_IN_SIZE_R16                     0x0024
+
+// SBRM register offsets
+#define SBRM_VERSION_32R                            0x0000
+#define SBRM_GENCP_CCI_DEV_CAP_64R                  0x0004
+#define SBRM_NUM_OF_STREAM_CHAN_32R                 0x000C
+#define SBRM_SUPP_CSI2_LANE_COUNTS_8R               0x0010
+#define SBRM_CSI2_LANE_COUNT_8RW                    0x0014
+#define SBRM_MIN_SUPP_CSI2_CLK_FREQ_32R             0x0018
+#define SBRM_MAX_SUPP_CSI2_CLK_FREQ_32R             0x001C
+#define SBRM_CSI2_CLK_FREQ_32RW                     0x0020
+#define SBRM_SIRM_ADDR_64R                          0x0024
+#define SBRM_SIRM_LENGTH_32R                        0x002C
+
+// SIRM register offsets
+#define SIRM_STREAM_ENABLE_8RW                      0x0000
+#define SIRM_LEADER_SIZE_32R                        0x0004
+#define SIRM_PAYLOAD_SIZE_64R                       0x0008
+#define SIRM_TRAILER_SIZE_32R                       0x0010
+#define SIRM_CSI2_DATA_ID_INQ1_64R                  0x0014
+#define SIRM_CSI2_DATA_ID_INQ2_64R                  0x001C
+#define SIRM_CSI2_DATA_ID_INQ3_64R                  0x0024
+#define SIRM_CSI2_DATA_ID_INQ4_64R                  0x002C
+#define SIRM_CSI2_DATA_ID_8RW                       0x0034
+#define SIRM_IPU_X_MIN_32W                          0x0038
+#define SIRM_IPU_X_MAX_32W                          0x003C
+#define SIRM_IPU_X_INC_32W                          0x0040
+#define SIRM_IPU_Y_MIN_32W                          0x0044
+#define SIRM_IPU_Y_MAX_32W                          0x0048
+#define SIRM_IPU_Y_INC_32W                          0x004C
+#define SIRM_IPU_X_32R                              0x0050
+#define SIRM_IPU_Y_32R                              0x0054
+#define SIRM_GENCP_IMAGE_SIZE_X_32R                 0x0058
+#define SIRM_GENCP_IMAGE_SIZE_Y_32R                 0x005C
+#define SIRM_GENCP_IMAGE_OFFSET_X_32R               0x0060
+#define SIRM_GENCP_IMAGE_OFFSET_Y_32R               0x0064
+#define SIRM_GENCP_IMAGE_PADDING_X_16R              0x0068
+#define SIRM_GENCP_IMAGE_PIXEL_FORMAT_32R           0x006C
+#define SIRM_GENCP_IMAGE_PAYLOAD_TYPE_16R           0x0070
+#define SIRM_GENCP_VALID_PAYLOAD_SIZE_64R           0x0074
+#define SIRM_GENCP_CHUNK_LAYOUT_ID_32R              0x007C
+
+// BCRM register offsets
+#define BCRM_VERSION_32R                            0x0000
+#define BCRM_FEATURE_INQUIRY_64R                    0x0008
+#define BCRM_DEVICE_FIRMWARE_VERSION_64R            0x0010
+#define BCRM_WRITE_HANDSHAKE_8RW                    0x0018
+#define BCRM_SUPPORTED_CSI2_LANE_COUNTS_8R          0x0040
+#define BCRM_CSI2_LANE_COUNT_8RW                    0x0044
+#define BCRM_CSI2_CLOCK_MIN_32R                     0x0048
+#define BCRM_CSI2_CLOCK_MAX_32R                     0x004C
+#define BCRM_CSI2_CLOCK_32RW                        0x0050
+#define BCRM_BUFFER_SIZE_32R                        0x0054
+#define BCRM_IPU_X_MIN_32W                          0x0058
+#define BCRM_IPU_X_MAX_32W                          0x005C
+#define BCRM_IPU_X_INC_32W                          0x0060
+#define BCRM_IPU_Y_MIN_32W                          0x0064
+#define BCRM_IPU_Y_MAX_32W                          0x0068
+#define BCRM_IPU_Y_INC_32W                          0x006C
+#define BCRM_IPU_X_32R                              0x0070
+#define BCRM_IPU_Y_32R                              0x0074
+#define BCRM_PHY_RESET_8RW                          0x0078
+#define BCRM_ACQUISITION_START_8RW                  0x0080
+#define BCRM_ACQUISITION_STOP_8RW                   0x0084
+#define BCRM_ACQUISITION_ABORT_8RW                  0x0088
+#define BCRM_ACQUISITION_STATUS_8R                  0x008C
+#define BCRM_ACQUISITION_FRAME_RATE_64RW            0x0090
+#define BCRM_ACQUISITION_FRAME_RATE_MIN_64R         0x0098
+#define BCRM_ACQUISITION_FRAME_RATE_MAX_64R         0x00A0
+#define BCRM_ACQUISITION_FRAME_RATE_INC_64R         0x00A8
+#define BCRM_ACQUISITION_FRAME_RATE_ENABLE_8RW      0x00B0
+#define BCRM_FRAME_START_TRIGGER_MODE_8RW           0x00B4
+#define BCRM_FRAME_START_TRIGGER_SOURCE_8RW         0x00B8
+#define BCRM_FRAME_START_TRIGGER_ACTIVATION_8RW     0x00BC
+#define BCRM_FRAME_START_TRIGGER_SOFTWARE_8W        0x00C0
+#define BCRM_FRAME_START_TRIGGER_DELAY_32RW         0x00C4
+#define BCRM_EXPOSURE_ACTIVE_LINE_MODE_8RW          0x00C8
+#define BCRM_EXPOSURE_ACTIVE_OUTPUT_LINE_8RW        0x00CC
+#define BCRM_LINE_CONFIGURATION_32RW                0x00D0
+#define BCRM_LINE_STATUS_8R                         0x00D4
+#define BCRM_IMG_WIDTH_32RW                         0x0100
+#define BCRM_IMG_WIDTH_MIN_32R                      0x0104
+#define BCRM_IMG_WIDTH_MAX_32R                      0x0108
+#define BCRM_IMG_WIDTH_INC_32R                      0x010C
+#define BCRM_IMG_HEIGHT_32RW                        0x0110
+#define BCRM_IMG_HEIGHT_MIN_32R                     0x0114
+#define BCRM_IMG_HEIGHT_MAX_32R                     0x0118
+#define BCRM_IMG_HEIGHT_INC_32R                     0x011C
+#define BCRM_IMG_OFFSET_X_32RW                      0x0120
+#define BCRM_IMG_OFFSET_X_MIN_32R                   0x0124
+#define BCRM_IMG_OFFSET_X_MAX_32R                   0x0128
+#define BCRM_IMG_OFFSET_X_INC_32R                   0x012C
+#define BCRM_IMG_OFFSET_Y_32RW                      0x0130
+#define BCRM_IMG_OFFSET_Y_MIN_32R                   0x0134
+#define BCRM_IMG_OFFSET_Y_MAX_32R                   0x0138
+#define BCRM_IMG_OFFSET_Y_INC_32R                   0x013C
+#define BCRM_IMG_MIPI_DATA_FORMAT_32RW              0x0140
+#define BCRM_IMG_AVAILABLE_MIPI_DATA_FORMATS_64R    0x0148
+#define BCRM_IMG_BAYER_PATTERN_INQUIRY_8R           0x0150
+#define BCRM_IMG_BAYER_PATTERN_8RW                  0x0154
+#define BCRM_IMG_REVERSE_X_8RW                      0x0158
+#define BCRM_IMG_REVERSE_Y_8RW                      0x015C
+#define BCRM_SENSOR_WIDTH_32R                       0x0160
+#define BCRM_SENSOR_HEIGHT_32R                      0x0164
+#define BCRM_WIDTH_MAX_32R                          0x0168
+#define BCRM_HEIGHT_MAX_32R                         0x016C
+#define BCRM_DIGITAL_BINNIG_INQ_16R                 0x0170
+#define BCRM_DIGITAL_BINNIG_SETTING_8RW             0x0174
+#define BCRM_DIGITAL_BINNIG_MODE_8RW                0x0178
+#define BCRM_EXPOSURE_TIME_64RW                     0x0180
+#define BCRM_EXPOSURE_TIME_MIN_64R                  0x0188
+#define BCRM_EXPOSURE_TIME_MAX_64R                  0x0190
+#define BCRM_EXPOSURE_TIME_INC_64R                  0x0198
+#define BCRM_EXPOSURE_AUTO_8RW                      0x01A0
+#define BCRM_INTENSITY_AUTO_PRECEDENCE_8RW          0x01A4
+#define BCRM_INTENSITY_AUTO_PRECEDENCE_VALUE_32RW   0x01A8
+#define BCRM_INTENSITY_AUTO_PRECEDENCE_MIN_32R      0x01AC
+#define BCRM_INTENSITY_AUTO_PRECEDENCE_MAX_32R      0x01B0
+#define BCRM_INTENSITY_AUTO_PRECEDENCE_INC_32R      0x01B4
+#define BCRM_BLACK_LEVEL_32RW                       0x01B8
+#define BCRM_BLACK_LEVEL_MIN_32R                    0x01BC
+#define BCRM_BLACK_LEVEL_MAX_32R                    0x01C0
+#define BCRM_BLACK_LEVEL_INC_32R                    0x01C4
+#define BCRM_GAIN_64RW                              0x01C8
+#define BCRM_GAIN_MIN_64R                           0x01D0
+#define BCRM_GAIN_MAX_64R                           0x01D8
+#define BCRM_GAIN_INC_64R                           0x01E0
+#define BCRM_GAIN_AUTO_8RW                          0x01E8
+#define BCRM_GAMMA_64RW                             0x01F0
+#define BCRM_GAMMA_MIN_64R                          0x01F8
+#define BCRM_GAMMA_MAX_64R                          0x0200
+#define BCRM_GAMMA_INC_64R                          0x0208
+#define BCRM_CONTRAST_VALUE_32RW                    0x0214
+#define BCRM_CONTRAST_VALUE_MIN_32R                 0x0218
+#define BCRM_CONTRAST_VALUE_MAX_32R                 0x021C
+#define BCRM_CONTRAST_VALUE_INC_32R                 0x0220
+#define BCRM_SATURATION_32RW                        0x0240
+#define BCRM_SATURATION_MIN_32R                     0x0244
+#define BCRM_SATURATION_MAX_32R                     0x0248
+#define BCRM_SATURATION_INC_32R                     0x024C
+#define BCRM_HUE_32RW                               0x0250
+#define BCRM_HUE_MIN_32R                            0x0254
+#define BCRM_HUE_MAX_32R                            0x0258
+#define BCRM_HUE_INC_32R                            0x025C
+#define BCRM_RED_BALANCE_RATIO_64RW                 0x0280
+#define BCRM_RED_BALANCE_RATIO_MIN_64R              0x0288
+#define BCRM_RED_BALANCE_RATIO_MAX_64R              0x0290
+#define BCRM_RED_BALANCE_RATIO_INC_64R              0x0298
+#define BCRM_GREEN_BALANCE_RATIO_64RW               0x02A0
+#define BCRM_GREEN_BALANCE_RATIO_MIN_64R            0x02A8
+#define BCRM_GREEN_BALANCE_RATIO_MAX_64R            0x02B0
+#define BCRM_GREEN_BALANCE_RATIO_INC_64R            0x02B8
+#define BCRM_BLUE_BALANCE_RATIO_64RW                0x02C0
+#define BCRM_BLUE_BALANCE_RATIO_MIN_64R             0x02C8
+#define BCRM_BLUE_BALANCE_RATIO_MAX_64R             0x02D0
+#define BCRM_BLUE_BALANCE_RATIO_INC_64R             0x02D8
+#define BCRM_WHITE_BALANCE_AUTO_8RW                 0x02E0
+#define BCRM_SHARPNESS_32RW                         0x0300
+#define BCRM_SHARPNESS_MIN_32R                      0x0304
+#define BCRM_SHARPNESS_MAX_32R                      0x0308
+#define BCRM_SHARPNESS_INC_32R                      0x030C
+#define BCRM_DEVICE_TEMPERATURE_32R                 0x0310
+#define BCRM_EXPOSURE_AUTO_MIN_64RW                 0x0330
+#define BCRM_EXPOSURE_AUTO_MAX_64RW                 0x0338
+#define BCRM_GAIN_AUTO_MIN_64RW                     0x0340
+#define BCRM_GAIN_AUTO_MAX_64RW                     0x0348
+#define BCRM_AUTO_REGION_WIDTH_32RW                 0x0350
+#define BCRM_AUTO_REGION_WIDTH_MIN_32R              0x0354
+#define BCRM_AUTO_REGION_WIDTH_MAX_32R              0x0358
+#define BCRM_AUTO_REGION_WIDTH_INC_32R              0x035C
+#define BCRM_AUTO_REGION_HEIGHT_32RW                0x0360
+#define BCRM_AUTO_REGION_HEIGHT_MIN_32R             0x0364
+#define BCRM_AUTO_REGION_HEIGHT_MAX_32R             0x0368
+#define BCRM_AUTO_REGION_HEIGHT_INC_32R             0x036C
+#define BCRM_AUTO_REGION_OFFSET_X_32RW              0x0370
+#define BCRM_AUTO_REGION_OFFSET_X_MIN_32R           0x0374
+#define BCRM_AUTO_REGION_OFFSET_X_MAX_32R           0x0378
+#define BCRM_AUTO_REGION_OFFSET_X_INC_32R           0x037C
+#define BCRM_AUTO_REGION_OFFSET_Y_32RW              0x0380
+#define BCRM_AUTO_REGION_OFFSET_Y_MIN_32R           0x0384
+#define BCRM_AUTO_REGION_OFFSET_Y_MAX_32R           0x0388
+#define BCRM_AUTO_REGION_OFFSET_Y_INC_32R           0x038C
+#define _BCRM_LAST_ADDR                             BCRM_AUTO_REGION_OFFSET_Y_INC_32R
+
+#define AV_CAM_REG_SIZE                 2
+#define AV_CAM_DATA_SIZE_8              1
+#define AV_CAM_DATA_SIZE_16             2
+#define AV_CAM_DATA_SIZE_32             4
+#define AV_CAM_DATA_SIZE_64             8
+
+
+////////////////////////////////////////////////////////////////////////////////
+// ENUMS
+////////////////////////////////////////////////////////////////////////////////
+
+/* BCRM_IMG_MIPI_DATA_FORMAT_32RW register values */
+enum MIPI_DATA_FORMAT {
+    MIPI_DATA_FORMAT_YUV_420_8_LEG      = 0x1A,
+    MIPI_DATA_FORMAT_YUV_420_8          = 0x18,
+    MIPI_DATA_FORMAT_YUV_420_10         = 0x19,
+    MIPI_DATA_FORMAT_YUV_420_8_CSPS     = 0x1C,
+    MIPI_DATA_FORMAT_YUV_420_10_CSPS    = 0x1D,
+    MIPI_DATA_FORMAT_YUV_422_8          = 0x1E,
+    MIPI_DATA_FORMAT_YUV_422_10         = 0x1F,
+    MIPI_DATA_FORMAT_RGB888             = 0x24,
+    MIPI_DATA_FORMAT_RGB666             = 0x23,
+    MIPI_DATA_FORMAT_RGB565             = 0x22,
+    MIPI_DATA_FORMAT_RGB555             = 0x21,
+    MIPI_DATA_FORMAT_RGB444             = 0x20,
+    MIPI_DATA_FORMAT_RAW6               = 0x28,
+    MIPI_DATA_FORMAT_RAW7               = 0x29,
+    MIPI_DATA_FORMAT_RAW8               = 0x2A,
+    MIPI_DATA_FORMAT_RAW10              = 0x2B,
+    MIPI_DATA_FORMAT_RAW12              = 0x2C,
+    MIPI_DATA_FORMAT_RAW14              = 0x2D,
+    MIPI_DATA_FORMAT_JPEG               = 0x30
+};
+
+/* BCRM_IMG_BAYER_PATTERN_8RW register values */
+enum BAYER_PATTERN {
+    BAYER_PATTERN_MONO          = 0,
+    BAYER_PATTERN_GR            = 1,
+    BAYER_PATTERN_RG            = 2,
+    BAYER_PATTERN_GB            = 3,
+    BAYER_PATTERN_BG            = 4
+};
+
+/* BCRM_IMG_REVERSE_X_8RW */
+enum REVERSE_X {
+    REVERSE_X_OFF               = 0,
+    REVERSE_X_FLIP_H            = 1,
+};
+
+/* BCRM_IMG_REVERSE_X_8RW */
+enum REVERSE_Y {
+    REVERSE_Y_OFF               = 0,
+    REVERSE_Y_FLIP_V            = 1,
+};
+
+/* BCRM_IMG_BAYER_PATTERN_8RW register values */
+enum EXPOSURE_AUTO {
+    EXPOSURE_AUTO_OFF           = 0,
+    EXPOSURE_AUTO_ONCE          = 1,
+    EXPOSURE_AUTO_CONTINUOUS    = 2
+};
+
+/* BCRM_GAIN_AUTO_8RW register values */
+enum GAIN_AUTO {
+    GAIN_AUTO_OFF               = 0,
+    GAIN_AUTO_ONCE              = 1,
+    GAIN_AUTO_CONTINUOUS        = 2
+};
+
+/* BCRM_WHITE_BALANCE_AUTO_8RW register values */
+enum WHITEBALANCE_AUTO {
+    WHITEBALANCE_AUTO_OFF           = 0,
+    WHITEBALANCE_AUTO_ONCE          = 1,
+    WHITEBALANCE_AUTO_CONTINUOUS    = 2
+};
+
+/* CCI_CHANGE_MODE_8W & CCI_CURRENT_MODE_8R */
+enum OPERATION_MODE {
+    OPERATION_MODE_BCRM     = 0,
+    OPERATION_MODE_GENCP    = 1
+};
+
+/* BCRM_ACQUISITION_STATUS_8R register values */
+enum ACQUISITION_STATUS {
+    ACQUISITION_STATUS_STOPPED = 0,
+    ACQUISITION_STATUS_RUNNING = 1
+};
+
+/* CCI Device capability String encoding */
+enum CCI_STRING_ENC {
+    CCI_STRING_ENC_ASCII    = 0,
+    CCI_STRING_ENC_UTF8     = 1,
+    CCI_STRING_ENC_UTF16    = 2
+};
+
+/* BCRM digital binning setting */
+enum BCRM_DIGITAL_BINNING_SETTING {
+    DIGITAL_BINNING_OFF = 0,
+    DIGITAL_BINNING_2X2 = 1,
+    DIGITAL_BINNING_3X3 = 2,
+    DIGITAL_BINNING_4X4 = 3,
+    DIGITAL_BINNING_5X5 = 4,
+    DIGITAL_BINNING_6X6 = 5,
+    DIGITAL_BINNING_7X7 = 6,
+    DIGITAL_BINNING_8X8 = 7
+};
+
+/* BCRM digital binning mode */
+enum BCRM_DIGITAL_BINNING_MODE {
+    DIGITAL_BINNING_MODE_AVG = 0,
+    DIGITAL_BINNING_MODE_SUM = 1
+};
+
+
+////////////////////////////////////////////////////////////////////////////////
+// UNIONS
+////////////////////////////////////////////////////////////////////////////////
+/* CCI_DEVICE_CAP_64R regsiter values */
+union cci_device_caps_reg {
+	struct {
+        unsigned long long user_name:1;
+        unsigned long long bcrm:1;
+        unsigned long long gencp:1;
+        unsigned long long reserved:1;
+        unsigned long long string_encoding:4;
+        unsigned long long family_name:1;
+        unsigned long long reserved2:55;
+	} caps;
+
+	unsigned long long value;
+};
+
+/* BCRM_VERSION_32R register values */
+union bcrm_version_reg {
+	struct {
+        unsigned long minor:16;
+        unsigned long major:16;
+	} handshake;
+
+	unsigned long value;
+};
+
+/* BCRM_DEVICE_FIRMWARE_VERSION_64R register values */
+union bcrm_device_firmware_version_reg {
+	struct {
+        unsigned long long special:8;
+        unsigned long long major:8;
+        unsigned long long minor:16;
+        unsigned long long patch:32;
+	} handshake;
+
+	unsigned long long value;
+};
+
+/* BCRM_WRITE_HANDSHAKE_8RW register values */
+union bcrm_write_done_handshake_reg {
+	struct {
+        unsigned char finished:1;
+        unsigned char reserved:6;
+        unsigned char handshake_supported:1;
+	} handshake;
+
+	unsigned char value;
+};
+
+/* BCRM_FEATURE_INQUIRY_64R register values */
+union bcrm_feature_reg {
+	struct {
+        unsigned long long reverse_x_avail:1;
+        unsigned long long reverse_y_avail:1;
+        unsigned long long intensity_auto_prcedence_avail:1;
+        unsigned long long black_level_avail:1;
+        unsigned long long gain_avail:1;
+        unsigned long long gamma_avail:1;
+        unsigned long long contrast_avail:1;
+        unsigned long long saturation_avail:1;
+        unsigned long long hue_avail:1;
+        unsigned long long white_balance_avail:1;
+        unsigned long long sharpness_avail:1;
+        unsigned long long exposure_auto:1;
+        unsigned long long gain_auto:1;
+        unsigned long long white_balance_auto_avail:1;
+        unsigned long long device_temperature_avail:1;
+        unsigned long long acquisition_abort:1;
+        unsigned long long acquisition_frame_rate:1;
+        unsigned long long frame_trigger:1;
+        unsigned long long exposure_active_line_avail:1;
+        unsigned long long reserved:45;
+	} feature_inq;
+
+	unsigned long long value;
+};
+
+/* BCRM_SUPPORTED_CSI2_LANE_COUNTS_8R register values */
+union bcrm_supported_lanecount_reg {
+	struct {
+        unsigned char one_lane_avail:1;
+        unsigned char two_lane_avail:1;
+        unsigned char three_lane_avail:1;
+        unsigned char four_lane_avail:1;
+        unsigned char reserved:4;
+	} lane_count;
+
+	unsigned char value;
+};
+
+/* BCRM_IMG_AVAILABLE_MIPI_DATA_FORMATS_64R register values */
+union bcrm_avail_mipi_reg {
+	struct {
+        unsigned long long yuv420_8_leg_avail:1;
+        unsigned long long yuv420_8_avail:1;
+        unsigned long long yuv420_10_avail:1;
+        unsigned long long yuv420_8_csps_avail:1;
+        unsigned long long yuv420_10_csps_avail:1;
+        unsigned long long yuv422_8_avail:1;
+        unsigned long long yuv422_10_avail:1;
+        unsigned long long rgb888_avail:1;
+        unsigned long long rgb666_avail:1;
+        unsigned long long rgb565_avail:1;
+        unsigned long long rgb555_avail:1;
+        unsigned long long rgb444_avail:1;
+        unsigned long long raw6_avail:1;
+        unsigned long long raw7_avail:1;
+        unsigned long long raw8_avail:1;
+        unsigned long long raw10_avail:1;
+        unsigned long long raw12_avail:1;
+        unsigned long long raw14_avail:1;
+        unsigned long long jpeg_avail:1;
+        unsigned long long reserved:45;
+	} avail_mipi;
+
+	unsigned long long value;
+};
+
+/* BCRM_IMG_BAYER_PATTERN_INQUIRY_8R register values */
+union bcrm_bayer_inquiry_reg {
+	struct {
+        unsigned char monochrome_avail:1;
+        unsigned char bayer_GR_avail:1;
+        unsigned char bayer_RG_avail:1;
+        unsigned char bayer_GB_avail:1;
+        unsigned char bayer_BG_avail:1;
+        unsigned char reserved:3;
+	} bayer_pattern;
+
+	unsigned char value;
+};
+
+
+union bcrm_digital_binning_inquiry_reg {
+	struct {
+        unsigned short int digital_binning_2x2:1;
+        unsigned short int digital_binning_3x3:1;
+        unsigned short int digital_binning_4x4:1;
+        unsigned short int digital_binning_5x5:1;
+        unsigned short int digital_binning_6x6:1;
+        unsigned short int digital_binning_7x7:1;
+        unsigned short int digital_binning_8x8:1;
+        unsigned short int reserved:9;
+	} digital_binning_inquiry;
+
+	unsigned short int value;
+};
+
+#endif /* ALVIUM_REGS_H */
diff --git a/drivers/media/i2c/avt_csi2.c b/drivers/media/i2c/avt_csi2.c
new file mode 100644
index 000000000000..5c3a0deaec95
--- /dev/null
+++ b/drivers/media/i2c/avt_csi2.c
@@ -0,0 +1,7249 @@
+/*
+ * Allied Vision CSI2 Camera
+ *
+ * This program is free software; you may redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ *
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/slab.h>
+#include <linux/i2c.h>
+#include <linux/lcm.h>
+#include <linux/crc32.h>
+#include <media/v4l2-device.h>
+#include <media/v4l2-event.h>
+#include <media/v4l2-of.h>
+#include <media/tegra-v4l2-camera.h>
+#include <media/camera_common.h>
+#include <media/mc_common.h>
+
+#include "avt_csi2.h"
+#include <uapi/linux/libcsi_ioctl.h>
+#include <media/avt_csi2_soc.h>
+
+static int debug;
+MODULE_PARM_DESC(debug, "debug");
+module_param(debug, int, 0600);/* S_IRUGO */
+
+/* For overriding alignment value. 0=Use internal value.*/
+static int v4l2_width_align = 0;
+MODULE_PARM_DESC(v4l2_width_align, "v4l2_width_align");
+module_param(v4l2_width_align, int, 0600);/* S_IRUGO */
+
+
+static int add_wait_time_ms = 2000;
+module_param(add_wait_time_ms, int, 0600);
+
+static const char * const v4l2_triggeractivation_menu[] = {
+        "Rising Edge",
+        "Falling Edge",
+        "Any Edge",
+        "Level High",
+		"Level Low"
+};
+static const char * const v4l2_triggersource_menu[] = {
+        "Line 0",
+        "Line 1",
+        "Line 2",
+        "Line 3",
+		"Software"
+};
+
+#define AVT_DBG_LVL 3
+
+#define avt_dbg(dev, fmt, args...) \
+		v4l2_dbg(AVT_DBG_LVL, debug, dev, "%s:%d: " fmt "", \
+				__func__, __LINE__, ##args) \
+
+#define avt_err(dev, fmt, args...) \
+		v4l2_err(dev, "%s:%d: " fmt "", __func__, __LINE__, ##args) \
+
+#define avt_warn(dev, fmt, args...) \
+		v4l2_warn(dev, "%s:%d: " fmt "", __func__, __LINE__, ##args) \
+
+#define avt_info(dev, fmt, args...) \
+		v4l2_info(dev, "%s:%d: " fmt "", __func__, __LINE__, ##args) \
+
+#define DEFAULT_FPS 30
+
+#define AV_CAM_DEFAULT_FMT	MEDIA_BUS_FMT_VYUY8_2X8
+
+#define IO_LIMIT	1024
+#define BCRM_WAIT_HANDSHAKE_TIMEOUT	3000
+
+static int avt_set_selection(struct v4l2_subdev *sd,
+		struct v4l2_subdev_pad_config *cfg,
+		struct v4l2_subdev_selection *sel);
+
+static int avt_reg_read(struct i2c_client *client, __u32 reg,
+		__u32 reg_size, __u32 count, char *buffer);
+
+static int avt_init_mode(struct v4l2_subdev *sd);
+
+static int avt_init_frame_param(struct v4l2_subdev *sd);
+
+static int avt_s_parm(struct v4l2_subdev *sd, struct v4l2_streamparm *parm);
+static int avt_align_width(struct v4l2_subdev *sd, int width);
+static int avt_get_align_width(struct v4l2_subdev *sd);
+static bool common_range(uint32_t nMin1, uint32_t nMax1, uint32_t nInc1,
+				uint32_t nMin2, uint32_t nMax2, uint32_t nInc2,
+				uint32_t *rMin, uint32_t *rMax, uint32_t *rInc);
+
+static void bcrm_dump(struct i2c_client *client);
+static void dump_bcrm_reg_8(struct i2c_client *client, u16 nOffset, const char *pRegName);
+static void dump_bcrm_reg_32(struct i2c_client *client, u16 nOffset, const char *pRegName);
+static void dump_bcrm_reg_64(struct i2c_client *client, u16 nOffset, const char *pRegName);
+static int soft_reset(struct i2c_client *client);
+static void dump_frame_param(struct v4l2_subdev *sd);
+static void dump_camera_firmware_version(struct i2c_client *client);
+static bool is_fallback_app_running(struct i2c_client *client);
+static int ioctl_queryctrl64(struct v4l2_subdev *sd, struct v4l2_query_ext_ctrl *qctrl);
+
+static void swapbytes(void *_object, size_t _size)
+{
+	switch (_size) {
+	case 2:
+		cpu_to_be16s((uint16_t *)_object);
+		break;
+	case 4:
+		cpu_to_be32s((uint32_t *)_object);
+		break;
+	case 8:
+		cpu_to_be64s((uint64_t *)_object);
+		break;
+	}
+}
+
+static uint32_t i2c_read(struct i2c_client *client, uint32_t reg, uint32_t size, uint32_t count, char *buf)
+{
+	struct i2c_msg msg[2];
+	u8 msgbuf[size];
+	int ret = 0, i = 0, j = 0, reg_size_bkp;
+
+	reg_size_bkp = size;
+
+	/* clearing i2c msg with 0's */
+	memset(msg, 0, sizeof(msg));
+
+	if (count > IO_LIMIT) {
+		dev_err(&client->dev, "Limit excedded! i2c_reg->count > IO_LIMIT\n");
+		count = IO_LIMIT;
+	}
+
+	/* find start address of buffer */
+	for (i = --size; i >= 0; i--, j++)
+		msgbuf[i] = ((reg >> (8*j)) & 0xFF);
+
+	msg[0].addr = client->addr;
+	msg[0].flags = 0;
+	msg[0].len = reg_size_bkp;
+	msg[0].buf = msgbuf;
+	msg[1].addr = client->addr; /* slave address */
+	msg[1].flags = I2C_M_RD; /* read flag setting */
+	msg[1].len = count;
+	msg[1].buf = buf; /* dest buffer */
+
+	ret = i2c_transfer(client->adapter, msg, 2);
+
+	return ret;
+}
+
+static int i2c_write(struct i2c_client *client, uint32_t reg, uint32_t reg_size, uint32_t buf_size, char *buf)
+{
+	int j = 0, i = 0;
+	char *i2c_w_buf;
+	int ret = 0;
+
+	/* count exceeds writing IO_LIMIT characters */
+	if (buf_size > IO_LIMIT) {
+		dev_err(&client->dev, "limit excedded! i2c_reg->count > IO_LIMIT\n");
+		buf_size = IO_LIMIT;
+	}
+
+	i2c_w_buf = kzalloc(buf_size + reg_size, GFP_KERNEL);
+	if (!i2c_w_buf)
+		return -ENOMEM;
+
+	/* Fill the address in buffer upto size of address want to write */
+	for (i = reg_size - 1, j = 0; i >= 0; i--, j++)
+		i2c_w_buf[i] = ((reg >> (8 * j)) & 0xFF);
+
+	/* Append the data value in the same buffer */
+	memcpy(i2c_w_buf + reg_size, buf, buf_size);
+
+	ret = i2c_master_send(client, i2c_w_buf, buf_size + reg_size);
+	
+        kfree(i2c_w_buf);
+
+	return ret;
+}
+
+static bool is_fallback_app_running(struct i2c_client *client)
+{
+    struct camera_common_data *s_data = to_camera_common_data(&client->dev);
+    struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+    int ret = 0;
+    bool fallback_app_running = false;
+    u64 avail_mipi = 0;
+    uint8_t supported_lane_counts = 0;
+
+    /* If camera lists no available MIPI data formats or no available MIPI lanes the fallback app is running */
+    ret = avt_reg_read(client,
+        priv->cci_reg.bcrm_addr +
+        BCRM_IMG_AVAILABLE_MIPI_DATA_FORMATS_64R,
+        AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+        (char *) &avail_mipi);
+
+    if (ret < 0)
+    {
+        dev_err(&client->dev, "i2c read failed (%d)\n", ret);
+        return false;
+    }
+
+    ret = avt_reg_read(priv->client,
+        priv->cci_reg.bcrm_addr + BCRM_SUPPORTED_CSI2_LANE_COUNTS_8R,
+        AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_8,
+        (char *) &supported_lane_counts);
+
+    if (ret < 0)
+    {
+        dev_err(&client->dev, "i2c read failed (%d)\n", ret);
+        return false;
+    }
+
+    fallback_app_running = ((avail_mipi == 0) || supported_lane_counts == 0);
+    if (fallback_app_running)
+    {
+        dev_warn(&client->dev, "Camera fallback app running. Streaming disabled.\n");
+    }
+
+    return fallback_app_running;
+}
+
+static bool bcrm_get_write_handshake_availibility(struct i2c_client *client)
+{
+	struct camera_common_data *s_data = to_camera_common_data(&client->dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+	u8 value = 0;
+	int status;
+
+	/* Reading the device firmware version from camera */
+	status = avt_reg_read(client,
+					priv->cci_reg.bcrm_addr +
+					BCRM_WRITE_HANDSHAKE_8RW,
+				 	AV_CAM_REG_SIZE,
+					AV_CAM_DATA_SIZE_8,
+					(char *) &value);
+
+	if ((status >= 0) && (value & 0x80))
+	{
+		dev_dbg(&client->dev, "BCRM write handshake supported!");
+		return true;
+	}
+	else
+	{
+		dev_warn(&client->dev, "BCRM write handshake NOT supported!");
+		return false;
+	}
+}
+
+/**
+ * @brief Since the camera needs a few ms to process written data, we need to poll
+   the handshake register to make sure to continue not too early with the next write access.
+ *
+ * @param timeout_ms : Timeout value in ms
+ * @param reg : Register previously written to (used just for debug msg)
+ * @return uint64_t : Duration in ms
+ */
+static uint64_t wait_for_bcrm_write_handshake(struct i2c_client *client, uint64_t timeout_ms, u16 reg)
+{
+	struct camera_common_data *s_data = to_camera_common_data(&client->dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+	static const int poll_interval_ms = 2;
+	static const int default_wait_time_ms = 20;
+	int status = 0;
+	u8 buffer[3] = {0};
+	u8 handshake_val = 0;
+	bool handshake_valid = false;
+	uint64_t duration_ms = 0;
+	uint64_t start_jiffies = get_jiffies_64();
+	unsigned long timeout_jiffies = jiffies + msecs_to_jiffies(timeout_ms);
+
+	if (priv->write_handshake_available)
+	{
+		/* We need to poll the handshake register and wait until the camera has processed the data */
+		dev_dbg(&client->dev, " Wait for 'write done' bit (0x81) ...");
+		do
+		{
+			usleep_range(poll_interval_ms*1000, (poll_interval_ms*1000)+1);
+			/* Read handshake register */
+			status = avt_reg_read(client,
+					        priv->cci_reg.bcrm_addr +
+					        BCRM_WRITE_HANDSHAKE_8RW,
+					        AV_CAM_REG_SIZE,
+					        AV_CAM_DATA_SIZE_8,
+				                (char *)&handshake_val);
+
+			if (status >= 0)
+			{
+				/* Check, if handshake bit is set */
+				if ((handshake_val & 0x01) == 1)
+				{
+					do
+					{
+						/* Handshake set by camera. We should to reset it */
+						buffer[0] = (priv->cci_reg.bcrm_addr + BCRM_WRITE_HANDSHAKE_8RW) >> 8;
+						buffer[1] = (priv->cci_reg.bcrm_addr + BCRM_WRITE_HANDSHAKE_8RW) & 0xff;
+						buffer[2] = (handshake_val & 0xFE); /* Reset LSB (handshake bit)*/
+						status = i2c_master_send(client, buffer, sizeof(buffer));
+						if (status >= 0)
+						{
+							/* Since the camera needs a few ms for every write access to finish, we need to poll here too */
+							dev_dbg(&client->dev, " Wait for reset of 'write done' bit (0x80) ...");
+							do
+							{
+								usleep_range(poll_interval_ms*1000, (poll_interval_ms*1000)+1);
+								/* We need to wait again until the bit is reset */
+								status = avt_reg_read(client,
+											priv->cci_reg.bcrm_addr +
+											BCRM_WRITE_HANDSHAKE_8RW,
+											AV_CAM_REG_SIZE,
+											AV_CAM_DATA_SIZE_8,
+											(char *)&handshake_val);
+
+								if (status >= 0)
+								{
+									if ((handshake_val & 0x1) == 0) /* Verify write */
+									{
+										duration_ms = jiffies_to_msecs(get_jiffies_64() - start_jiffies);
+										handshake_valid = true;
+										break;
+									}
+									usleep_range(poll_interval_ms*1000, (poll_interval_ms*1000)+1);
+								}
+								else
+								{
+									dev_err(&client->dev, " Error while reading WRITE_HANDSHAKE_REG_8RW register.");
+									break;
+								}
+							} while (time_before(jiffies, timeout_jiffies));
+							if (!handshake_valid)
+							{
+								dev_warn(&client->dev, " Verify handshake timeout :-)");
+							}
+							break;
+						}
+						else
+						{
+							dev_err(&client->dev, " Error while writing WRITE_HANDSHAKE_REG_8RW register.");
+							break;
+						}
+					} while (!handshake_valid && time_before(jiffies, timeout_jiffies));
+				}
+			}
+			else
+			{
+				dev_err(&client->dev, " Error while reading WRITE_HANDSHAKE_REG_8RW register.");
+				break;
+			}
+		}
+		while (!handshake_valid && time_before(jiffies, timeout_jiffies));
+
+		if (!handshake_valid)
+		{
+			dev_err(&client->dev, " Write handshake timeout! (Register 0x%02X)", reg);
+		}
+	}
+	else
+	{
+		/* Handshake not supported. Use static sleep at least once as fallback */
+
+		usleep_range(default_wait_time_ms*1000, (default_wait_time_ms*1000)+1);
+		//for (i=0; i<default_wait_time_ms; i++) {
+		//	udelay(1000);
+		//}
+		duration_ms = jiffies_to_msecs(get_jiffies_64() - start_jiffies);
+	}
+
+	return duration_ms;
+}
+
+static int avt_reg_read(struct i2c_client *client, __u32 reg,
+		__u32 reg_size, __u32 count, char *buffer)
+{
+	int ret;
+
+	uint32_t i2c_reg;
+	uint32_t i2c_reg_size;
+	uint32_t i2c_reg_count;
+
+	char *i2c_reg_buf;
+
+	i2c_reg = reg;
+	i2c_reg_size = reg_size;
+	i2c_reg_count = count;
+	i2c_reg_buf = buffer;
+
+	ret = i2c_read(client, i2c_reg,
+			i2c_reg_size, i2c_reg_count, i2c_reg_buf);
+
+	if (ret < 0)
+		return ret;
+
+	swapbytes(buffer, count);
+	return ret;
+}
+
+static int avt_reg_write(struct i2c_client *client, u16 reg, u8 val)
+{
+	int ret = 0;
+	u8 au8Buf[3] = {0};
+	uint64_t duration = 0;
+
+	au8Buf[0] = reg >> 8;
+	au8Buf[1] = reg & 0xff;
+	au8Buf[2] = val;
+
+	ret = i2c_master_send(client, au8Buf, 3);
+
+	if (ret < 0)
+		dev_err(&client->dev, "%s, i2c write failed reg=%x,val=%x error=%d\n",
+			__func__, reg, val, ret);
+
+	duration = wait_for_bcrm_write_handshake(client, BCRM_WAIT_HANDSHAKE_TIMEOUT, reg);
+
+	dev_dbg(&client->dev, "i2c write success reg=0x%x, duration=%lldms, ret=%d\n", reg, duration, ret);
+
+	return ret;
+}
+
+static struct avt_csi2_priv *avt_get_priv(struct v4l2_subdev *sd)
+{
+	struct i2c_client *client;
+	struct camera_common_data *s_data;
+
+	if (sd == NULL)
+		return NULL;
+
+	client = v4l2_get_subdevdata(sd);
+	if (client == NULL)
+		return NULL;
+
+	s_data = to_camera_common_data(&client->dev);
+	if (s_data == NULL)
+		return NULL;
+
+	return (struct avt_csi2_priv *)s_data->priv;
+}
+
+static struct v4l2_ctrl *avt_get_control(struct v4l2_subdev *sd, u32 id)
+{
+	int i;
+	struct avt_csi2_priv *priv = avt_get_priv(sd);
+
+	for (i = 0; i < AVT_MAX_CTRLS; i++) {
+		if (priv->ctrls[i] == NULL)
+			continue;
+		if (priv->ctrls[i]->id == id)
+			return priv->ctrls[i];
+	}
+
+	return NULL;
+}
+
+static int ioctl_gencam_i2cwrite_reg(struct i2c_client *client, uint32_t reg,
+		uint32_t size, uint32_t count, const char *buf)
+{
+	int j = 0, i = 0;
+	char *i2c_w_buf;
+	int ret = 0;
+	uint64_t duration = 0;
+	struct camera_common_data *s_data = to_camera_common_data(&client->dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+
+	/* count exceeds writting IO_LIMIT characters */
+	if (count > IO_LIMIT) {
+		dev_err(&client->dev, "limit excedded! i2c_reg->count > IO_LIMIT\n");
+		count = IO_LIMIT;
+	}
+
+	i2c_w_buf = kzalloc(count + size, GFP_KERNEL);
+	if (!i2c_w_buf)
+		return -ENOMEM;
+
+	/* Fill the address in buffer upto size of address want to write */
+	for (i = size - 1, j = 0; i >= 0; i--, j++)
+		i2c_w_buf[i] = ((reg >> (8 * j)) & 0xFF);
+
+	/* Append the data value in the same buffer */
+	memcpy(i2c_w_buf + size, buf, count);
+
+	ret = i2c_master_send(client, i2c_w_buf, count + size);
+
+	if (ret < 0)
+		dev_err(&client->dev, "%s:%d: i2c write failed ret %d\n",
+				__func__, __LINE__, ret);
+
+
+	/* Wait for write handshake register only for BCM registers */
+	if ((reg >= priv->cci_reg.bcrm_addr) && (reg <= priv->cci_reg.bcrm_addr + _BCRM_LAST_ADDR))
+	{
+		duration = wait_for_bcrm_write_handshake(client, BCRM_WAIT_HANDSHAKE_TIMEOUT, reg);
+		dev_dbg(&client->dev, "i2c write success reg=0x%x, duration=%lldms, ret=%d\n", reg, duration, ret);
+	}
+
+	kfree(i2c_w_buf);
+
+	return ret;
+}
+
+static int ioctl_bcrm_i2cwrite_reg(struct i2c_client *client,
+		struct v4l2_ext_control *vc,
+		unsigned int reg,
+		int length)
+{
+	uint32_t i2c_reg;
+	uint32_t i2c_reg_size;
+	uint32_t i2c_reg_count;
+	char *i2c_reg_buf;
+
+	ssize_t ret;
+	__u64 temp = 0;
+
+	if (length > AV_CAM_DATA_SIZE_32) {
+		temp = vc->value64;
+		swapbytes(&temp, length);
+	} else
+		swapbytes(&vc->value, length);
+
+	i2c_reg = reg;
+	i2c_reg_size = AV_CAM_REG_SIZE;
+	i2c_reg_count = length;
+
+	if (length > AV_CAM_DATA_SIZE_32)
+		i2c_reg_buf = (char *) &temp;
+	else
+		i2c_reg_buf = (char *) &vc->value;
+
+	ret = ioctl_gencam_i2cwrite_reg(client, i2c_reg, i2c_reg_size,
+			i2c_reg_count, i2c_reg_buf);
+
+	if (ret < 0)
+		dev_err(&client->dev, "%s:%d i2c write failed\n",
+				__func__, __LINE__);
+
+	return ret;
+}
+
+static int set_bayer_format(struct i2c_client *client, __u8 value)
+{
+	struct camera_common_data *s_data = to_camera_common_data(&client->dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+	int ret = 0;
+
+	uint32_t i2c_reg;
+	uint32_t i2c_reg_size;
+	uint32_t i2c_reg_count;
+
+	char *i2c_reg_buf;
+
+	CLEAR(i2c_reg);
+	i2c_reg = priv->cci_reg.bcrm_addr + BCRM_IMG_BAYER_PATTERN_8RW;
+	i2c_reg_size = AV_CAM_REG_SIZE;
+	i2c_reg_count = AV_CAM_DATA_SIZE_8;
+	i2c_reg_buf = (char *) &value;
+
+	ret = ioctl_gencam_i2cwrite_reg(client, i2c_reg, i2c_reg_size,
+					i2c_reg_count, i2c_reg_buf);
+
+	if (ret < 0) {
+		dev_err(&client->dev, "%s:%d i2c write failed\n",
+				__func__, __LINE__);
+		return ret;
+	}
+
+	return 0;
+}
+
+
+static bool avt_check_fmt_available(struct i2c_client *client, u32 media_bus_fmt)
+{
+	struct camera_common_data *s_data = to_camera_common_data(&client->dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+	u64 avail_mipi = 0;
+	unsigned char bayer_val = 0;
+	union bcrm_avail_mipi_reg feature_inquiry_reg;
+	union bcrm_bayer_inquiry_reg bayer_inquiry_reg;
+	int ret;
+
+    dev_dbg(&client->dev,"%s: media_bus_fmt: 0x%x\n", __FUNCTION__, media_bus_fmt);
+
+	if (media_bus_fmt ==  MEDIA_BUS_FMT_CUSTOM)
+		return true;
+
+	/* read the MIPI format register to check whether the camera
+	 * really support the requested pixelformat format
+	 */
+	ret = avt_reg_read(client,
+			priv->cci_reg.bcrm_addr +
+			BCRM_IMG_AVAILABLE_MIPI_DATA_FORMATS_64R,
+			AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+			(char *) &avail_mipi);
+
+	if (ret < 0) {
+		dev_err(&client->dev, "i2c read failed (%d)\n", ret);
+		return false;
+	}
+
+    dev_dbg(&client->dev,"%s: Camera available MIPI data formats: 0x%llx\n", __FUNCTION__, avail_mipi);
+
+    if (priv->fallback_app_running)
+    {
+            /* Fallback app running? -> Fake pixelformat */
+            avail_mipi = 0x80;      // RGB888 
+    }
+
+	feature_inquiry_reg.value = avail_mipi;
+
+	/* read the Bayer Inquiry register to check whether the camera
+	 * really support the requested RAW format
+	 */
+	ret = avt_reg_read(client,
+			priv->cci_reg.bcrm_addr +
+			BCRM_IMG_BAYER_PATTERN_INQUIRY_8R,
+			AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_8,
+			(char *) &bayer_val);
+
+    dev_dbg(&client->dev,"%s: Camera bayer pattern inq: 0x%x\n", __FUNCTION__, bayer_val);
+	if (ret < 0) {
+		dev_err(&client->dev, "i2c read failed (%d)\n", ret);
+		return false;
+	}
+
+	bayer_inquiry_reg.value = bayer_val;
+
+	switch (media_bus_fmt) {
+		case MEDIA_BUS_FMT_RGB444_1X12:
+			return feature_inquiry_reg.avail_mipi.rgb444_avail;
+		case MEDIA_BUS_FMT_RGB565_1X16:
+			return feature_inquiry_reg.avail_mipi.rgb565_avail;
+		case MEDIA_BUS_FMT_RGB888_1X24:
+		case MEDIA_BUS_FMT_BGR888_1X24:
+			return feature_inquiry_reg.avail_mipi.rgb888_avail;
+		case MEDIA_BUS_FMT_VYUY8_2X8:
+			return feature_inquiry_reg.avail_mipi.yuv422_8_avail;
+		/* RAW 8 */
+		case MEDIA_BUS_FMT_Y8_1X8:
+			return feature_inquiry_reg.avail_mipi.raw8_avail &&
+				bayer_inquiry_reg.bayer_pattern.monochrome_avail;
+		case MEDIA_BUS_FMT_SBGGR8_1X8:
+			return feature_inquiry_reg.avail_mipi.raw8_avail &&
+				bayer_inquiry_reg.bayer_pattern.bayer_BG_avail;
+		case MEDIA_BUS_FMT_SGBRG8_1X8:
+			return feature_inquiry_reg.avail_mipi.raw8_avail
+				&& bayer_inquiry_reg.bayer_pattern.bayer_GB_avail;
+		case MEDIA_BUS_FMT_SGRBG8_1X8:
+			return feature_inquiry_reg.avail_mipi.raw8_avail &&
+				bayer_inquiry_reg.bayer_pattern.bayer_GR_avail;
+		case MEDIA_BUS_FMT_SRGGB8_1X8:
+			return feature_inquiry_reg.avail_mipi.raw8_avail &&
+				bayer_inquiry_reg.bayer_pattern.bayer_RG_avail;
+		/* RAW 10 */
+		case MEDIA_BUS_FMT_Y10_1X10:
+			return feature_inquiry_reg.avail_mipi.raw10_avail &&
+				bayer_inquiry_reg.bayer_pattern.monochrome_avail;
+		case MEDIA_BUS_FMT_SGBRG10_1X10:
+			return feature_inquiry_reg.avail_mipi.raw10_avail &&
+				bayer_inquiry_reg.bayer_pattern.bayer_GB_avail;
+		case MEDIA_BUS_FMT_SGRBG10_1X10:
+			return feature_inquiry_reg.avail_mipi.raw10_avail &&
+				bayer_inquiry_reg.bayer_pattern.bayer_GR_avail;
+		case MEDIA_BUS_FMT_SRGGB10_1X10:
+			return feature_inquiry_reg.avail_mipi.raw10_avail &&
+				bayer_inquiry_reg.bayer_pattern.bayer_RG_avail;
+		/* RAW 12 */
+		case MEDIA_BUS_FMT_Y12_1X12:
+			return feature_inquiry_reg.avail_mipi.raw12_avail &&
+				bayer_inquiry_reg.bayer_pattern.monochrome_avail;
+		case MEDIA_BUS_FMT_SBGGR12_1X12:
+			return feature_inquiry_reg.avail_mipi.raw12_avail &&
+				bayer_inquiry_reg.bayer_pattern.bayer_BG_avail;
+		case MEDIA_BUS_FMT_SGBRG12_1X12:
+			return feature_inquiry_reg.avail_mipi.raw12_avail &&
+				bayer_inquiry_reg.bayer_pattern.bayer_GB_avail;
+		case MEDIA_BUS_FMT_SGRBG12_1X12:
+			return feature_inquiry_reg.avail_mipi.raw12_avail &&
+				bayer_inquiry_reg.bayer_pattern.bayer_GR_avail;
+		case MEDIA_BUS_FMT_SRGGB12_1X12:
+			return feature_inquiry_reg.avail_mipi.raw12_avail &&
+				bayer_inquiry_reg.bayer_pattern.bayer_RG_avail;
+	}
+
+	return false;
+}
+
+static int avt_ctrl_send(struct i2c_client *client,
+		struct avt_ctrl *vc)
+{
+	struct camera_common_data *s_data = to_camera_common_data(&client->dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+	int ret = 0;
+	unsigned int reg = 0;
+	int length = 0;
+
+	uint32_t i2c_reg;
+	uint32_t i2c_reg_size;
+	uint32_t i2c_reg_count;
+
+	char *i2c_reg_buf;
+
+	//void *mipi_csi2_info;
+	int r_wn = 0;/* write -> r_wn = 0, read -> r_wn = 1 */
+	u64 avail_mipi = 0;
+	union bcrm_avail_mipi_reg feature_inquiry_reg;
+	union bcrm_bayer_inquiry_reg bayer_inquiry_reg;
+	unsigned char bayer_val = 0;
+	u64 temp = 0;
+	int gencp_mode_local = 0;/* Default BCRM mode */
+	__u8 bayer_temp = 0;
+
+	bayer_inquiry_reg.value = 0;
+	feature_inquiry_reg.value = 0;
+
+	if (vc->id == V4L2_AV_CSI2_PIXELFORMAT_W) 
+    {
+		/* read the MIPI format register to check whether the camera
+		 * really support the requested pixelformat format
+		 */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr +
+				BCRM_IMG_AVAILABLE_MIPI_DATA_FORMATS_64R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &avail_mipi);
+
+		if (ret < 0)
+        {
+			dev_err(&client->dev, "i2c read failed (%d)\n", ret);
+        }
+
+        if (priv->fallback_app_running)
+        {
+            /* Fallback app running? */
+            avail_mipi = 0x80; // fake RGB888
+        }
+		feature_inquiry_reg.value = avail_mipi;
+
+        	/* read the Bayer Inquiry register to check whether the camera
+		 * really support the requested RAW format
+		 */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr +
+				BCRM_IMG_BAYER_PATTERN_INQUIRY_8R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_8,
+				(char *) &bayer_val);
+
+		if (ret < 0)
+			dev_err(&client->dev, "i2c read failed (%d)\n", ret);
+
+		dev_dbg(&client->dev, "Bayer Inquiry Reg value : 0x%x\n",
+				bayer_val);
+
+		bayer_inquiry_reg.value = bayer_val;
+	}
+
+	switch (vc->id) {
+	case V4L2_AV_CSI2_STREAMON_W:
+		reg = BCRM_ACQUISITION_START_8RW;
+		length = AV_CAM_DATA_SIZE_8;
+		r_wn = 0;
+		break;
+	case V4L2_AV_CSI2_STREAMOFF_W:
+		reg = BCRM_ACQUISITION_STOP_8RW;
+		length = AV_CAM_DATA_SIZE_8;
+		r_wn = 0;
+		break;
+	case V4L2_AV_CSI2_ABORT_W:
+		reg = BCRM_ACQUISITION_ABORT_8RW;
+		length = AV_CAM_DATA_SIZE_8;
+		r_wn = 0;
+		break;
+	case V4L2_AV_CSI2_WIDTH_W:
+		reg = BCRM_IMG_WIDTH_32RW;
+		length = AV_CAM_DATA_SIZE_32;
+		r_wn = 0;
+		break;
+	case V4L2_AV_CSI2_HEIGHT_W:
+		reg = BCRM_IMG_HEIGHT_32RW;
+		length = AV_CAM_DATA_SIZE_32;
+		r_wn = 0;
+		break;
+	case V4L2_AV_CSI2_OFFSET_X_W:
+		reg = BCRM_IMG_OFFSET_X_32RW;
+		length = AV_CAM_DATA_SIZE_32;
+		r_wn = 0;
+		break;
+	case V4L2_AV_CSI2_OFFSET_Y_W:
+		reg = BCRM_IMG_OFFSET_Y_32RW;
+		length = AV_CAM_DATA_SIZE_32;
+		r_wn = 0;
+		break;
+	case V4L2_AV_CSI2_HFLIP_W:
+		reg = BCRM_IMG_REVERSE_X_8RW;
+		length = AV_CAM_DATA_SIZE_8;
+		r_wn = 0;
+		break;
+	case V4L2_AV_CSI2_VFLIP_W:
+		reg = BCRM_IMG_REVERSE_Y_8RW;
+		length = AV_CAM_DATA_SIZE_8;
+		r_wn = 0;
+		break;
+	case V4L2_AV_CSI2_PIXELFORMAT_W:
+		reg = BCRM_IMG_MIPI_DATA_FORMAT_32RW;
+		length = AV_CAM_DATA_SIZE_32;
+		r_wn = 0;
+
+		if(!avt_check_fmt_available(client, vc->value0)) {
+				dev_err(&client->dev, "format 0x%x not supported\n", vc->value0);
+				return -EINVAL;
+		}
+
+		switch (vc->value0) {
+		case MEDIA_BUS_FMT_CUSTOM:
+			vc->value0 = MIPI_DT_CUSTOM;
+			break;
+		case MEDIA_BUS_FMT_RGB444_1X12:
+			vc->value0 = MIPI_DT_RGB444;
+			break;
+		case MEDIA_BUS_FMT_RGB565_1X16:
+			vc->value0 = MIPI_DT_RGB565;
+			break;
+		case MEDIA_BUS_FMT_RGB888_1X24:
+		case MEDIA_BUS_FMT_BGR888_1X24:
+			vc->value0 = MIPI_DT_RGB888;
+			break;
+		case MEDIA_BUS_FMT_VYUY8_2X8:
+			vc->value0 = MIPI_DT_YUV422;
+			break;
+		/* RAW 8 */
+		case MEDIA_BUS_FMT_Y8_1X8:
+			vc->value0 = MIPI_DT_RAW8;
+			bayer_temp = monochrome;
+			break;
+		case MEDIA_BUS_FMT_SBGGR8_1X8:
+			vc->value0 = MIPI_DT_RAW8;
+			bayer_temp = bayer_bg;
+			break;
+		case MEDIA_BUS_FMT_SGBRG8_1X8:
+			vc->value0 = MIPI_DT_RAW8;
+			bayer_temp = bayer_gb;
+			break;
+		case MEDIA_BUS_FMT_SGRBG8_1X8:
+			vc->value0 = MIPI_DT_RAW8;
+			bayer_temp = bayer_gr;
+			break;
+		case MEDIA_BUS_FMT_SRGGB8_1X8:
+			vc->value0 = MIPI_DT_RAW8;
+			bayer_temp = bayer_rg;
+			break;
+		/* RAW 10 */
+		case MEDIA_BUS_FMT_Y10_1X10:
+			vc->value0 = MIPI_DT_RAW10;
+			bayer_temp = monochrome;
+			break;
+		case MEDIA_BUS_FMT_SGBRG10_1X10:
+			vc->value0 = MIPI_DT_RAW10;
+			bayer_temp = bayer_gb;
+			break;
+		case MEDIA_BUS_FMT_SGRBG10_1X10:
+			vc->value0 = MIPI_DT_RAW10;
+			bayer_temp = bayer_gr;
+			break;
+		case MEDIA_BUS_FMT_SRGGB10_1X10:
+			vc->value0 = MIPI_DT_RAW10;
+			bayer_temp = bayer_rg;
+			break;
+		/* RAW 12 */
+		case MEDIA_BUS_FMT_Y12_1X12:
+			vc->value0 = MIPI_DT_RAW12;
+			bayer_temp = monochrome;
+			break;
+		case MEDIA_BUS_FMT_SBGGR12_1X12:
+			vc->value0 = MIPI_DT_RAW12;
+			bayer_temp = bayer_bg;
+			break;
+		case MEDIA_BUS_FMT_SGBRG12_1X12:
+			vc->value0 = MIPI_DT_RAW12;
+			bayer_temp = bayer_gb;
+			break;
+		case MEDIA_BUS_FMT_SGRBG12_1X12:
+			vc->value0 = MIPI_DT_RAW12;
+			bayer_temp = bayer_gr;
+			break;
+		case MEDIA_BUS_FMT_SRGGB12_1X12:
+			vc->value0 = MIPI_DT_RAW12;
+			bayer_temp = bayer_rg;
+			break;
+
+		case 0:
+			/* Fallback app running */
+			dev_warn(&client->dev, "Invalid pixelformat detected (0). Fallback app running?");
+			vc->value0 = MIPI_DT_RGB888;
+			break;       
+
+		default:
+			dev_err(&client->dev, "%s: format 0x%x not supported by the host\n",
+					__func__, vc->value0);
+			return -EINVAL;
+		}
+		break;
+
+	case V4L2_AV_CSI2_WIDTH_R:
+		reg = BCRM_IMG_WIDTH_32RW;
+		length = AV_CAM_DATA_SIZE_32;
+		r_wn = 1;
+		break;
+	case V4L2_AV_CSI2_WIDTH_MINVAL_R:
+		reg = BCRM_IMG_WIDTH_MIN_32R;
+		length = AV_CAM_DATA_SIZE_32;
+		r_wn = 1;
+		break;
+	case V4L2_AV_CSI2_WIDTH_MAXVAL_R:
+		reg = BCRM_IMG_WIDTH_MAX_32R;
+		length = AV_CAM_DATA_SIZE_32;
+		r_wn = 1;
+		break;
+	case V4L2_AV_CSI2_WIDTH_INCVAL_R:
+		reg = BCRM_IMG_WIDTH_INC_32R;
+		length = AV_CAM_DATA_SIZE_32;
+		r_wn = 1;
+		break;
+	case V4L2_AV_CSI2_HEIGHT_R:
+		reg = BCRM_IMG_HEIGHT_32RW;
+		length = AV_CAM_DATA_SIZE_32;
+		r_wn = 1;
+		break;
+	case V4L2_AV_CSI2_HEIGHT_MINVAL_R:
+		reg = BCRM_IMG_HEIGHT_MIN_32R;
+		length = AV_CAM_DATA_SIZE_32;
+		r_wn = 1;
+		break;
+	case V4L2_AV_CSI2_HEIGHT_MAXVAL_R:
+		reg = BCRM_IMG_HEIGHT_MAX_32R;
+		length = AV_CAM_DATA_SIZE_32;
+		r_wn = 1;
+		break;
+	case V4L2_AV_CSI2_HEIGHT_INCVAL_R:
+		reg = BCRM_IMG_HEIGHT_INC_32R;
+		length = AV_CAM_DATA_SIZE_32;
+		r_wn = 1;
+		break;
+	case V4L2_AV_CSI2_OFFSET_X_R:
+		reg = BCRM_IMG_OFFSET_X_32RW;
+		length = AV_CAM_DATA_SIZE_32;
+		r_wn = 1;
+		break;
+	case V4L2_AV_CSI2_OFFSET_X_MIN_R:
+		reg = BCRM_IMG_OFFSET_X_MIN_32R;
+		length = AV_CAM_DATA_SIZE_32;
+		r_wn = 1;
+		break;
+	case V4L2_AV_CSI2_OFFSET_X_MAX_R:
+		reg = BCRM_IMG_OFFSET_X_MAX_32R;
+		length = AV_CAM_DATA_SIZE_32;
+		r_wn = 1;
+		break;
+	case V4L2_AV_CSI2_OFFSET_X_INC_R:
+		reg = BCRM_IMG_OFFSET_X_INC_32R;
+		length = AV_CAM_DATA_SIZE_32;
+		r_wn = 1;
+		break;
+	case V4L2_AV_CSI2_OFFSET_Y_R:
+		reg = BCRM_IMG_OFFSET_Y_32RW;
+		length = AV_CAM_DATA_SIZE_32;
+		r_wn = 1;
+		break;
+	case V4L2_AV_CSI2_OFFSET_Y_MIN_R:
+		reg = BCRM_IMG_OFFSET_Y_MIN_32R;
+		length = AV_CAM_DATA_SIZE_32;
+		r_wn = 1;
+		break;
+	case V4L2_AV_CSI2_OFFSET_Y_MAX_R:
+		reg = BCRM_IMG_OFFSET_Y_MAX_32R;
+		length = AV_CAM_DATA_SIZE_32;
+		r_wn = 1;
+		break;
+	case V4L2_AV_CSI2_OFFSET_Y_INC_R:
+		reg = BCRM_IMG_OFFSET_Y_INC_32R;
+		length = AV_CAM_DATA_SIZE_32;
+		r_wn = 1;
+		break;
+	case V4L2_AV_CSI2_SENSOR_WIDTH_R:
+		reg = BCRM_SENSOR_WIDTH_32R;
+		length = AV_CAM_DATA_SIZE_32;
+		r_wn = 1;
+		break;
+	case V4L2_AV_CSI2_SENSOR_HEIGHT_R:
+		reg = BCRM_SENSOR_HEIGHT_32R;
+		length = AV_CAM_DATA_SIZE_32;
+		r_wn = 1;
+		break;
+	case V4L2_AV_CSI2_MAX_WIDTH_R:
+		reg = BCRM_WIDTH_MAX_32R;
+		length = AV_CAM_DATA_SIZE_32;
+		r_wn = 1;
+		break;
+	case V4L2_AV_CSI2_MAX_HEIGHT_R:
+		reg = BCRM_HEIGHT_MAX_32R;
+		length = AV_CAM_DATA_SIZE_32;
+		r_wn = 1;
+		break;
+	case V4L2_AV_CSI2_PIXELFORMAT_R:
+		reg = BCRM_IMG_MIPI_DATA_FORMAT_32RW;
+		length = AV_CAM_DATA_SIZE_32;
+		r_wn = 1;
+		break;
+	case V4L2_AV_CSI2_PALYLOADSIZE_R:
+		reg = BCRM_BUFFER_SIZE_32R;
+		length = AV_CAM_DATA_SIZE_32;
+		r_wn = 1;
+		break;
+	case V4L2_AV_CSI2_ACQ_STATUS_R:
+		reg = BCRM_ACQUISITION_STATUS_8R;
+		length = AV_CAM_DATA_SIZE_8;
+		r_wn = 1;
+		break;
+	case V4L2_AV_CSI2_HFLIP_R:
+		reg = BCRM_IMG_REVERSE_X_8RW;
+		length = AV_CAM_DATA_SIZE_8;
+		r_wn = 1;
+		break;
+	case V4L2_AV_CSI2_VFLIP_R:
+		reg = BCRM_IMG_REVERSE_Y_8RW;
+		length = AV_CAM_DATA_SIZE_8;
+		r_wn = 1;
+		break;
+	case V4L2_AV_CSI2_CURRENTMODE_R:
+		reg = CCI_CURRENT_MODE_8R;
+		length = AV_CAM_DATA_SIZE_8;
+		gencp_mode_local = 1;
+		r_wn = 1;
+		break;
+	case V4L2_AV_CSI2_CHANGEMODE_W:
+		reg = CCI_CHANGE_MODE_8W;
+		length = AV_CAM_DATA_SIZE_8;
+		gencp_mode_local = 1;
+		if (vc->value0 == MIPI_DT_CUSTOM)
+			priv->mode = AVT_GENCP_MODE;
+		else
+			priv->mode = AVT_BCRM_MODE;
+		r_wn = 0;
+		break;
+	default:
+		dev_err(&client->dev, "%s: unknown ctrl 0x%x\n",
+				__func__, vc->id);
+		return -EINVAL;
+	}
+
+	if (r_wn) {/* read (r_wn=1) */
+
+		if (gencp_mode_local) {
+
+			ret = avt_reg_read(client,
+					reg, AV_CAM_REG_SIZE, length,
+					(char *) &vc->value0);
+
+			if (ret < 0) {
+				dev_err(&client->dev, "i2c read failed (%d)\n",
+						ret);
+				return ret;
+			}
+			return 0;
+		}
+
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + reg,
+				AV_CAM_REG_SIZE, length,
+				(char *) &vc->value0);
+
+		if (ret < 0) {
+			dev_err(&client->dev, "i2c read failed (%d)\n", ret);
+			return ret;
+		}
+
+		if (vc->id == V4L2_AV_CSI2_PIXELFORMAT_R) {
+			/* To avoid ambiguity, resulting from
+			 * two MBUS formats linked with
+			 * one camera image format,
+			 * we return value stored in private data
+			 */
+			vc->value0 = priv->mbus_fmt_code;
+		}
+
+		return 0;
+
+	} else {/* write (r_wn=0) */
+		dev_dbg(&client->dev, "reg %x, length %d, vc->value0 0x%x\n",
+				reg, length, vc->value0);
+
+		if (gencp_mode_local) {
+
+			i2c_reg = reg;
+			i2c_reg_size = AV_CAM_REG_SIZE;
+			i2c_reg_count = length;
+
+			if (length > AV_CAM_DATA_SIZE_32)
+				i2c_reg_buf = (char *) &temp;
+			else
+				i2c_reg_buf = (char *) &vc->value0;
+
+			ret = ioctl_gencam_i2cwrite_reg(client,
+					i2c_reg, i2c_reg_size,
+					i2c_reg_count, i2c_reg_buf);
+
+			if (ret < 0) {
+				dev_err(&client->dev, "%s:%d i2c write failed\n",
+						__func__, __LINE__);
+				return ret;
+			} else {
+				return 0;
+			}
+		}
+
+		if (vc->id == V4L2_AV_CSI2_PIXELFORMAT_W) {
+			/* Set pixelformat then set bayer format, refer OCT-2417
+			 *
+			 * XXX implement these somehow, below imx6 code:
+			 * mipi_csi2_info = mipi_csi2_get_info();
+			 * mipi_csi2_set_datatype(mipi_csi2_info, vc->value0);
+			 */
+		}
+
+		temp = vc->value0;
+
+		if (length > AV_CAM_DATA_SIZE_32)
+			swapbytes(&temp, length);
+		else
+			swapbytes(&vc->value0, length);
+
+		i2c_reg       = priv->cci_reg.bcrm_addr + reg;
+		i2c_reg_size  = AV_CAM_REG_SIZE;
+		i2c_reg_count = length;
+
+		if (length > AV_CAM_DATA_SIZE_32)
+			i2c_reg_buf = (char *) &temp;
+		else
+			i2c_reg_buf = (char *) &vc->value0;
+
+		ret = ioctl_gencam_i2cwrite_reg(client, i2c_reg, i2c_reg_size,
+						i2c_reg_count, i2c_reg_buf);
+
+		if (ret < 0) {
+			dev_err(&client->dev, "%s:%d i2c write failed\n",
+					__func__, __LINE__);
+			return ret;
+		}
+
+		/* Set pixelformat then set bayer format, refer OCT-2417 */
+		if (vc->id == V4L2_AV_CSI2_PIXELFORMAT_W) {
+			ret = set_bayer_format(client, bayer_temp);
+			if (ret < 0) {
+				dev_err(&client->dev, "%s:%d i2c write failed, ret %d\n",
+						__func__, __LINE__, ret);
+				return ret;
+			}
+		}
+
+		return 0;
+	}
+}
+
+static void set_channel_avt_cam_mode(struct v4l2_subdev *sd, bool cam_mode)
+{
+	struct tegra_channel *tch;
+	struct media_pad *pad_csi, *pad_vi;
+	struct v4l2_subdev *sd_csi, *sd_vi;
+	struct video_device *vdev_vi;
+
+	if (!sd->entity.pads)
+		return;
+
+	pad_csi = media_entity_remote_pad(&sd->entity.pads[0]);
+	sd_csi = media_entity_to_v4l2_subdev(pad_csi->entity);
+	pad_vi = media_entity_remote_pad(&sd_csi->entity.pads[1]);
+	sd_vi = media_entity_to_v4l2_subdev(pad_vi->entity);
+	vdev_vi = media_entity_to_video_device(pad_vi->entity);
+	tch = video_get_drvdata(vdev_vi);
+
+	tch->avt_cam_mode = cam_mode;
+}
+
+static void set_channel_trigger_mode(struct v4l2_subdev *sd, bool trigger_mode)
+{
+	struct tegra_channel *tch;
+	struct media_pad *pad_csi, *pad_vi;
+	struct v4l2_subdev *sd_csi, *sd_vi;
+	struct video_device *vdev_vi;
+
+	if (!sd->entity.pads)
+		return;
+
+	pad_csi = media_entity_remote_pad(&sd->entity.pads[0]);
+	sd_csi = media_entity_to_v4l2_subdev(pad_csi->entity);
+	pad_vi = media_entity_remote_pad(&sd_csi->entity.pads[1]);
+	sd_vi = media_entity_to_v4l2_subdev(pad_vi->entity);
+	vdev_vi = media_entity_to_video_device(pad_vi->entity);
+	tch = video_get_drvdata(vdev_vi);
+
+	tch->trigger_mode = trigger_mode;
+}
+
+static void set_channel_pending_trigger(struct v4l2_subdev *sd)
+{
+	struct tegra_channel *tch;
+	struct media_pad *pad_csi, *pad_vi;
+	struct v4l2_subdev *sd_csi, *sd_vi;
+	struct video_device *vdev_vi;
+
+	if (!sd->entity.pads)
+		return;
+
+	pad_csi = media_entity_remote_pad(&sd->entity.pads[0]);
+	sd_csi = media_entity_to_v4l2_subdev(pad_csi->entity);
+	pad_vi = media_entity_remote_pad(&sd_csi->entity.pads[1]);
+	sd_vi = media_entity_to_v4l2_subdev(pad_vi->entity);
+	vdev_vi = media_entity_to_video_device(pad_vi->entity);
+	tch = video_get_drvdata(vdev_vi);
+
+	tch->pending_trigger = true;
+}
+
+static void set_channel_timeout(struct v4l2_subdev *sd, unsigned long timeout)
+{
+	struct tegra_channel *tch;
+	struct media_pad *pad_csi, *pad_vi;
+	struct v4l2_subdev *sd_csi, *sd_vi;
+	struct video_device *vdev_vi;
+
+	if (!sd->entity.pads)
+		return;
+
+	pad_csi = media_entity_remote_pad(&sd->entity.pads[0]);
+	sd_csi = media_entity_to_v4l2_subdev(pad_csi->entity);
+	pad_vi = media_entity_remote_pad(&sd_csi->entity.pads[1]);
+	sd_vi = media_entity_to_v4l2_subdev(pad_vi->entity);
+	vdev_vi = media_entity_to_video_device(pad_vi->entity);
+	tch = video_get_drvdata(vdev_vi);
+
+	if (timeout == AVT_TEGRA_TIMEOUT_DISABLED) {
+		tch->timeout = timeout;
+	}
+	else
+		tch->timeout = msecs_to_jiffies(timeout);
+}
+
+static void set_channel_stride_align(struct v4l2_subdev *sd, uint8_t align)
+{
+	struct tegra_channel *tch;
+	struct media_pad *pad_csi, *pad_vi;
+	struct v4l2_subdev *sd_csi, *sd_vi;
+	struct video_device *vdev_vi;
+
+	if (!sd->entity.pads)
+		return;
+
+	pad_csi = media_entity_remote_pad(&sd->entity.pads[0]);
+	sd_csi = media_entity_to_v4l2_subdev(pad_csi->entity);
+	pad_vi = media_entity_remote_pad(&sd_csi->entity.pads[1]);
+	sd_vi = media_entity_to_v4l2_subdev(pad_vi->entity);
+	vdev_vi = media_entity_to_video_device(pad_vi->entity);
+	tch = video_get_drvdata(vdev_vi);
+
+	tch->stride_align = align;
+}
+
+static void set_channel_stride_align_for_format(struct v4l2_subdev *sd, uint32_t mbus_code)
+{
+	/* Set stride alignment required for the format */
+	switch (mbus_code) {
+	case MEDIA_BUS_FMT_RGB888_1X24:
+	case MEDIA_BUS_FMT_BGR888_1X24:
+		set_channel_stride_align(sd, 16);
+		break;
+	case MEDIA_BUS_FMT_VYUY8_2X8:
+	case MEDIA_BUS_FMT_RGB565_1X16:
+		set_channel_stride_align(sd, 32);
+		break;
+	case MEDIA_BUS_FMT_CUSTOM:
+		set_channel_stride_align(sd, 64);
+		break;
+	/* 8 bit bayer formats */
+	case MEDIA_BUS_FMT_SBGGR8_1X8:
+	case MEDIA_BUS_FMT_SGBRG8_1X8:
+	case MEDIA_BUS_FMT_SGRBG8_1X8:
+	case MEDIA_BUS_FMT_SRGGB8_1X8:
+	case MEDIA_BUS_FMT_Y8_1X8:
+		set_channel_stride_align(sd, 64);
+		break;
+	/* the remaining formats */
+	default:
+		set_channel_stride_align(sd, 1);
+		break;
+	}
+}
+
+static int avt_tegra_s_ctrl(struct v4l2_ctrl *ctrl)
+{
+	struct v4l2_subdev *sd;
+	struct avt_csi2_priv *priv;
+	unsigned long timeout;
+	int i;
+
+	priv = container_of(ctrl->handler, struct avt_csi2_priv, hdl);
+	sd = priv->subdev;
+
+	switch (ctrl->id) {
+	case AVT_TEGRA_TIMEOUT:
+		if (ctrl->val == 0)
+			set_channel_timeout(sd, AVT_TEGRA_TIMEOUT_DISABLED);
+		else {
+			for (i = 0; i < ARRAY_SIZE(priv->ctrls); ++i) {
+				if (priv->ctrls[i]->id == AVT_TEGRA_TIMEOUT_VALUE) {
+					timeout = priv->ctrls[i]->val;
+					set_channel_timeout(sd, timeout);
+					return 0;
+				}
+			}
+		}
+		break;
+	case AVT_TEGRA_TIMEOUT_VALUE:
+		for (i = 0; i < ARRAY_SIZE(priv->ctrls); ++i) {
+			/* First check if the timouet is not disabled */
+			if (priv->ctrls[i]->id == AVT_TEGRA_TIMEOUT) {
+				if (priv->ctrls[i]->val == 0)
+					return 0;
+				else
+					break;
+			}
+		}
+
+		/* If it is not disabled, set it in HW */
+		set_channel_timeout(sd, ctrl->val);
+		break;
+	case AVT_TEGRA_STRIDE_ALIGN:
+		if (ctrl->val == 0)
+			priv->stride_align_enabled = false;
+		else
+			priv->stride_align_enabled = true;
+		break;
+	case AVT_TEGRA_CROP_ALIGN:
+		if (ctrl->val == 0)
+			priv->crop_align_enabled = false;
+		else
+			priv->crop_align_enabled = true;
+        break;
+    case AVT_TEGRA_VALUE_UPDATE_INTERVAL:
+        priv->value_update_interval =  ctrl->val;
+		atomic_set(&priv->force_value_update, 1);
+		wake_up_all(&priv->value_update_wq);
+        break;
+    case AVT_TEGRA_FORCE_VALUE_UPDATE:
+        atomic_set(&priv->force_value_update, 1);
+        wake_up_all(&priv->value_update_wq);
+        break;
+}
+
+	return 0;
+}
+
+static const struct v4l2_ctrl_ops avt_tegra_ctrl_ops = {
+	.s_ctrl = avt_tegra_s_ctrl,
+};
+
+static const struct v4l2_ctrl_config avt_tegra_ctrl[] = {
+	{
+		.ops = &avt_tegra_ctrl_ops,
+		.id = AVT_TEGRA_TIMEOUT,
+		.name = "Frame timeout enabled",
+		.type = V4L2_CTRL_TYPE_BOOLEAN,
+		.def = 1,
+		.min = 0,
+		.max = 1,
+		.step = 1,
+	},
+	{
+		.ops = &avt_tegra_ctrl_ops,
+		.id = AVT_TEGRA_TIMEOUT_VALUE,
+		.name = "Frame timeout",
+		.type = V4L2_CTRL_TYPE_INTEGER,
+		.min = 100,
+		.max = 12000,
+		.step = 1,
+		.def = AVT_TEGRA_TIMEOUT_DEFAULT,
+	},
+	{
+		.ops = &avt_tegra_ctrl_ops,
+		.id = AVT_TEGRA_STRIDE_ALIGN,
+		.name = "Stride alignment enabled",
+		.type = V4L2_CTRL_TYPE_BOOLEAN,
+		.def = 1,
+		.min = 0,
+		.max = 1,
+		.step = 1,
+	},
+	{
+		.ops = &avt_tegra_ctrl_ops,
+		.id = AVT_TEGRA_CROP_ALIGN,
+		.name = "Crop alignment enabled",
+		.type = V4L2_CTRL_TYPE_BOOLEAN,
+		.def = 1,
+		.min = 0,
+		.max = 1,
+		.step = 1,
+	},
+    {
+        .ops = &avt_tegra_ctrl_ops,
+        .id = AVT_TEGRA_VALUE_UPDATE_INTERVAL,
+        .name = "Value update interval",
+        .type = V4L2_CTRL_TYPE_INTEGER,
+        .def = 1000,
+        .min = 0,
+        .max = 60000,
+        .step = 1,
+    },
+    {
+        .ops = &avt_tegra_ctrl_ops,
+        .id = AVT_TEGRA_FORCE_VALUE_UPDATE,
+        .name = "Force value update",
+        .type = V4L2_CTRL_TYPE_BUTTON,
+        .def = 0,
+        .min = 0,
+        .max = 0,
+        .step = 0,
+    },
+
+};
+
+/* --------------- INIT --------------- */
+
+static int avt_csi2_subscribe_event(struct v4l2_subdev *sd, struct v4l2_fh *fh,
+		struct v4l2_event_subscription *sub)
+{
+	switch (sub->type) {
+	case V4L2_EVENT_SOURCE_CHANGE:
+		return v4l2_src_change_event_subdev_subscribe(sd, fh, sub);
+	case V4L2_EVENT_CTRL:
+		return v4l2_ctrl_subdev_subscribe_event(sd, fh, sub);
+	default:
+		return -EINVAL;
+	}
+}
+
+
+/* --------------- CUSTOM IOCTLS --------------- */
+
+long avt_csi2_ioctl(struct v4l2_subdev *sd, unsigned int cmd, void *arg)
+{
+	int ret = -ENOTTY;
+	struct i2c_client *client = v4l2_get_subdevdata(sd);
+	struct avt_csi2_priv *priv = avt_get_priv(sd);
+	struct v4l2_i2c *i2c_reg;
+	char *i2c_reg_buf;
+	int *i2c_clk_freq;
+	struct v4l2_gencp_buffer_sizes *gencp_buf_sz;
+	struct v4l2_csi_driver_info *info;
+	struct v4l2_csi_config *config;
+	uint32_t i2c_reg_address;
+	uint32_t i2c_reg_size;
+	uint32_t i2c_reg_count;
+	uint32_t clk;
+	uint8_t avt_supported_lane_counts = 0;
+	uint32_t avt_min_clk = 0;
+	uint32_t avt_max_clk = 0;
+	uint32_t common_min_clk = 0;
+	uint32_t common_max_clk = 0;
+	uint32_t common_inc_clk = 0;
+
+	avt_dbg(sd, "%s(cmd=%u)\n", __func__, cmd);
+
+	switch(cmd) {
+	case VIDIOC_R_I2C:
+		avt_dbg(sd, "VIDIOC_R_I2C\n");
+		i2c_reg = (struct v4l2_i2c *)arg;
+		i2c_reg_buf = kzalloc(i2c_reg->num_bytes, GFP_KERNEL);
+		if (!i2c_reg_buf)
+			return -ENOMEM;
+
+		ret = i2c_read(client, i2c_reg->register_address, i2c_reg->register_size,
+				i2c_reg->num_bytes, i2c_reg_buf);
+
+		if (ret < 0)
+			avt_err(sd, " I2C read failed. addr=0x%04X, num_bytes=%d, ret=%d\n", i2c_reg->register_address, i2c_reg->num_bytes, ret);
+		else
+		{
+			ret = copy_to_user((char *)i2c_reg->ptr_buffer, i2c_reg_buf, i2c_reg->num_bytes);
+
+			if (ret == 0)
+				avt_dbg(sd, " I2C read success. addr=0x%04X, num_bytes=%d, ret=%d\n", i2c_reg->register_address, i2c_reg->num_bytes, ret);
+			else
+				avt_err(sd, " I2C read failed. copy_to_user failed. addr=0x%04X, num_bytes=%d, ret=%d\n", i2c_reg->register_address, i2c_reg->num_bytes, ret);
+		}
+
+		kfree(i2c_reg_buf);
+		break;
+
+	case VIDIOC_W_I2C:
+		avt_dbg(sd, "VIDIOC_W_I2C\n");
+		i2c_reg = (struct v4l2_i2c *)arg;
+
+		i2c_reg_buf = kzalloc(i2c_reg->num_bytes, GFP_KERNEL);
+		if (!i2c_reg_buf)
+			return -ENOMEM;
+
+		ret = copy_from_user(i2c_reg_buf, (char *) i2c_reg->ptr_buffer, i2c_reg->num_bytes);
+
+		ret = ioctl_gencam_i2cwrite_reg(client, i2c_reg->register_address, i2c_reg->register_size, i2c_reg->num_bytes, i2c_reg_buf);
+
+		if (ret < 0)
+		{
+			avt_err(sd, " I2C write failed. addr=0x%04X, num_bytes=%d, ret=%d\n", i2c_reg->register_address, i2c_reg->num_bytes, ret);
+		}
+		/* Check if mode (BCRM or GenCP) is changed */
+		else
+		{
+			avt_dbg(sd, " I2C write success. addr=0x%04X, num_bytes=%d, ret=%d\n", i2c_reg->register_address, i2c_reg->num_bytes, ret);
+            
+			if(i2c_reg->register_address == CCI_CHANGE_MODE_8W)
+			{
+				priv->mode = i2c_reg_buf[0] == 0 ? AVT_BCRM_MODE : AVT_GENCP_MODE;
+				set_channel_avt_cam_mode(sd, priv->mode);
+				if (priv->mode)
+					set_channel_timeout(sd, AVT_TEGRA_TIMEOUT_DISABLED);
+				else
+					set_channel_timeout(sd, CAPTURE_TIMEOUT_MS);
+			}
+		}
+
+		break;
+
+	case VIDIOC_G_I2C_CLOCK_FREQ:
+		avt_dbg(sd, "VIDIOC_G_I2C_CLOCK_FREQ\n");
+
+		i2c_clk_freq = arg;
+		*i2c_clk_freq = i2c_get_adapter_bus_clk_rate(client->adapter);
+		ret = 0;
+
+		break;
+
+	case VIDIOC_G_GENCP_BUFFER_SIZES:
+		avt_dbg(sd, "VIDIOC_G_GENCP_BUFFER_SIZE\n");
+		gencp_buf_sz = arg;
+		gencp_buf_sz->gencp_in_buffer_size = priv->gencp_reg.gencp_in_buffer_size;
+		gencp_buf_sz->gencp_out_buffer_size = priv->gencp_reg.gencp_out_buffer_size;
+		ret = 0;
+		break;
+
+	case VIDIOC_G_DRIVER_INFO:
+		avt_dbg(sd, "VIDIOC_G_DRIVER_INFO\n");
+		info = (struct v4l2_csi_driver_info *)arg;
+
+		info->id.manufacturer_id = MANUFACTURER_ID_NVIDIA;
+		info->id.soc_family_id = SOC_FAMILY_ID_TEGRA;
+		info->id.driver_id = TEGRA_DRIVER_ID_DEFAULT;
+
+		info->driver_version = (DRV_VER_MAJOR << 16) + (DRV_VER_MINOR << 8) + DRV_VER_PATCH;
+		info->driver_interface_version = (LIBCSI_DRV_SPEC_VERSION_MAJOR << 16) + (LIBCSI_DRV_SPEC_VERSION_MINOR << 8) + LIBCSI_DRV_SPEC_VERSION_PATCH;
+		info->driver_caps = AVT_DRVCAP_MMAP | AVT_DRVCAP_USRPTR;
+		info->usrptr_alignment = dma_get_cache_alignment();
+
+		ret = 0;
+		break;
+
+	case VIDIOC_G_CSI_CONFIG:
+		avt_dbg(sd, "VIDIOC_G_CSI_CONFIG\n");
+		config = (struct v4l2_csi_config *)arg;
+
+		config->lane_count = priv->numlanes;
+		config->csi_clock = priv->csi_clk_freq;
+
+		ret = 0;
+		break;
+
+	case VIDIOC_S_CSI_CONFIG:
+		avt_dbg(sd, "VIDIOC_S_CSI_CONFIG\n");
+		config = (struct v4l2_csi_config *)arg;
+
+		/* Set number of lanes */
+		priv->s_data->numlanes = config->lane_count;
+
+		ret = avt_reg_read(priv->client,
+				priv->cci_reg.bcrm_addr + BCRM_SUPPORTED_CSI2_LANE_COUNTS_8R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_8,
+				(char *) &avt_supported_lane_counts);
+		if (ret < 0) {
+			avt_err(sd, " BCRM_SUPPORTED_CSI2_LANE_COUNTS_8R: i2c read failed (%d)\n", ret);
+			ret = -1;
+			break;
+		}
+		if(!(test_bit(priv->s_data->numlanes - 1, (const long *)(&avt_supported_lane_counts)))) {
+			avt_err(sd, " requested number of lanes (%u) not supported by this camera!\n",
+					priv->s_data->numlanes);
+			ret = -1;
+			break;
+		}
+		ret = avt_reg_write(priv->client,
+				priv->cci_reg.bcrm_addr + BCRM_CSI2_LANE_COUNT_8RW,
+				priv->s_data->numlanes);
+		if (ret < 0){
+			avt_err(sd, " i2c write failed (%d)\n", ret);
+			ret = -1;
+			break;
+		}
+		priv->numlanes = priv->s_data->numlanes;
+
+		/* Set CSI clock frequency */
+
+		ret = avt_reg_read(priv->client,
+				priv->cci_reg.bcrm_addr + BCRM_CSI2_LANE_COUNT_8RW,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_32,
+				(char *) &avt_min_clk);
+	
+		if (ret < 0) {
+			avt_err(sd, " BCRM_CSI2_LANE_COUNT_8RW: i2c read failed (%d)\n", ret);
+			ret = -1;
+			break;
+		}
+	
+		ret = avt_reg_read(priv->client,
+				priv->cci_reg.bcrm_addr + BCRM_CSI2_CLOCK_MAX_32R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_32,
+				(char *) &avt_max_clk);
+	
+		if (ret < 0) {
+			avt_err(sd, " BCRM_CSI2_CLOCK_MAX_32R: i2c read failed (%d)\n", ret);
+			ret = -1;
+			break;
+		}
+
+		if (common_range(avt_min_clk, avt_max_clk, 1,
+				config->csi_clock, config->csi_clock, 1,
+				&common_min_clk, &common_max_clk, &common_inc_clk)
+				== false) {
+			avt_err(sd, " clock value does not fit the supported frequency range!\n");
+			return -EINVAL;
+		}
+
+		CLEAR(i2c_reg_address);
+		clk = config->csi_clock;
+		swapbytes(&clk, AV_CAM_DATA_SIZE_32);
+		i2c_reg_address = priv->cci_reg.bcrm_addr + BCRM_CSI2_CLOCK_32RW;
+		i2c_reg_size = AV_CAM_REG_SIZE;
+		i2c_reg_count = AV_CAM_DATA_SIZE_32;
+		i2c_reg_buf = (char *) &clk;
+		ret = ioctl_gencam_i2cwrite_reg(priv->client, i2c_reg_address, i2c_reg_size,
+						i2c_reg_count, i2c_reg_buf);
+		if (ret < 0) {
+			avt_err(sd, " BCRM_CSI2_CLOCK_32RW: i2c write failed (%d)\n", ret);
+			ret = -1;
+			break;
+		}
+
+		/* Read back CSI clock frequency */
+		ret = avt_reg_read(priv->client,
+				priv->cci_reg.bcrm_addr + BCRM_CSI2_CLOCK_32RW,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_32,
+				(char *) &priv->csi_clk_freq);
+
+		if (ret < 0) {
+			avt_err(sd, "BCRM_CSI2_CLOCK_32RW: i2c read failed (%d)\n", ret);
+			ret = -1;
+			break;
+		}
+		ret = 0;
+		break;
+
+	default:
+		break;
+	}
+
+	return ret;
+}
+
+
+/* --------------- VIDEO OPS --------------- */
+
+static int avt_csi2_g_mbus_config(struct v4l2_subdev *sd,
+		struct v4l2_mbus_config *cfg)
+{
+	cfg->type = V4L2_MBUS_CSI2;
+
+	cfg->flags = V4L2_MBUS_CSI2_CONTINUOUS_CLOCK;
+	cfg->flags |= V4L2_MBUS_CSI2_2_LANE; /* XXX wierd */
+
+	return 0;
+}
+
+static int avt_set_param(struct i2c_client *client,
+			uint32_t id, uint32_t value)
+{
+	struct avt_ctrl ct;
+
+	CLEAR(ct);
+	ct.id = id;
+	ct.value0 = value;
+
+	return avt_ctrl_send(client, &ct);
+}
+
+static int avt_get_param(struct i2c_client *client,
+			uint32_t id, uint32_t *value)
+{
+	struct avt_ctrl ct;
+	int ret;
+
+	CLEAR(ct);
+	ct.id = id;
+	ret = avt_ctrl_send(client, &ct);
+
+	if (ret < 0)
+		return ret;
+
+	*value = ct.value0;
+
+	return 0;
+}
+
+static int auto_value_update_thread(void *param)
+{
+    struct avt_csi2_priv *priv = (struct avt_csi2_priv *)param;
+    struct i2c_client *client = priv->client;
+    struct v4l2_subdev *sd = priv->subdev;
+    struct v4l2_ctrl_handler *handler = sd->ctrl_handler;
+    struct v4l2_ctrl *exposure_ctrl,*exposure_auto_ctrl,*gain_ctrl,*gain_auto_ctrl,*awb_ctrl,*red_balance_ctrl,
+			*blue_balance_ctrl;
+    int ret;
+
+    exposure_ctrl = v4l2_ctrl_find(handler,V4L2_CID_EXPOSURE);
+    exposure_auto_ctrl = v4l2_ctrl_find(handler,V4L2_CID_EXPOSURE_AUTO);
+    gain_ctrl = v4l2_ctrl_find(handler,V4L2_CID_GAIN);
+    gain_auto_ctrl = v4l2_ctrl_find(handler,V4L2_CID_AUTOGAIN);
+    awb_ctrl = v4l2_ctrl_find(handler,V4L2_CID_AUTO_WHITE_BALANCE);
+    red_balance_ctrl = v4l2_ctrl_find(handler,V4L2_CID_RED_BALANCE);
+	blue_balance_ctrl = v4l2_ctrl_find(handler,V4L2_CID_BLUE_BALANCE);
+
+
+    while (!kthread_should_stop())
+    {
+        atomic_set(&priv->force_value_update, 0);
+
+        if (exposure_auto_ctrl != NULL && exposure_ctrl != NULL)
+        {
+            int exposure_auto = v4l2_ctrl_g_ctrl(exposure_auto_ctrl);
+
+            if (V4L2_EXPOSURE_AUTO == exposure_auto)
+            {
+                uint64_t exposure_time;
+
+                ret = avt_reg_read(client,
+                                   priv->cci_reg.bcrm_addr + BCRM_EXPOSURE_TIME_64RW,
+                                   AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+                                   (char *) &exposure_time);
+
+                if (ret < 0)
+                {
+                    avt_warn(sd,"Automatic exposure time update failed");
+                }
+
+                avt_dbg(sd,"Exposure auto update");
+
+                priv->ignore_control_write = true;
+                v4l2_ctrl_s_ctrl_int64(exposure_ctrl,exposure_time);
+                priv->ignore_control_write = false;
+            }
+        }
+
+        if (gain_auto_ctrl != NULL && gain_ctrl != NULL)
+        {
+            int auto_gain_enabled = v4l2_ctrl_g_ctrl(gain_auto_ctrl);
+
+            if (auto_gain_enabled)
+            {
+                uint64_t gain;
+
+                ret = avt_reg_read(client,
+                                   priv->cci_reg.bcrm_addr + BCRM_GAIN_64RW,
+                                   AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+                                   (char *) &gain);
+
+                if (ret < 0)
+                {
+                    avt_warn(sd,"Automatic gain update failed");
+                }
+
+                avt_dbg(sd,"Gain auto update");
+
+                priv->ignore_control_write = true;
+                v4l2_ctrl_s_ctrl_int64(gain_ctrl,gain);
+                priv->ignore_control_write = false;
+            }
+        }
+
+        if (awb_ctrl != NULL)
+        {
+            int awb_enabled = v4l2_ctrl_g_ctrl(awb_ctrl);
+
+            if (awb_enabled)
+            {
+                if (red_balance_ctrl != NULL)
+                {
+                    uint64_t red_balance;
+
+                    ret = avt_reg_read(client,
+                                       priv->cci_reg.bcrm_addr + BCRM_RED_BALANCE_RATIO_64RW,
+                                       AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+                                       (char *) &red_balance);
+
+                    if (ret < 0)
+                    {
+                        avt_warn(sd,"Red balance update failed");
+                    }
+
+                    avt_dbg(sd,"Red balance update");
+
+                    priv->ignore_control_write = true;
+                    v4l2_ctrl_s_ctrl_int64(red_balance_ctrl,red_balance);
+                    priv->ignore_control_write = false;
+                }
+
+				if (blue_balance_ctrl != NULL)
+				{
+					uint64_t blue_balance;
+
+					ret = avt_reg_read(client,
+									   priv->cci_reg.bcrm_addr + BCRM_BLUE_BALANCE_RATIO_64RW,
+									   AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+									   (char *) &blue_balance);
+
+					if (ret < 0)
+					{
+						avt_warn(sd,"Blue balance update failed");
+					}
+
+					avt_dbg(sd,"Blue balance update");
+
+					priv->ignore_control_write = true;
+					v4l2_ctrl_s_ctrl_int64(blue_balance_ctrl,blue_balance);
+					priv->ignore_control_write = false;
+				}
+			}
+        }
+
+        if (0 == priv->value_update_interval)
+        {
+            wait_event_interruptible(priv->value_update_wq, kthread_should_stop() || atomic_read(&priv->force_value_update));
+        }
+        else
+        {
+            wait_event_interruptible_timeout(priv->value_update_wq, kthread_should_stop() || atomic_read(&priv->force_value_update), msecs_to_jiffies(priv->value_update_interval));
+        }
+    }
+
+    return 0;
+}
+
+static bool avt_mode_reinit_required(struct avt_csi2_priv *priv)
+{
+    if (priv->csi_fixed_lanes > 0) {
+      return priv->numlanes != priv->csi_fixed_lanes;
+    }
+    return priv->numlanes != priv->s_data->numlanes;
+}
+
+static void avt_disable_stream_ctrls(struct avt_csi2_priv *priv,bool disabled)
+{
+    int i;
+
+    for (i = 0; i < AVT_MAX_CTRLS;i++)
+    {
+        if (priv->ctrls[i] != NULL)
+        {
+            if (priv->ctrls[i]->priv != NULL)
+            {
+                struct avt_ctrl_mapping *mapping = priv->ctrls[i]->priv;
+
+                if (mapping->disabled_while_streaming)
+                {
+                    v4l2_ctrl_grab(priv->ctrls[i],disabled);
+                }
+            }
+        }
+    }
+}
+
+/* Start/Stop streaming from the device */
+static int avt_csi2_s_stream(struct v4l2_subdev *sd, int enable)
+{
+	struct i2c_client *client = v4l2_get_subdevdata(sd);
+	struct avt_csi2_priv *priv = avt_get_priv(sd);
+    struct v4l2_ctrl *trigger_sw_ctrl;
+	int ret = 0;
+
+    trigger_sw_ctrl = v4l2_ctrl_find(sd->ctrl_handler,V4L2_CID_TRIGGER_SOFTWARE);
+
+
+    if (enable) {
+		if (avt_mode_reinit_required(priv)) {
+			ret = avt_init_mode(sd);
+			if (ret < 0)
+				return ret;
+		}
+
+        if (priv->mode == AVT_BCRM_MODE) {
+            if (MEDIA_BUS_FMT_CUSTOM == priv->mbus_fmt_code)
+                return -EINVAL;
+
+            if (trigger_sw_ctrl)
+                v4l2_ctrl_activate(trigger_sw_ctrl,true);
+
+            avt_disable_stream_ctrls(priv,true);
+
+            ret = avt_set_param(client, V4L2_AV_CSI2_STREAMON_W, 1);
+
+            priv->value_update_thread = kthread_run(auto_value_update_thread, priv, "avt_csi2");
+        }
+	} else if (priv->mode == AVT_BCRM_MODE) {
+		ret = avt_set_param(client, V4L2_AV_CSI2_STREAMOFF_W, 1);
+		if (priv->trig_thread)
+            kthread_stop(priv->trig_thread);
+
+        if (priv->value_update_thread)
+        {
+            wake_up_all(&priv->value_update_wq);
+            kthread_stop(priv->value_update_thread);
+            priv->value_update_thread = NULL;
+        }
+
+        if (trigger_sw_ctrl)
+            v4l2_ctrl_activate(trigger_sw_ctrl,false);
+
+        avt_disable_stream_ctrls(priv,false);
+	}
+
+	if (ret < 0)
+		return ret;
+
+	priv->stream_on = enable ? true : false;
+
+	return 0;
+}
+
+static int avt_csi2_get_fmt(struct v4l2_subdev *sd,
+		struct v4l2_subdev_pad_config *cfg,
+		struct v4l2_subdev_format *format)
+{
+	int ret = 0;
+	uint32_t val = 0;
+
+	struct i2c_client *client = v4l2_get_subdevdata(sd);
+
+	if (format->pad != 0)
+		return -EINVAL;
+
+	ret = avt_get_param(client, V4L2_AV_CSI2_WIDTH_R, &val);
+	if (ret < 0)
+		return ret;
+	format->format.width = val;
+
+	ret = avt_get_param(client, V4L2_AV_CSI2_HEIGHT_R, &val);
+	if (ret < 0)
+		return ret;
+	format->format.height = val;
+
+	ret = avt_get_param(client, V4L2_AV_CSI2_PIXELFORMAT_R, &val);
+	if (ret < 0)
+		return ret;
+	format->format.code = val;
+
+	/* Hardcoded default format */
+	format->format.field = V4L2_FIELD_NONE;
+	format->format.colorspace = V4L2_COLORSPACE_SRGB;
+
+	return 0;
+}
+
+static int avt_frm_supported(int wmin, int wmax, int ws,
+				int hmin, int hmax, int hs,
+				int w, int h)
+{
+	if (
+		w > wmax || w < wmin ||
+		h > hmax || h < hmin ||
+		(h - hmin) % hs != 0 ||
+		(w - wmin) % ws != 0
+	)
+		return -EINVAL;
+
+	return 0;
+}
+
+static int avt_csi2_try_fmt(struct v4l2_subdev *sd,
+		struct v4l2_subdev_pad_config *cfg,
+		struct v4l2_subdev_format *format)
+{
+	struct avt_csi2_priv *priv = avt_get_priv(sd);
+	int ret = 0;
+
+	ret = avt_frm_supported(
+			priv->frmp.minw, priv->frmp.maxw, priv->frmp.sw,
+			priv->frmp.minh, priv->frmp.maxh, priv->frmp.sh,
+			format->format.width, format->format.height);
+
+	if (ret < 0) {
+		//avt_err(sd, "Not supported format!\n");
+		//return ret;
+        format->format.width = priv->frmp.r.width;
+        format->format.height  = priv->frmp.r.height;
+	}
+
+	return 0;
+}
+
+static int avt_csi2_set_fmt(struct v4l2_subdev *sd,
+		struct v4l2_subdev_pad_config *cfg,
+		struct v4l2_subdev_format *format)
+{
+	struct i2c_client *client = v4l2_get_subdevdata(sd);
+	struct avt_csi2_priv *priv = avt_get_priv(sd);
+	struct v4l2_subdev_selection sel;
+	int ret;
+
+	// changing the resolution is not allowed with VIDIOC_S_FMT
+	if (priv->mode == AVT_BCRM_MODE &&
+		(format->format.width != priv->frmp.r.width ||
+		 format->format.height != priv->frmp.r.height))
+	{
+		format->format.width = priv->frmp.r.width;
+        format->format.height  = priv->frmp.r.height;
+	}
+
+	format->format.colorspace = V4L2_COLORSPACE_SRGB;
+	format->format.field = V4L2_FIELD_NONE;
+
+	if (format->which == V4L2_SUBDEV_FORMAT_TRY) {
+		if (priv->mode == AVT_BCRM_MODE)
+			return avt_csi2_try_fmt(sd, cfg, format);
+		else
+			return 0;
+	}
+
+
+    priv->mbus_fmt_code = format->format.code;
+
+	if (priv->mode != AVT_BCRM_MODE)
+		return 0;
+	sel.target = V4L2_SEL_TGT_CROP;
+	sel.r = priv->frmp.r;
+
+	/* Save format to private data only if
+	 * set_param succeded
+	 */
+	ret = avt_set_param(client, V4L2_AV_CSI2_PIXELFORMAT_W,
+		format->format.code);
+	if(ret < 0)
+		return ret;
+
+	avt_set_selection(sd, NULL, &sel);
+
+	if (priv->stride_align_enabled)
+		set_channel_stride_align_for_format(sd, format->format.code);
+	else
+		set_channel_stride_align(sd, 1);
+
+	format->format.width = priv->frmp.r.width;
+	return 0;
+}
+
+static uint16_t avt_mbus_formats[] = {
+	/* RAW 8 */
+	MEDIA_BUS_FMT_Y8_1X8,
+	MEDIA_BUS_FMT_SBGGR8_1X8,
+	MEDIA_BUS_FMT_SGBRG8_1X8,
+	MEDIA_BUS_FMT_SGRBG8_1X8,
+	MEDIA_BUS_FMT_SRGGB8_1X8,
+        
+	/* RAW10 */
+	MEDIA_BUS_FMT_Y10_1X10,
+	MEDIA_BUS_FMT_SBGGR10_1X10,
+	MEDIA_BUS_FMT_SGBRG10_1X10,
+	MEDIA_BUS_FMT_SGRBG10_1X10,
+	MEDIA_BUS_FMT_SRGGB10_1X10, 
+
+	/* RAW12 */
+	MEDIA_BUS_FMT_Y12_1X12,
+	MEDIA_BUS_FMT_SRGGB12_1X12,
+	MEDIA_BUS_FMT_SGRBG12_1X12,
+	MEDIA_BUS_FMT_SGBRG12_1X12,
+	MEDIA_BUS_FMT_SBGGR12_1X12,
+	/* RGB565 */
+	MEDIA_BUS_FMT_RGB565_1X16,
+	/* RGB888 */
+	MEDIA_BUS_FMT_RGB888_1X24,
+	MEDIA_BUS_FMT_BGR888_1X24,
+	/* YUV422 */
+	MEDIA_BUS_FMT_VYUY8_2X8,
+	/* CUSTOM TP31 */
+	//MEDIA_BUS_FMT_CUSTOM,
+};
+
+/* These formats are hidden from VIDIOC_ENUM_FMT ioctl */
+static uint16_t avt_hidden_mbus_formats[] = {
+/*KHO	
+	MEDIA_BUS_FMT_Y10_1X10,
+	MEDIA_BUS_FMT_Y12_1X12,
+
+        MEDIA_BUS_FMT_SRGGB12_1X12,
+	MEDIA_BUS_FMT_SGRBG12_1X12,
+	MEDIA_BUS_FMT_SGBRG12_1X12,
+	MEDIA_BUS_FMT_SBGGR12_1X12,
+        */
+};
+
+//static int32_t avt_avail_formats[ARRAY_SIZE(avt_mbus_formats)];
+
+static bool avt_mbus_fmt_is_hidden(uint16_t mbus_fmt)
+{
+	int i;
+	for(i = 0; i < ARRAY_SIZE(avt_hidden_mbus_formats); i++)
+		if(avt_hidden_mbus_formats[i] == mbus_fmt)
+			return true;
+
+	return false;
+}
+
+static void avt_init_avail_formats(struct v4l2_subdev *sd)
+{
+	struct i2c_client *client = v4l2_get_subdevdata(sd);
+	struct avt_csi2_priv *priv = avt_get_priv(sd);
+
+	int fmt_iter = 0;
+	int i;
+	int32_t *avail_fmts;
+
+	avail_fmts = kmalloc(sizeof(int32_t)*ARRAY_SIZE(avt_mbus_formats), GFP_KERNEL);
+
+	for(i = 0; i < ARRAY_SIZE(avt_mbus_formats); i++){
+		if(avt_check_fmt_available(client, avt_mbus_formats[i])
+		   && !avt_mbus_fmt_is_hidden(avt_mbus_formats[i])) {
+			avail_fmts[fmt_iter++] = avt_mbus_formats[i];
+		}
+	}
+
+	avail_fmts[fmt_iter] = -EINVAL;
+
+	priv->available_fmts = avail_fmts;
+	priv->available_fmts_cnt = fmt_iter+1;;
+}
+
+static int avt_csi2_enum_mbus_code(struct v4l2_subdev *sd,
+				struct v4l2_subdev_pad_config *cfg,
+				struct v4l2_subdev_mbus_code_enum *code)
+{
+	struct avt_csi2_priv *priv = avt_get_priv(sd);
+
+	avt_dbg(sd, "()\n");
+	if (code->index >= priv->available_fmts_cnt)
+		return -EINVAL;
+
+	code->code = priv->available_fmts[code->index];
+	if (code->code == -EINVAL)
+		return -EINVAL;
+
+	return 0;
+}
+
+static int avt_csi2_enum_framesizes(struct v4l2_subdev *sd,
+				struct v4l2_subdev_pad_config *cfg,
+				struct v4l2_subdev_frame_size_enum *fse)
+{
+	struct avt_csi2_priv *priv = avt_get_priv(sd);
+	bool format_present = false;
+	int i;
+
+	avt_dbg(sd, "()\n");
+
+	fse->min_width = fse->max_width = priv->frmp.r.width;
+	fse->min_height = fse->max_height = priv->frmp.r.height;
+
+	for (i = 0; i < ARRAY_SIZE(avt_mbus_formats); i++)
+		if (avt_mbus_formats[i] == fse->code)
+			format_present = true;
+
+	if (fse->index != 0 || format_present == false)
+		return -EINVAL;
+
+	return 0;
+}
+
+
+static int read_framerate(struct v4l2_subdev *sd, struct v4l2_fract *tpf) {
+	struct i2c_client *client = v4l2_get_subdevdata(sd);
+	struct camera_common_data *s_data = to_camera_common_data(&client->dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+    u8 framerate_enable;
+	u64 framerate;
+
+	int ret = avt_reg_read(client,
+                       priv->cci_reg.bcrm_addr +
+                       BCRM_ACQUISITION_FRAME_RATE_ENABLE_8RW,
+                       AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_8,
+                       (char *) &framerate_enable);
+	if (ret < 0) {
+        dev_err(&client->dev, "read framerate_enable failed\n");
+        return ret;
+	}
+	
+    if(framerate_enable == 1) {
+        ret = avt_reg_read(client,
+                           priv->cci_reg.bcrm_addr +
+                           BCRM_ACQUISITION_FRAME_RATE_64RW,
+                           AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+                           (char *) &framerate);
+        if (ret < 0) {
+            dev_err(&client->dev, "read frameinterval failed\n");
+            return ret;
+        }
+
+        /* Translate frequency to timeperframe
+        * by inverting the fraction
+        */
+        tpf->numerator = FRAQ_NUM;
+        tpf->denominator = (framerate * FRAQ_NUM) / UHZ_TO_HZ;
+    } else {
+        tpf->numerator = FRAQ_NUM;
+        tpf->denominator = 0;
+    }
+
+    return 0;
+}
+
+
+static int avt_csi2_enum_frameintervals(struct v4l2_subdev *sd,
+				struct v4l2_subdev_pad_config *cfg,
+				struct v4l2_subdev_frame_interval_enum *fie)
+{
+	struct i2c_client *client = v4l2_get_subdevdata(sd);
+	struct camera_common_data *s_data = to_camera_common_data(&client->dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+	int ret;
+	u64 min_framerate,max_framerate,framerate_step,tmp;
+
+	if(fie->index > 0)
+		return -EINVAL;
+
+    if (fie->width != priv->frmp.r.width || fie->height != priv->frmp.r.height)
+    {
+        return -EINVAL;
+    }
+
+	ret = avt_reg_read(client,
+					   priv->cci_reg.bcrm_addr +
+					   BCRM_ACQUISITION_FRAME_RATE_INC_64R,
+					   AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+					   (char *) &framerate_step);
+	if (ret < 0) {
+		dev_err(&client->dev, "read frameinterval inc failed\n");
+		return ret;
+	}
+
+	if (framerate_step) {
+		fie->type = V4L2_SUBDEV_FRMIVAL_TYPE_STEPWISE;
+		fie->step_interval.numerator = FRAQ_NUM;
+		fie->step_interval.denominator = (framerate_step * FRAQ_NUM) / UHZ_TO_HZ;
+	}
+	else {
+		fie->type = V4L2_SUBDEV_FRMIVAL_TYPE_CONTINUOUS;
+	}
+
+	ret = avt_reg_read(client,
+					   priv->cci_reg.bcrm_addr +
+					   BCRM_ACQUISITION_FRAME_RATE_MIN_64R,
+					   AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+					   (char *) &min_framerate);
+	if (ret < 0) {
+		dev_err(&client->dev, "read min frameinterval failed\n");
+		return ret;
+	}
+
+	ret = avt_reg_read(client,
+					   priv->cci_reg.bcrm_addr +
+					   BCRM_ACQUISITION_FRAME_RATE_MAX_64R,
+					   AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+					   (char *) &max_framerate);
+	if (ret < 0) {
+		dev_err(&client->dev, "read max frameinterval failed\n");
+		return ret;
+	}
+
+    tmp = min_framerate * FRAQ_NUM;
+
+    //Check if result of division will be between 0 and 1, if it is so increase numerator
+    if (tmp < UHZ_TO_HZ) {
+        fie->max_interval.numerator = UHZ_TO_HZ;
+        fie->max_interval.denominator = min_framerate;
+    }
+    else {
+        fie->max_interval.numerator = FRAQ_NUM;
+        fie->max_interval.denominator = tmp / UHZ_TO_HZ;
+    }
+
+    tmp = max_framerate * FRAQ_NUM;
+
+    //Check if result of division will be between 0 and 1, if it is so increase numerator
+    if (tmp < UHZ_TO_HZ) {
+        fie->max_interval.numerator = UHZ_TO_HZ;
+        fie->max_interval.denominator = max_framerate;
+    }
+    else {
+        fie->interval.numerator = FRAQ_NUM;
+        fie->interval.denominator = tmp / UHZ_TO_HZ;
+    }
+
+
+	return 0;
+}
+
+
+static __s32 convert_s_ctrl(__s32 val, __s32 min, __s32 max, __s32 step)
+{
+	int32_t valuedown = 0, valueup = 0;
+
+	if (val > max)
+		val = max;
+
+	else if (val < min)
+		val = min;
+
+	valuedown = val - ((val - min) % step);
+	valueup = valuedown + step;
+
+	if (val >= 0) {
+		if (((valueup - val) <= (val - valuedown)) && (valueup <= max))
+			val = valueup;
+		else
+			val = valuedown;
+	} else {
+		if (((valueup - val) < (val - valuedown)) && (valueup <= max))
+			val = valueup;
+		else
+			val = valuedown;
+	}
+
+	return val;
+}
+
+static __s64 convert_s_ctrl64(struct v4l2_query_ext_ctrl* qctrl_ext, __s64 val)
+{
+	__s64 valuedown = 0, valueup = 0;
+	__s64 step=(__s64)qctrl_ext->step;
+	if (val > qctrl_ext->maximum)
+		val = qctrl_ext->maximum;
+
+	else if (val < qctrl_ext->minimum)
+		val = qctrl_ext->minimum;
+
+	valuedown = val - ((val - qctrl_ext->minimum) % step);
+	valueup = valuedown + step;
+	if (val >= 0) {
+		if (((valueup - val) <= (val - valuedown)) && (valueup <= qctrl_ext->maximum))
+			val = valueup;
+		else
+			val = valuedown;
+	} else {
+		if (((valueup - val) < (val - valuedown)) && (valueup <= qctrl_ext->maximum))
+			val = valueup;
+		else
+			val = valuedown;
+	}
+	return val;
+}
+
+
+static int read_feature_register(struct v4l2_subdev *sd, union bcrm_feature_reg *features) {
+	struct i2c_client *client = v4l2_get_subdevdata(sd);
+	struct camera_common_data *s_data = to_camera_common_data(&client->dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+
+	return avt_reg_read(client,
+			priv->cci_reg.bcrm_addr + BCRM_FEATURE_INQUIRY_64R,
+			AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+			(char *) features);
+}
+
+
+static int ioctl_queryctrl(struct v4l2_subdev *sd,
+		struct v4l2_queryctrl *qctrl)
+{
+	struct i2c_client *client = v4l2_get_subdevdata(sd);
+	struct camera_common_data *s_data = to_camera_common_data(&client->dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+
+	u32 value = 0;
+	int ret;
+	union bcrm_feature_reg feature_inquiry_reg;
+
+	avt_dbg(sd, "\n");
+
+	ret = read_feature_register(sd, &feature_inquiry_reg);
+	if (ret < 0) {
+		avt_err(sd, "BCRM_FEATURE_INQUIRY_64R: i2c read failed (%d)\n", ret);
+	}
+
+	switch (qctrl->id) {
+
+	/* BLACK LEVEL is deprecated and thus we use Brightness */
+	case V4L2_CID_BRIGHTNESS:
+		avt_dbg(sd, "case V4L2_CID_BRIGHTNESS\n");
+
+		if (!feature_inquiry_reg.feature_inq.black_level_avail) {
+			avt_info(sd, "control 'Brightness' not supported by firmware\n");
+			qctrl->flags = V4L2_CTRL_FLAG_DISABLED;
+			return 0;
+		}
+
+		/* reading the current Black Level value */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_BLACK_LEVEL_32RW,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_32,
+				(char *) &value);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_BLACK_LEVEL_32RW: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->default_value = value;
+
+		/* reading the Minimum Black Level */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_BLACK_LEVEL_MIN_32R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_32,
+				(char *) &value);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_BLACK_LEVEL_MIN_32R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->minimum = value;
+
+		/* reading the Maximum Black Level */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_BLACK_LEVEL_MAX_32R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_32,
+				(char *) &value);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_BLACK_LEVEL_MAX_32R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->maximum = value;
+
+		/* reading the Black Level step increment */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_BLACK_LEVEL_INC_32R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_32,
+				(char *) &value);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_BLACK_LEVEL_INC_32R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->step = value;
+
+		if (qctrl->minimum > qctrl->maximum) {
+			avt_err(sd, "Brightness: min > max! (%d > %d)\n",
+					qctrl->minimum, qctrl->maximum);
+			return -EINVAL;
+		}
+		if (qctrl->step <= 0) {
+			avt_err(sd, "Brightness: non-positive step value (%d)!\n",
+					qctrl->step);
+			return -EINVAL;
+		}
+
+		qctrl->type = V4L2_CTRL_TYPE_INTEGER;
+		strcpy(qctrl->name, "Brightness");
+		break;
+
+	case V4L2_CID_EXPOSURE_AUTO:
+
+		avt_dbg(sd, "case V4L2_CID_EXPOSURE_AUTO\n");
+
+		if (!feature_inquiry_reg.feature_inq.exposure_auto) {
+			avt_info(sd, "control 'Exposure Auto' not supported by firmware\n");
+			qctrl->flags = V4L2_CTRL_FLAG_DISABLED;
+			return 0;
+		}
+
+		/* reading the current exposure auto value */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_EXPOSURE_AUTO_8RW,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_8,
+				(char *) &value);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_EXPOSURE_AUTO_8RW: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		if (value == 2)
+			/* continous mode, Refer BCRM doc */
+			qctrl->default_value = V4L2_EXPOSURE_AUTO;
+		else
+			/* false (OFF) */
+			qctrl->default_value = V4L2_EXPOSURE_MANUAL;
+
+		qctrl->minimum = 0;
+		qctrl->step = 0;
+		qctrl->maximum = 1;
+		qctrl->type = V4L2_CTRL_TYPE_MENU;
+
+		strcpy(qctrl->name, "Exposure Auto");
+		break;
+
+	case V4L2_CID_AUTOGAIN:
+		avt_dbg(sd, "case V4L2_CID_AUTOGAIN\n");
+
+		if (!feature_inquiry_reg.feature_inq.gain_auto) {
+			avt_info(sd, "control 'Auto Gain' not supported by firmware\n");
+			qctrl->flags = V4L2_CTRL_FLAG_DISABLED;
+			return 0;
+		}
+
+		/* reading the Auto Gain value */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_GAIN_AUTO_8RW,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_8,
+				(char *) &value);
+
+		if (ret < 0) {
+			avt_err(sd, "BCRM_GAIN_AUTO_8RW: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		if (value == 2)
+			/* true (ON) for continous mode, Refer BCRM doc */
+			qctrl->default_value = true;
+		else
+			/* false (OFF) */
+			qctrl->default_value = false;
+
+		qctrl->minimum = 0;
+		qctrl->step = 1;
+		qctrl->maximum = 1;
+		qctrl->type = V4L2_CTRL_TYPE_BOOLEAN;
+
+		strcpy(qctrl->name, "Auto Gain");
+		break;
+
+	case V4L2_CID_HFLIP:
+		avt_dbg(sd, "case V4L2_CID_HFLIP\n");
+
+		if (!feature_inquiry_reg.feature_inq.reverse_x_avail) {
+			avt_info(sd, "control 'Reversing X (Horizantal Flip)' not supported by firmware\n");
+			qctrl->flags = V4L2_CTRL_FLAG_DISABLED;
+			return 0;
+		}
+
+		/* reading the Reverse X value */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_IMG_REVERSE_X_8RW,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_8,
+				(char *) &value);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_IMG_REVERSE_X_8RW: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->default_value = value;
+
+		qctrl->minimum = 0;
+		qctrl->step = qctrl->maximum = 1;
+		qctrl->type = V4L2_CTRL_TYPE_BOOLEAN;
+		strcpy(qctrl->name, "Reverse X");
+
+		break;
+
+	case V4L2_CID_VFLIP:
+		avt_dbg(sd, "case V4L2_CID_VFLIP\n");
+		if (!feature_inquiry_reg.feature_inq.reverse_y_avail) {
+			avt_info(sd, "control 'Reversing Y (Vertical Flip)' not supported by firmware\n");
+			qctrl->flags = V4L2_CTRL_FLAG_DISABLED;
+			return 0;
+		}
+
+		/* reading the Reverse Y value */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_IMG_REVERSE_Y_8RW,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_8,
+				(char *) &value);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_IMG_REVERSE_Y_8RW: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->default_value = value;
+
+		qctrl->minimum = 0;
+		qctrl->step = qctrl->maximum = 1;
+		qctrl->type = V4L2_CTRL_TYPE_BOOLEAN;
+		strcpy(qctrl->name, "Reverse Y");
+
+		break;
+
+	case V4L2_CID_CONTRAST:
+		avt_dbg(sd, "case V4L2_CID_CONTRAST\n");
+
+		if (!feature_inquiry_reg.feature_inq.contrast_avail) {
+			avt_info(sd, "control 'Contrast' not supported by firmware\n");
+			qctrl->flags = V4L2_CTRL_FLAG_DISABLED;
+			return 0;
+		}
+
+		/* reading the Contrast value */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_CONTRAST_VALUE_32RW,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_32,
+				(char *) &value);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_CONTRAST_VALUE_32RW: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->default_value = value;
+
+		/* reading the Minimum Contrast */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_CONTRAST_VALUE_MIN_32R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_32,
+				(char *) &value);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_CONTRAST_VALUE_MIN_32R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->minimum = value;
+
+		/* reading the Maximum Contrast */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_CONTRAST_VALUE_MAX_32R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_32,
+				(char *) &value);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_CONTRAST_VALUE_MAX_32R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->maximum = value;
+
+		/* reading the Contrast step increment */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr +
+				BCRM_CONTRAST_VALUE_INC_32R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_32,
+				(char *) &value);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_CONTRAST_VALUE_INC_32R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->step = value;
+
+		qctrl->type = V4L2_CTRL_TYPE_INTEGER;
+
+		if (qctrl->minimum > qctrl->maximum) {
+			avt_err(sd, "Contrast: min > max! (%d > %d)\n",
+					qctrl->minimum, qctrl->maximum);
+			return -EINVAL;
+		}
+		if (qctrl->step <= 0) {
+			avt_err(sd, "Contrast: non-positive step value (%d)!\n",
+					qctrl->step);
+			return -EINVAL;
+		}
+
+		strcpy(qctrl->name, "Contrast");
+		break;
+
+	case V4L2_CID_AUTO_WHITE_BALANCE:
+		avt_dbg(sd, "case V4L2_CID_AUTO_WHITE_BALANCE\n");
+
+		if (!feature_inquiry_reg.feature_inq.white_balance_auto_avail) {
+			avt_info(sd, "control 'White balance Auto' not supported by firmware\n");
+			qctrl->flags = V4L2_CTRL_FLAG_DISABLED;
+			return 0;
+		}
+
+		/* reading the White balance auto value */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_WHITE_BALANCE_AUTO_8RW,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_8,
+				(char *) &value);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_WHITE_BALANCE_AUTO_8RW: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		if (value == 2)
+			/* true (ON) */
+			qctrl->default_value = true;
+		else
+			/* false (OFF) */
+			qctrl->default_value = false;
+
+		qctrl->minimum = 0;
+		qctrl->step = 1;
+		qctrl->maximum = 1;
+		qctrl->type = V4L2_CTRL_TYPE_BOOLEAN;
+
+		strcpy(qctrl->name, "White Balance Auto");
+		break;
+
+	case V4L2_CID_DO_WHITE_BALANCE:
+		avt_dbg(sd, "case V4L2_CID_DO_WHITE_BALANCE\n");
+
+		if (!feature_inquiry_reg.feature_inq.white_balance_avail) {
+			avt_info(sd, "control 'White balance' not supported by firmware\n");
+			qctrl->flags = V4L2_CTRL_FLAG_DISABLED;
+			return 0;
+		}
+
+		/* reading the White balance auto reg */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_WHITE_BALANCE_AUTO_8RW,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_8,
+				(char *) &value);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_WHITE_BALANCE_AUTO_8RW: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->default_value = 0;
+		qctrl->minimum = 0;
+		qctrl->step = 0;
+		qctrl->maximum = 0;
+		qctrl->type = V4L2_CTRL_TYPE_BUTTON;
+
+		strcpy(qctrl->name, "White Balance");
+		break;
+
+	case V4L2_CID_SATURATION:
+		avt_dbg(sd, "case V4L2_CID_SATURATION\n");
+
+		if (!feature_inquiry_reg.feature_inq.saturation_avail) {
+			avt_info(sd, "control 'Saturation' not supported by firmware\n");
+			qctrl->flags = V4L2_CTRL_FLAG_DISABLED;
+			return 0;
+		}
+
+		/* reading the Saturation value */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_SATURATION_32RW,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_32,
+				(char *) &value);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_SATURATION_32RW: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->default_value = value;
+
+		/* reading the Minimum Saturation */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_SATURATION_MIN_32R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_32,
+				(char *) &value);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_SATURATION_MIN_32R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->minimum = value;
+
+		/* reading the Maximum Saturation */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_SATURATION_MAX_32R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_32,
+				(char *) &value);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_SATURATION_MAX_32R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->maximum = value;
+
+		/* reading the Saturation step increment */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_SATURATION_INC_32R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_32,
+				(char *) &value);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_SATURATION_INC_32R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->step = value;
+
+		if (qctrl->minimum > qctrl->maximum) {
+			avt_err(sd, "Saturation: min > max! (%d > %d)\n",
+					qctrl->minimum, qctrl->maximum);
+			return -EINVAL;
+		}
+		if (qctrl->step <= 0) {
+			avt_err(sd, "Saturation: non-positive step value (%d)!\n",
+					qctrl->step);
+			return -EINVAL;
+		}
+
+		qctrl->type = V4L2_CTRL_TYPE_INTEGER;
+		strcpy(qctrl->name, "Saturation");
+		break;
+
+	case V4L2_CID_HUE:
+		avt_dbg(sd, "case V4L2_CID_HUE\n");
+
+		if (!feature_inquiry_reg.feature_inq.hue_avail) {
+			avt_info(sd, "control 'Hue' not supported by firmware\n");
+			qctrl->flags = V4L2_CTRL_FLAG_DISABLED;
+			return 0;
+		}
+
+		/* reading the Hue value */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_HUE_32RW,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_32,
+				(char *) &value);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_HUE_32RW: i2c read failed (%d)\n", ret);
+			return ret;
+		}
+
+		qctrl->default_value = value;
+
+		/* reading the Minimum HUE */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_HUE_MIN_32R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_32,
+				(char *) &value);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_HUE_MIN_32R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->minimum = value;
+
+		/* reading the Maximum HUE */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_HUE_MAX_32R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_32,
+				(char *) &value);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_HUE_MAX_32R: i2c read failed (%d)\n", ret);
+			return ret;
+		}
+
+		qctrl->maximum = value;
+
+		/* reading the HUE step increment */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_HUE_INC_32R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_32,
+				(char *) &value);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_HUE_INC_32R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->step = value;
+
+		if (qctrl->minimum > qctrl->maximum) {
+			avt_err(sd, "Hue: min > max! (%d > %d)\n",
+					qctrl->minimum, qctrl->maximum);
+			return -EINVAL;
+		}
+		if (qctrl->step <= 0) {
+			avt_err(sd, "Hue: non-positive step value (%d)!\n",
+					qctrl->step);
+			return -EINVAL;
+		}
+
+		qctrl->type = V4L2_CTRL_TYPE_INTEGER;
+		strcpy(qctrl->name, "Hue");
+		break;
+
+	case V4L2_CID_SHARPNESS:
+		avt_dbg(sd, "case V4L2_CID_SHARPNESS\n");
+
+		if (!feature_inquiry_reg.feature_inq.sharpness_avail) {
+			avt_info(sd, "control 'Sharpness' not supported by firmware\n");
+			qctrl->flags = V4L2_CTRL_FLAG_DISABLED;
+			return 0;
+		}
+
+		/* reading the Sharpness value */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_SHARPNESS_32RW,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_32,
+				(char *) &value);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_SHARPNESS_32RW: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->default_value = value;
+
+		/* reading the Minimum sharpness */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_SHARPNESS_MIN_32R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_32,
+				(char *) &value);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_SHARPNESS_MIN_32R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->minimum = value;
+
+		/* reading the Maximum sharpness */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_SHARPNESS_MAX_32R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_32,
+				(char *) &value);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_SHARPNESS_MAX_32R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->maximum = value;
+
+		/* reading the sharpness step increment */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_SHARPNESS_INC_32R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_32,
+				(char *) &value);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_SHARPNESS_INC_32R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->step = value;
+
+		if (qctrl->minimum > qctrl->maximum) {
+			avt_err(sd, "Sharpness: min > max! (%d > %d)\n",
+					qctrl->minimum, qctrl->maximum);
+			return -EINVAL;
+		}
+		if (qctrl->step <= 0) {
+			avt_err(sd, "Sharpness: non-positive step value (%d)!\n",
+					qctrl->step);
+			return -EINVAL;
+		}
+
+		qctrl->type = V4L2_CTRL_TYPE_INTEGER;
+		strcpy(qctrl->name, "Sharpness");
+		break;
+	case V4L2_CID_EXPOSURE_ACTIVE_LINE_MODE:
+		avt_dbg(sd, "case V4L2_CID_EXPOSURE_ACTIVE_LINE_MODE\n");
+
+		if (!feature_inquiry_reg.feature_inq.exposure_active_line_avail) {
+			avt_info(sd, "control 'exposure active line' not supported by firmware\n");
+			qctrl->flags = V4L2_CTRL_FLAG_DISABLED;
+			return 0;
+		}
+
+		/* reading the exposure active line mode value */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_EXPOSURE_ACTIVE_LINE_MODE_8RW,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_8,
+				(char *) &value);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_EXPOSURE_ACTIVE_LINE_MODE_8RW: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		if (value == 1)
+			/* true (ON) */
+			qctrl->default_value = true;
+		else
+			/* false (OFF) */
+			qctrl->default_value = false;
+
+		qctrl->minimum = 0;
+		qctrl->step = 1;
+		qctrl->maximum = 1;
+		qctrl->type = V4L2_CTRL_TYPE_BOOLEAN;
+
+		strcpy(qctrl->name, "Exposure Active Line Mode");
+		break;
+
+	case V4L2_CID_EXPOSURE_ACTIVE_LINE_SELECTOR:
+		{
+			char selector;
+			avt_dbg(sd, "case V4L2_CID_EXPOSURE_ACTIVE_LINE_SELECTOR\n");
+
+			if (!feature_inquiry_reg.feature_inq.exposure_active_line_avail) {
+				avt_info(sd, "control 'exposure active line' not supported by firmware\n");
+				qctrl->flags = V4L2_CTRL_FLAG_DISABLED;
+				return 0;
+			}
+
+			/* reading the exposure active line mode value */
+			ret = avt_reg_read(client,
+					priv->cci_reg.bcrm_addr + BCRM_EXPOSURE_ACTIVE_OUTPUT_LINE_8RW,
+					AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_8,
+					(char *) &selector);
+			if (ret < 0) {
+				avt_err(sd, "BCRM_EXPOSURE_ACTIVE_OUTPUT_LINE_8RW: i2c read failed (%d)\n",
+						ret);
+				return ret;
+			}
+
+			qctrl->default_value = selector;
+			qctrl->minimum = 0;
+			qctrl->step = 1;
+			qctrl->maximum = 1;
+			qctrl->type = V4L2_CTRL_TYPE_INTEGER;
+
+			strcpy(qctrl->name, "Exposure Active Line Selector");
+			break;
+		}
+
+	case V4L2_CID_EXPOSURE_ACTIVE_INVERT:
+		{
+			avt_dbg(sd, "case V4L2_CID_EXPOSURE_ACTIVE_INVERT\n");
+
+			if (!feature_inquiry_reg.feature_inq.exposure_active_line_avail) {
+				avt_info(sd, "control 'exposure active line' not supported by firmware\n");
+				qctrl->flags = V4L2_CTRL_FLAG_DISABLED;
+				return 0;
+			}
+
+			qctrl->default_value = false;
+			qctrl->minimum = 0;
+			qctrl->step = 1;
+			qctrl->maximum = 1;
+			qctrl->type = V4L2_CTRL_TYPE_BOOLEAN;
+
+			strcpy(qctrl->name, "Exposure Active Invert");
+			break;
+		}
+
+	case V4L2_CID_TRIGGER_MODE:
+		{
+			avt_dbg(sd, "case V4L2_CID_TRIGGER_MODE\n");
+			qctrl->default_value = priv->trigger_mode;
+			qctrl->minimum = 0;
+			qctrl->step = 1;
+			qctrl->maximum = 1;
+			qctrl->type = V4L2_CTRL_TYPE_BOOLEAN;
+
+			strcpy(qctrl->name, "Trigger Mode");
+			break;
+		}
+	
+	case V4L2_CID_TRIGGER_ACTIVATION:
+		{
+			u8 trigger_activation;
+			avt_dbg(sd, "case V4L2_CID_TRIGGER_ACTIVATION\n");
+        
+			ret = avt_reg_read(client,
+            	priv->cci_reg.bcrm_addr + BCRM_FRAME_START_TRIGGER_ACTIVATION_8RW,
+            	AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_8,
+            	&trigger_activation);
+
+			if (ret < 0) {
+				return ret;
+			}
+
+			qctrl->default_value = trigger_activation;
+			qctrl->minimum = V4L2_TRIGGER_ACTIVATION_RISING_EDGE;
+			qctrl->step = 0;
+			qctrl->maximum = V4L2_TRIGGER_ACTIVATION_LEVEL_LOW;
+
+			qctrl->type = V4L2_CTRL_TYPE_MENU;
+
+			strcpy(qctrl->name, "Trigger Activation");
+			break;
+		}
+		
+	case V4L2_CID_TRIGGER_SOURCE:
+		{
+			u8 trigger_source_reg;
+			avt_dbg(sd, "case V4L2_CID_TRIGGER_SOURCE\n");
+			
+        
+			ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr +
+				BCRM_FRAME_START_TRIGGER_SOURCE_8RW,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_8,
+				(char *) &trigger_source_reg);
+
+			if (ret < 0) {
+				return ret;
+			}
+			if(trigger_source_reg > V4L2_TRIGGER_SOURCE_SOFTWARE) {
+				avt_err(sd, " Unknown trigger mode (%d) returned from camera. Driver outdated?", trigger_source_reg);
+				return -1;
+			}
+			qctrl->default_value = trigger_source_reg;
+			qctrl->minimum = V4L2_TRIGGER_SOURCE_LINE0;
+			qctrl->step = 0;
+			qctrl->maximum = V4L2_TRIGGER_SOURCE_SOFTWARE;
+
+			qctrl->type = V4L2_CTRL_TYPE_MENU;
+			strcpy(qctrl->name, "Trigger Source");
+			break;
+		}
+		
+	case V4L2_CID_TRIGGER_SOFTWARE:
+		{
+			avt_dbg(sd, "case V4L2_CID_TRIGGER_SOFTWARE\n");
+
+			qctrl->default_value = 0;
+			qctrl->minimum = 0;
+			qctrl->step = 0;
+			qctrl->maximum = 0;
+			qctrl->type = V4L2_CTRL_TYPE_BUTTON;
+			qctrl->flags = V4L2_CTRL_FLAG_INACTIVE;
+
+			strcpy(qctrl->name, "Trigger software");
+			break;
+		}
+
+	case V4L2_CID_EXPOSURE_ABSOLUTE:
+		{
+			struct v4l2_query_ext_ctrl query_exposure = {.id = V4L2_CID_EXPOSURE};
+			ioctl_queryctrl64(sd, &query_exposure);
+			qctrl->default_value = (int32_t)(query_exposure.default_value / EXP_ABS);
+			qctrl->minimum       = (int32_t)(query_exposure.minimum / EXP_ABS);
+			qctrl->maximum       = (int32_t)(query_exposure.maximum / EXP_ABS);
+			qctrl->step          = max((int32_t)(query_exposure.step / EXP_ABS), 1);
+			qctrl->type          = V4L2_CTRL_TYPE_INTEGER;
+			strcpy(qctrl->name, "Exposure Absolute");
+			break;
+		}
+
+	case V4L2_CID_DEVICE_TEMPERATURE:
+		avt_dbg(sd, "case V4L2_CID_DEVICE_TEMPERATURE\n");
+
+		if (!feature_inquiry_reg.feature_inq.device_temperature_avail) {
+			avt_info(sd, "control 'Device Temperature' not supported by firmware\n");
+			qctrl->flags = V4L2_CTRL_FLAG_DISABLED;
+			return 0;
+		}
+
+		/* reading the current Device Temperature value */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_DEVICE_TEMPERATURE_32R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_32,
+				(char *) &value);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_DEVICE_TEMPERATURE_32R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->default_value = value;
+		qctrl->minimum = -1000;
+		qctrl->maximum = 2000;
+		qctrl->step = 1;
+		qctrl->type = V4L2_CTRL_TYPE_INTEGER;
+		qctrl->flags = V4L2_CTRL_FLAG_VOLATILE;
+		strcpy(qctrl->name, "Device Temperature");
+		break;
+
+	default:
+		avt_info(sd, "case default or not supported qctrl->id 0x%x\n",
+				qctrl->id);
+		qctrl->flags = V4L2_CTRL_FLAG_DISABLED;
+		return 0;
+	}
+
+	if (ret < 0) {
+		avt_err(sd, "i2c read failed (%d)\n", ret);
+		return ret;
+	}
+
+	avt_dbg(sd, "ret = %d\n", ret);
+
+	return 0;
+}
+
+static int ioctl_queryctrl64(struct v4l2_subdev *sd,
+		struct v4l2_query_ext_ctrl *qctrl)
+{
+	struct i2c_client *client = v4l2_get_subdevdata(sd);
+	struct camera_common_data *s_data = to_camera_common_data(&client->dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+
+	u64 value64 = 0;
+	int ret;
+	union bcrm_feature_reg feature_inquiry_reg;
+
+	qctrl->type = V4L2_CTRL_TYPE_INTEGER64; /* all types are V4L2_CTRL_TYPE_INTEGER64*/
+	qctrl->elem_size=8;
+	qctrl->elems=1;
+
+	avt_dbg(sd, "\n");
+
+	/* reading the Feature inquiry register */
+	ret = read_feature_register(sd, &feature_inquiry_reg);
+  
+	if (ret < 0) {
+		avt_err(sd, "BCRM_FEATURE_INQUIRY_64R: i2c read failed (%d)\n", ret);
+		return ret;
+	}
+
+	switch (qctrl->id) {
+
+	case V4L2_CID_EXPOSURE:
+		avt_dbg(sd, "case V4L2_CID_EXPOSURE\n");
+
+		/* reading the Exposure time */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_EXPOSURE_TIME_64RW,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_EXPOSURE_TIME_64RW: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->default_value = (s64)value64;
+
+		/* reading the Minimum Exposure time */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_EXPOSURE_TIME_MIN_64R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_EXPOSURE_TIME_MIN_64R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+		qctrl->minimum = (s64)value64;
+
+		/* reading the Maximum Exposure time */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_EXPOSURE_TIME_MAX_64R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_EXPOSURE_TIME_MAX_64R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->maximum = (s64)value64;
+
+		/* setting step value fixed to 1 to avoid fighting between camera and driver side adjustments */
+		qctrl->step = 1;
+
+		if (qctrl->minimum > qctrl->maximum) {
+			avt_err(sd, "Exposure: min > max! (%lld > %lld)\n",
+					qctrl->minimum, qctrl->maximum);
+			return -EINVAL;
+		}
+
+		strcpy(qctrl->name, "Exposure");
+		break;
+
+	case V4L2_CID_GAIN:
+
+		avt_dbg(sd, "case V4L2_CID_GAIN\n");
+
+		if (!feature_inquiry_reg.feature_inq.gain_avail) {
+			avt_info(sd, "control 'Gain' not supported by firmware\n");
+			qctrl->flags = V4L2_CTRL_FLAG_DISABLED;
+			return 0;
+		}
+
+		/* reading the Gain value */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_GAIN_64RW,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_GAIN_64RW: i2c read failed (%d)\n", ret);
+			return ret;
+		}
+
+		qctrl->default_value = (__s64) value64;
+
+		/* reading the Minimum Gain value */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_GAIN_MIN_64R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_GAIN_MIN_64R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->minimum = (__s64) value64;
+
+		/* reading the Maximum Gain value */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_GAIN_MAX_64R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_GAIN_MAX_64R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->maximum = (__s64) value64;
+
+		/* setting step value fixed to 1 to avoid fighting between camera and driver side adjustments */
+		qctrl->step = 1;
+
+		if (qctrl->minimum > qctrl->maximum) {
+			avt_err(sd, "Gain: min > max! (%lld > %lld)\n",
+					qctrl->minimum, qctrl->maximum);
+			return -EINVAL;
+		}
+
+		strcpy(qctrl->name, "Gain");
+		break;
+
+	case V4L2_CID_GAMMA:
+		avt_dbg(sd, "case V4L2_CID_GAMMA\n");
+
+		if (!feature_inquiry_reg.feature_inq.gamma_avail) {
+			avt_info(sd, "control 'Gamma' not supported by firmware\n");
+			qctrl->flags = V4L2_CTRL_FLAG_DISABLED;
+			return 0;
+		}
+
+		/* reading the Gamma value */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_GAMMA_64RW,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_GAMMA_64RW: i2c read failed (%d)\n", ret);
+			return ret;
+		}
+
+		qctrl->default_value = (__s64) value64;
+
+		/* reading the Minimum Gamma */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_GAMMA_MIN_64R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_GAMMA_MIN_64R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->minimum = (__s64) value64;
+
+		/* reading the Maximum Gamma */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_GAMMA_MAX_64R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_GAMMA_MAX_64R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->maximum = (__s64) value64;
+
+		/* reading the Gamma step increment */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_GAMMA_INC_64R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_GAMMA_INC_64R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->step = value64;
+
+		if (qctrl->minimum > qctrl->maximum) {
+			avt_err(sd, "Gamma: min > max! (%lld > %lld)\n",
+					qctrl->minimum, qctrl->maximum);
+			return -EINVAL;
+		}
+
+		strcpy(qctrl->name, "Gamma");
+		break;
+
+	case V4L2_CID_BLUE_BALANCE:
+		avt_dbg(sd, "case V4L2_CID_BLUE_BALANCE\n");
+
+		if (!feature_inquiry_reg.feature_inq.white_balance_avail) {
+			avt_info(sd, "control 'Blue balance' not supported by firmware\n");
+			qctrl->flags = V4L2_CTRL_FLAG_DISABLED;
+			return 0;
+		}
+
+		/* reading the Blue balance value */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_BLUE_BALANCE_RATIO_64RW,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_BLUE_BALANCE_RATIO_64RW: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->default_value = (__s64) value64;
+
+		/* reading the Minimum Blue balance */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_BLUE_BALANCE_RATIO_MIN_64R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_BLUE_BALANCE_RATIO_MIN_64R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->minimum = (__s64) value64;
+
+		/* reading the Maximum Blue balance */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_BLUE_BALANCE_RATIO_MAX_64R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_BLUE_BALANCE_RATIO_MAX_64R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->maximum = (__s64) value64;
+
+		/* reading the Blue balance step increment */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr +
+				BCRM_BLUE_BALANCE_RATIO_INC_64R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_BLUE_BALANCE_RATIO_INC_64R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->step = value64;
+
+		if (qctrl->minimum > qctrl->maximum) {
+			avt_err(sd, "Blue Balance: min > max! (%lld > %lld)\n",
+					qctrl->minimum, qctrl->maximum);
+			return -EINVAL;
+		}
+
+		strcpy(qctrl->name, "Blue Balance");
+		break;
+
+	case V4L2_CID_RED_BALANCE:
+		avt_dbg(sd, "case V4L2_CID_RED_BALANCE\n");
+
+		if (!feature_inquiry_reg.feature_inq.white_balance_avail) {
+			avt_info(sd, "control 'Red balance' not supported by firmware\n");
+			qctrl->flags = V4L2_CTRL_FLAG_DISABLED;
+			return 0;
+		}
+
+		/* reading the Red balance value */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_RED_BALANCE_RATIO_64RW,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_RED_BALANCE_RATIO_64RW: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->default_value = (__s64) value64;
+
+		/* reading the Minimum Red balance */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_RED_BALANCE_RATIO_MIN_64R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_RED_BALANCE_RATIO_MIN_64R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->minimum = (__s64) value64;
+
+		/* reading the Maximum Red balance */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_RED_BALANCE_RATIO_MAX_64R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_RED_BALANCE_RATIO_MAX_64R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->maximum = (__s64) value64;
+
+		/* reading the Red balance step increment */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr +
+				BCRM_RED_BALANCE_RATIO_INC_64R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_RED_BALANCE_RATIO_INC_64R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl->step = value64;
+
+		if (qctrl->minimum > qctrl->maximum) {
+			avt_err(sd, "Red Balance: min > max! (%lld > %lld)\n",
+					qctrl->minimum, qctrl->maximum);
+			return -EINVAL;
+		}
+
+		strcpy(qctrl->name, "Red Balance");
+		break;
+
+	case V4L2_CID_EXPOSURE_AUTO_MIN:
+		avt_dbg(sd, "case V4L2_CID_EXPOSURE_AUTO_MIN\n");
+
+		if (!feature_inquiry_reg.feature_inq.exposure_auto) {
+			avt_info(sd, "control 'Exposure Auto Min' not supported by firmware\n");
+			qctrl->flags = V4L2_CTRL_FLAG_DISABLED;
+			return 0;
+		}
+
+		/* Exposure Auto max value should be non-zero */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_EXPOSURE_AUTO_MAX_64RW,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_EXPOSURE_AUTO_MAX_64RW: i2c read failed (%d)\n", ret);
+			return ret;
+		}
+		qctrl->maximum = (__s64) value64;
+
+		/* reading the Auto Exposure min time */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_EXPOSURE_AUTO_MIN_64RW,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_EXPOSURE_AUTO_MIN_64RW: i2c read failed (%d)\n", ret);
+			return ret;
+		}
+		qctrl->default_value = (__s64) value64;
+
+		/* get min and max times for Exposure they are also valid for
+		   Auto Exposure min time */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_EXPOSURE_TIME_MIN_64R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_EXPOSURE_TIME_MIN_64R: i2c read failed (%d)\n", ret);
+			return ret;
+		}
+		qctrl->minimum = (__s64) value64;
+
+		/* reading the Maximum Exposure time */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_EXPOSURE_TIME_MAX_64R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_EXPOSURE_TIME_MAX_64R: i2c read failed (%d)\n", ret);
+			return ret;
+		}
+		/* max auto exposure time should be
+		   <= (min(Exposure Auto max value, max exposure time)*/
+		if(qctrl->maximum  > ((__s64) value64))
+			qctrl->maximum  = ((__s64) value64);
+
+		/* setting step value fixed to 1 to avoid fighting between camera and driver side adjustments */
+		qctrl->step = 1;
+
+		if (qctrl->minimum > qctrl->maximum) {
+			avt_err(sd, "Exposure auto: min > max! (%lld > %lld)\n", qctrl->minimum, qctrl->maximum);
+			return -EINVAL;
+		}
+		strcpy(qctrl->name, "Exposure auto min");
+		break;
+
+	case V4L2_CID_EXPOSURE_AUTO_MAX:
+		avt_dbg(sd, "case V4L2_CID_EXPOSURE_AUTO_MAX\n");
+
+		if (!feature_inquiry_reg.feature_inq.exposure_auto) {
+			avt_info(sd, "control 'Exposure Auto Max' not supported by firmware\n");
+			qctrl->flags = V4L2_CTRL_FLAG_DISABLED;
+			return 0;
+		}
+
+		/* Exposure Auto max value should be non-zero */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_EXPOSURE_AUTO_MAX_64RW,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_EXPOSURE_AUTO_MAX_64RW: i2c read failed (%d)\n", ret);
+			return ret;
+		}
+		qctrl->default_value = value64;
+
+		/* reading the Auto Exposure min time */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_EXPOSURE_AUTO_MIN_64RW,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_EXPOSURE_AUTO_MIN_64RW: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+		qctrl->minimum = (__s64) value64;
+
+		/* get min and max times for Exposure they are also valid for
+		   Auto Exposure max time */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_EXPOSURE_TIME_MAX_64R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_EXPOSURE_TIME_MAX_64R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+		qctrl->maximum = (__s64) value64;
+
+		/* reading the Minimum Exposure time */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_EXPOSURE_TIME_MIN_64R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_EXPOSURE_TIME_MIN_64R: i2c read failed (%d)\n", ret);
+			return ret;
+		}
+		/* main auto exposure time should be
+		   >= (max(Exposure Auto min value, min exposure time)*/
+		if(qctrl->minimum  < ((__s64) value64))
+			qctrl->minimum  = ((__s64) value64);
+
+		/* setting step value fixed to 1 to avoid fighting between camera and driver side adjustments */
+		qctrl->step = 1;
+
+		if (qctrl->minimum > qctrl->maximum) {
+			avt_err(sd, "Exposure auto: min > max! (%lld > %lld)\n", qctrl->minimum, qctrl->maximum);
+			return -EINVAL;
+		}
+		strcpy(qctrl->name, "Exposure auto max");
+		break;
+	case V4L2_CID_GAIN_AUTO_MIN:
+
+		avt_dbg(sd, "case V4L2_CID_GAIN_AUTO_MIN\n");
+
+		if (!feature_inquiry_reg.feature_inq.gain_auto) {
+			avt_info(sd, "control 'Gain Auto Min' not supported by firmware\n");
+			qctrl->flags = V4L2_CTRL_FLAG_DISABLED;
+			return 0;
+		}
+
+		/* Auto gain max value should be non-zero */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_GAIN_AUTO_MAX_64RW,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_GAIN_AUTO_MAX_64RW: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+		qctrl->maximum = (__s64) value64;
+
+		/* reading the Auto gain min val */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_GAIN_AUTO_MIN_64RW,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_GAIN_AUTO_MIN_64RW: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+		qctrl->default_value = (__s64) value64;
+
+		/* get min and max vals for auto gain they are also valid for
+		   Auto gain min val */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_GAIN_MIN_64R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_GAIN_MIN_64R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+		qctrl->minimum = (__s64) value64;
+
+		/* reading the Maximum gain time */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_GAIN_MAX_64R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_GAIN_MAX_64R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+		/* max auto gain val should be
+		   <= (min(Auto gian max value, max gain val)*/
+		if(qctrl->maximum  > ((__s64) value64))
+			qctrl->maximum  = ((__s64) value64);
+
+		/* setting step value fixed to 1 to avoid fighting between camera and driver side adjustments */
+		qctrl->step = 1;
+
+		strcpy(qctrl->name, "Gain auto min");
+		if (qctrl->minimum > qctrl->maximum) {
+			avt_err(sd, "Gain auto: min > max! (%lld > %lld)\n",
+					qctrl->minimum, qctrl->maximum);
+			return -EINVAL;
+		}
+		strcpy(qctrl->name, "Auto gain min");
+		break;
+
+	case V4L2_CID_GAIN_AUTO_MAX:
+
+		avt_dbg(sd, "case V4L2_CID_GAIN_AUTO_MAX\n");
+
+		if (!feature_inquiry_reg.feature_inq.gain_auto) {
+			avt_info(sd, "control 'Gain Auto Max' not supported by firmware\n");
+			qctrl->flags = V4L2_CTRL_FLAG_DISABLED;
+			return 0;
+		}
+
+		/* Auto gain max value should be non-zero */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_GAIN_AUTO_MAX_64RW,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_GAIN_AUTO_MAX_64RW: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+		qctrl->default_value = (__s64) value64;
+
+		/* reading the Auto gain min val */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_GAIN_AUTO_MIN_64RW,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_GAIN_AUTO_MIN_64RW: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+		qctrl->minimum = (__s64) value64;
+
+		/* get min and max vals for auto gain they are also valid for
+		   Auto gain max val */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_GAIN_MAX_64R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_GAIN_MAX_64R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+		qctrl->maximum = (__s64) value64;
+
+		/* reading the Minimum gain time */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_GAIN_MIN_64R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_GAIN_MIN_64R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+		/* min auto gain val should be
+		   >= (max(Auto gain min value, min gain val)*/
+		if(qctrl->minimum  < ((__s64) value64))
+			qctrl->minimum  = ((__s64) value64);
+
+		/* setting step value fixed to 1 to avoid fighting between camera and driver side adjustments */
+		qctrl->step = 1;
+
+		strcpy(qctrl->name, "Gain auto max");
+		break;
+
+	case V4L2_CID_EXPOSURE_ACTIVE_LINE_MODE:
+		avt_dbg(sd, "case V4L2_CID_EXPOSURE_ACTIVE_LINE_MODE\n");
+
+		if (!feature_inquiry_reg.feature_inq.exposure_active_line_avail) {
+			avt_info(sd, "control 'exposure active line' not supported by firmware\n");
+			qctrl->flags = V4L2_CTRL_FLAG_DISABLED;
+			return 0;
+		}
+
+		if (qctrl->minimum > qctrl->maximum) {
+			avt_err(sd, "Red Balance: min > max! (%lld > %lld)\n",
+					qctrl->minimum, qctrl->maximum);
+			return -EINVAL;
+		}
+		strcpy(qctrl->name, "Auto gain max");
+		break;
+
+	case V4L2_CID_EXPOSURE_ACTIVE_LINE_SELECTOR:
+		{
+			char selector;
+			avt_dbg(sd, "case V4L2_CID_EXPOSURE_ACTIVE_LINE_SELECTOR\n");
+
+			if (!feature_inquiry_reg.feature_inq.exposure_active_line_avail) {
+				avt_info(sd, "control 'exposure active line' not supported by firmware\n");
+				qctrl->flags = V4L2_CTRL_FLAG_DISABLED;
+				return 0;
+			}
+
+			/* reading the exposure active line mode value */
+			ret = avt_reg_read(client,
+					priv->cci_reg.bcrm_addr + BCRM_EXPOSURE_ACTIVE_OUTPUT_LINE_8RW,
+					AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_8,
+					(char *) &selector);
+			if (ret < 0) {
+				avt_err(sd, "BCRM_EXPOSURE_ACTIVE_OUTPUT_LINE_8RW: i2c read failed (%d)\n",
+						ret);
+				return ret;
+			}
+
+			qctrl->default_value = selector;
+			qctrl->minimum = 0;
+			qctrl->step = 1;
+			qctrl->maximum = 1;
+			qctrl->type = V4L2_CTRL_TYPE_INTEGER;
+
+			strcpy(qctrl->name, "Exposure Active Line Selector");
+			break;
+		}
+
+	case V4L2_CID_EXPOSURE_ACTIVE_INVERT:
+		{
+			avt_dbg(sd, "case V4L2_CID_EXPOSURE_ACTIVE_INVERT\n");
+
+			if (!feature_inquiry_reg.feature_inq.exposure_active_line_avail) {
+				avt_info(sd, "control 'exposure active line' not supported by firmware\n");
+				qctrl->flags = V4L2_CTRL_FLAG_DISABLED;
+				return 0;
+			}
+
+			qctrl->default_value = false;
+			qctrl->minimum = 0;
+			qctrl->step = 1;
+			qctrl->maximum = 1;
+			qctrl->type = V4L2_CTRL_TYPE_BOOLEAN;
+
+			strcpy(qctrl->name, "Exposure Active Invert");
+			break;
+		}
+	
+
+	default:
+		avt_info(sd, "case default or not supported qctrl->id 0x%x\n",
+				qctrl->id);
+		qctrl->flags = V4L2_CTRL_FLAG_DISABLED;
+		return 0;
+	}
+
+	if (ret < 0) {
+		avt_err(sd, "i2c read failed (%d)\n", ret);
+		return ret;
+	}
+
+	avt_dbg(sd, "ret = %d\n", ret);
+
+	return 0;
+}
+
+static int32_t convert_bcrm_to_v4l2_gctrl(struct bcrm_to_v4l2 *bcrmv4l2,
+		int64_t val64)
+{
+	int32_t value = 0;
+	int32_t min = 0;
+	int32_t max = 0;
+	int32_t step = 0;
+	int32_t result = 0;
+	int32_t valuedown = 0;
+	int32_t valueup = 0;
+
+/* 1. convert to double */
+	step = bcrmv4l2->step_v4l2;
+	max = bcrmv4l2->max_v4l2;
+	min = bcrmv4l2->min_v4l2;
+	value = (int32_t) val64;
+
+	/* 2. convert the units */
+/*	value *= factor; */
+
+	/* 3. Round value to next integer */
+
+	if (value < S32_MIN)
+		result = S32_MIN;
+	else if (value > S32_MAX)
+		result = S32_MAX;
+	else
+		result = value;
+
+	/* 4. Clamp to limits */
+	if (result > max)
+		result = max;
+	else if (result < min)
+		result = min;
+
+	/* 5. Use nearest increment */
+	valuedown = result - ((result - min) % (step));
+	valueup = valuedown + step;
+
+	if (result >= 0) {
+		if (((valueup - result) <= (result - valuedown))
+		&& (valueup <= bcrmv4l2->max_bcrm))
+			result = valueup;
+		else
+			result = valuedown;
+	} else {
+		if (((valueup - result) < (result - valuedown))
+			&& (valueup <= bcrmv4l2->max_bcrm))
+			result = valueup;
+		else
+			result = valuedown;
+	}
+
+	return result;
+}
+
+static __s64 convert_bcrm_to_v4l2_gctrl64(struct v4l2_query_ext_ctrl* qctrl_ext, int64_t val64)
+{
+	__s64 result = val64;
+	__s64 valuedown = 0;
+	__s64 valueup = 0;
+	__s64 step = (__s64)(qctrl_ext->step);
+
+	if (result > qctrl_ext->maximum)
+		result = qctrl_ext->maximum;
+	else if (result < qctrl_ext->minimum)
+		result = qctrl_ext->minimum;
+
+	/* 5. Use nearest increment */
+	valuedown = result - ((result - qctrl_ext->minimum) % (step));
+	valueup = valuedown + step;
+
+	if (result >= 0) {
+		if (((valueup - result) <= (result - valuedown))
+		&& (valueup <= qctrl_ext->maximum))
+			result = valueup;
+		else
+			result = valuedown;
+	} else {
+		if (((valueup - result) < (result - valuedown))
+			&& (valueup <= qctrl_ext->maximum))
+			result = valueup;
+		else
+			result = valuedown;
+	}
+
+	return result;
+}
+
+static int avt_ioctl_g_ctrl(struct v4l2_subdev *sd, struct v4l2_ext_control *vc)
+{
+	struct i2c_client *client = v4l2_get_subdevdata(sd);
+	struct camera_common_data *s_data = to_camera_common_data(&client->dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+
+	unsigned int reg = 0;
+	int length = 0;
+	struct bcrm_to_v4l2 bcrm_v4l2;
+	struct v4l2_queryctrl qctrl;
+	struct v4l2_query_ext_ctrl qctrl_ext;
+	int ret = 0;
+	uint64_t val64 = 0;
+
+	avt_dbg(sd, "\n");
+
+	vc->value = 0;
+	vc->value64=0;
+
+	switch (vc->id) {
+
+/* BLACK LEVEL is deprecated and thus we use Brightness */
+	case V4L2_CID_BRIGHTNESS:
+		avt_dbg(sd, "V4L2_CID_BRIGHTNESS\n");
+		reg = BCRM_BLACK_LEVEL_32RW;
+		length = AV_CAM_DATA_SIZE_32;
+		break;
+	case V4L2_CID_GAMMA:
+		avt_dbg(sd, "V4L2_CID_GAMMA\n");
+		reg = BCRM_GAIN_64RW;
+		length = AV_CAM_DATA_SIZE_64;
+		break;
+	case V4L2_CID_CONTRAST:
+		avt_dbg(sd, "V4L2_CID_CONTRAST\n");
+		reg = BCRM_CONTRAST_VALUE_32RW;
+		length = AV_CAM_DATA_SIZE_32;
+		break;
+	case V4L2_CID_DO_WHITE_BALANCE:
+		avt_dbg(sd, "V4L2_CID_DO_WHITE_BALANCE\n");
+		reg = BCRM_WHITE_BALANCE_AUTO_8RW;
+		length = AV_CAM_DATA_SIZE_8;
+		break;
+	case V4L2_CID_AUTO_WHITE_BALANCE:
+		avt_dbg(sd, "V4L2_CID_AUTO_WHITE_BALANCE\n");
+		reg = BCRM_WHITE_BALANCE_AUTO_8RW;
+		length = AV_CAM_DATA_SIZE_8;
+		break;
+	case V4L2_CID_SATURATION:
+		avt_dbg(sd, "V4L2_CID_SATURATION\n");
+		reg = BCRM_SATURATION_32RW;
+		length = AV_CAM_DATA_SIZE_32;
+		break;
+	case V4L2_CID_HUE:
+		avt_dbg(sd, "V4L2_CID_HUE\n");
+		reg = BCRM_HUE_32RW;
+		length = AV_CAM_DATA_SIZE_32;
+		break;
+	case V4L2_CID_RED_BALANCE:
+		avt_dbg(sd, "V4L2_CID_RED_BALANCE\n");
+		reg = BCRM_RED_BALANCE_RATIO_64RW;
+		length = AV_CAM_DATA_SIZE_64;
+		break;
+	case V4L2_CID_BLUE_BALANCE:
+		avt_dbg(sd, "V4L2_CID_BLUE_BALANCE\n");
+		reg = BCRM_BLUE_BALANCE_RATIO_64RW;
+		length = AV_CAM_DATA_SIZE_64;
+		break;
+	case V4L2_CID_EXPOSURE:
+		reg = BCRM_EXPOSURE_TIME_64RW;
+		length = AV_CAM_DATA_SIZE_64;
+		break;
+	case V4L2_CID_EXPOSURE_ABSOLUTE:
+		{
+			struct v4l2_ext_control query_exp = {.id = V4L2_CID_EXPOSURE};
+			int res_exp = avt_ioctl_g_ctrl(sd, &query_exp);
+			if (res_exp == 0) {
+				vc->value = (int32_t)(query_exp.value / EXP_ABS);
+			}
+			return res_exp;
+		}
+
+	case V4L2_CID_GAIN:
+		avt_dbg(sd, "V4L2_CID_GAIN\n");
+		reg = BCRM_GAIN_64RW;
+		length = AV_CAM_DATA_SIZE_64;
+		break;
+
+	case V4L2_CID_AUTOGAIN:
+		avt_dbg(sd, "V4L2_CID_AUTOGAIN\n");
+		reg = BCRM_GAIN_AUTO_8RW;
+		length = AV_CAM_DATA_SIZE_8;
+		break;
+
+	case V4L2_CID_SHARPNESS:
+		avt_dbg(sd, "V4L2_CID_SHARPNESS\n");
+		reg = BCRM_SHARPNESS_32RW;
+		length = AV_CAM_DATA_SIZE_32;
+		break;
+
+	case V4L2_CID_EXPOSURE_AUTO_MIN:
+		avt_dbg(sd, "V4L2_CID_EXPOSURE_AUTO_MIN\n");
+		reg = BCRM_EXPOSURE_AUTO_MIN_64RW;
+		length = AV_CAM_DATA_SIZE_64;
+		break;
+
+	case V4L2_CID_EXPOSURE_AUTO_MAX:
+		avt_dbg(sd, "V4L2_CID_EXPOSURE_AUTO_MAX\n");
+		reg = BCRM_EXPOSURE_AUTO_MAX_64RW;
+		length = AV_CAM_DATA_SIZE_64;
+		break;
+
+	case V4L2_CID_GAIN_AUTO_MIN:
+		avt_dbg(sd, "V4L2_CID_GAIN_AUTO_MIN\n");
+		reg = BCRM_GAIN_AUTO_MIN_64RW;
+		length = AV_CAM_DATA_SIZE_64;
+		break;
+
+	case V4L2_CID_GAIN_AUTO_MAX:
+		avt_dbg(sd, "V4L2_CID_GAIN_AUTO_MAX\n");
+		reg = BCRM_GAIN_AUTO_MAX_64RW;
+		length = AV_CAM_DATA_SIZE_64;
+		break;
+
+	case V4L2_CID_EXPOSURE_ACTIVE_LINE_MODE:
+		avt_dbg(sd, "V4L2_CID_EXPOSURE_ACTIVE_LINE_MODE\n");
+		reg = BCRM_EXPOSURE_ACTIVE_LINE_MODE_8RW;
+		length = AV_CAM_DATA_SIZE_8;
+		break;
+
+	case V4L2_CID_EXPOSURE_ACTIVE_LINE_SELECTOR:
+		avt_dbg(sd, "V4L2_CID_EXPOSURE_ACTIVE_LINE_SELECTOR\n");
+		reg = BCRM_EXPOSURE_ACTIVE_OUTPUT_LINE_8RW;
+		length = AV_CAM_DATA_SIZE_8;
+		break;
+
+	case V4L2_CID_EXPOSURE_ACTIVE_INVERT:
+		vc->value = priv->acquisition_active_invert;
+		return 0;
+
+	case V4L2_CID_TRIGGER_MODE:
+		avt_dbg(sd, "case V4L2_CID_TRIGGER_MODE\n");
+		vc->value=priv->trigger_mode;
+    length=AV_CAM_DATA_SIZE_8;
+		return 0;
+		
+	case V4L2_CID_TRIGGER_ACTIVATION:
+		avt_dbg(sd, "case V4L2_CID_TRIGGER_ACTIVATION\n");
+        reg = BCRM_FRAME_START_TRIGGER_ACTIVATION_8RW;
+		length = AV_CAM_DATA_SIZE_8;
+		break;
+		
+	case V4L2_CID_TRIGGER_SOURCE:
+		avt_dbg(sd, "case V4L2_CID_TRIGGER_SOURCE\n");
+		reg = BCRM_FRAME_START_TRIGGER_SOURCE_8RW;
+		length = AV_CAM_DATA_SIZE_8;
+		break;
+		
+	case V4L2_CID_TRIGGER_SOFTWARE:
+		avt_dbg(sd, "case V4L2_CID_TRIGGER_SOFTWARE\n");
+		vc->value = 0;
+		length = AV_CAM_DATA_SIZE_8;
+		return 0;
+	case V4L2_CID_DEVICE_TEMPERATURE:
+		avt_dbg(sd, "case V4L2_CID_DEVICE_TEMPERATURE\n");
+		length = AV_CAM_DATA_SIZE_32;
+		reg = BCRM_DEVICE_TEMPERATURE_32R;
+		vc->value = 0;
+		break;
+
+	default:
+		avt_err(sd, "case default or not supported\n");
+		return -EINVAL;
+	}
+
+	CLEAR(bcrm_v4l2);
+	CLEAR(qctrl);
+	CLEAR(qctrl_ext);
+
+	qctrl.id = vc->id;
+	qctrl_ext.id = vc->id;
+	if(length == AV_CAM_DATA_SIZE_64){
+		/* 64 bit ext control */
+		ret = ioctl_queryctrl64(sd, &qctrl_ext);
+		if (ret < 0) {
+			avt_err(sd, "queryctrl64 failed: ret %d\n", ret);
+			return ret;
+		}
+
+		ret = avt_reg_read(client,
+			priv->cci_reg.bcrm_addr + reg,
+			AV_CAM_REG_SIZE, length, (char *) &val64);
+    vc->value = convert_bcrm_to_v4l2_gctrl64(&qctrl_ext, (__s64)val64);
+
+	}
+	else {
+		ret = ioctl_queryctrl(sd, &qctrl);
+		if (ret < 0) {
+			avt_err(sd, "queryctrl failed: ret %d\n", ret);
+			return ret;
+		}
+
+		bcrm_v4l2.min_v4l2 = qctrl.minimum;
+		bcrm_v4l2.max_v4l2 = qctrl.maximum;
+		bcrm_v4l2.step_v4l2 = qctrl.step;
+
+		/* Overwrite the queryctrl maximum value for auto features since value
+		* 2 is 'true' (1)
+		*/
+		if (vc->id == V4L2_CID_AUTOGAIN ||
+				vc->id == V4L2_CID_AUTO_WHITE_BALANCE)
+			bcrm_v4l2.max_v4l2 = 2;
+
+		/* Check values from BCRM */
+		if ((bcrm_v4l2.min_v4l2 > bcrm_v4l2.max_v4l2) ||
+				(bcrm_v4l2.step_v4l2 <= 0)) {
+			avt_err(sd, "invalid BCRM values found. vc->id %d\n", vc->id);
+			return -EINVAL;
+		}
+
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + reg,
+				AV_CAM_REG_SIZE, length, (char *) &val64);
+
+		vc->value = convert_bcrm_to_v4l2_gctrl(&bcrm_v4l2, val64);
+
+		/* BCRM Auto Exposure changes -> Refer to BCRM document */
+		if (vc->id == V4L2_CID_EXPOSURE_AUTO) {
+			if (vc->value == 2)
+				/* continous mode, Refer BCRM doc */
+				vc->value = V4L2_EXPOSURE_AUTO;
+			else
+				/* OFF for off & once mode, Refer BCRM doc */
+				vc->value = V4L2_EXPOSURE_MANUAL;
+		}
+
+		/* BCRM Auto Gain/WB changes -> Refer to BCRM document */
+		if (vc->id == V4L2_CID_AUTOGAIN ||
+				vc->id == V4L2_CID_AUTO_WHITE_BALANCE) {
+
+			if (vc->value == 2)
+				/* continous mode, Refer BCRM doc */
+				vc->value = true;
+			else
+				/* OFF for off & once mode, Refer BCRM doc */
+				vc->value = false;
+		}
+	}
+
+	return ret;
+}
+static int avt_get_acquitision_active_line(struct v4l2_subdev *sd, int *line)
+{
+	struct i2c_client *client = v4l2_get_subdevdata(sd);
+	struct camera_common_data *s_data = to_camera_common_data(&client->dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+	int ret;
+
+	ret = avt_reg_read(client,
+		priv->cci_reg.bcrm_addr + BCRM_EXPOSURE_ACTIVE_OUTPUT_LINE_8RW,
+		AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_8, (char *) line);
+
+	if (ret < 0) {
+		avt_err(sd, "BCRM_EXPOSURE_ACTIVE_OUTPUT_LINE_8RW: i2c read failed (%d)\n",
+				ret);
+		return ret;
+	}
+	return 0;
+}
+
+
+static int avt_get_acquisition_active_mode(struct v4l2_subdev *sd, int *mode)
+{
+	struct i2c_client *client = v4l2_get_subdevdata(sd);
+	struct camera_common_data *s_data = to_camera_common_data(&client->dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+	int ret;
+	char mode_tmp;
+
+	ret = avt_reg_read(client,
+		priv->cci_reg.bcrm_addr + BCRM_EXPOSURE_ACTIVE_LINE_MODE_8RW,
+		AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_8, &mode_tmp);
+
+	if (ret < 0) {
+		avt_err(sd, "BCRM_EXPOSURE_ACTIVE_LINE_MODE_8RW: i2c read failed (%d)\n",
+				ret);
+		return ret;
+	}
+
+	*mode = mode_tmp;
+
+	return 0;
+}
+
+
+static int avt_set_acquitision_active_line(struct v4l2_subdev *sd, int line)
+{
+	struct i2c_client *client = v4l2_get_subdevdata(sd);
+	struct camera_common_data *s_data = to_camera_common_data(&client->dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+	int ret, active;
+	struct v4l2_ext_control ctrl = { .value = line };
+
+	ret = avt_get_acquisition_active_mode(sd, &active);
+	if (ret < 0) {
+		return ret;
+	}
+
+	if (active) {
+		avt_err(sd, "Cannot set acquisition active line while acquisition active mode is enabled\n");
+		return -EBUSY;
+	}
+
+	ret = ioctl_bcrm_i2cwrite_reg(client, &ctrl, BCRM_EXPOSURE_ACTIVE_OUTPUT_LINE_8RW + priv->cci_reg.bcrm_addr,
+			AV_CAM_DATA_SIZE_8);
+
+	if (ret < 0) {
+		avt_err(sd, "BCRM_EXPOSURE_ACTIVE_OUTPUT_LINE_8RW: i2c write failed (%d)\n", ret);
+		return ret;
+	}
+	return 0;
+}
+
+
+static int avt_set_acquisition_active_mode(struct v4l2_subdev *sd, int mode)
+{
+	struct i2c_client *client = v4l2_get_subdevdata(sd);
+	struct camera_common_data *s_data = to_camera_common_data(&client->dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+	int line;
+	int ret;
+	struct v4l2_ext_control ctrl = { 0 };
+
+	ret = avt_get_acquitision_active_line(sd, &line);
+	if (ret < 0) {
+		return ret;
+	}
+
+	ctrl.value = (mode ? (1 | (priv->acquisition_active_invert ? 2 : 0)) : 0) << (8*line);
+	ret = ioctl_bcrm_i2cwrite_reg(client, &ctrl, BCRM_LINE_CONFIGURATION_32RW + priv->cci_reg.bcrm_addr,
+			AV_CAM_DATA_SIZE_32);
+	if (ret < 0) {
+		avt_err(sd, "BCRM_LINE_CONFIGURATION_32RW: i2c write failed (%d)\n", ret);
+		return ret;
+	}
+
+	ctrl.value = mode;
+	ret = ioctl_bcrm_i2cwrite_reg(client, &ctrl, BCRM_EXPOSURE_ACTIVE_LINE_MODE_8RW + priv->cci_reg.bcrm_addr,
+			AV_CAM_DATA_SIZE_8);
+	if (ret < 0) {
+		avt_err(sd, "BCRM_EXPOSURE_ACTIVE_LINE_MODE_8RW: i2c write failed (%d)\n", ret);
+		return ret;
+	}
+
+	return 0;
+}
+
+
+static int avt_set_acquisition_active_invert(struct v4l2_subdev *sd, int invert)
+{
+	struct i2c_client *client = v4l2_get_subdevdata(sd);
+	struct camera_common_data *s_data = to_camera_common_data(&client->dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+	int ret, active;
+
+	ret = avt_get_acquisition_active_mode(sd, &active);
+	if (ret < 0) {
+		return ret;
+	}
+
+	if (active) {
+		avt_err(sd, "Cannot set acquisition active invert while acquisition active mode is enabled\n");
+		return -EBUSY;
+	}
+
+	priv->acquisition_active_invert = invert;
+
+	return 0;
+}
+
+
+static bool register_readback_required(u32 control)
+{
+  return (control == V4L2_CID_EXPOSURE) ||
+         (control == V4L2_CID_GAIN) ||
+         (control == V4L2_CID_GAIN_AUTO_MIN) ||
+         (control == V4L2_CID_GAIN_AUTO_MAX) ||
+         (control == V4L2_CID_EXPOSURE_AUTO_MIN) ||
+         (control == V4L2_CID_EXPOSURE_AUTO_MAX);
+}
+
+
+static int register_readback64(struct v4l2_subdev *sd, u32 ctrl_id, unsigned int reg)
+{
+  int64_t value64 = 0;
+  struct i2c_client *client = v4l2_get_subdevdata(sd);
+  struct avt_csi2_priv *priv = avt_get_priv(sd);
+  struct v4l2_ctrl *ctrl;
+  int ret; 
+
+  ctrl = avt_get_control(sd, ctrl_id);
+
+  ret = avt_reg_read(client,
+             priv->cci_reg.bcrm_addr + reg,
+             AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+             (char *) &value64);
+  if (ret < 0) {
+    avt_err(sd, "i2c read failed (%d)\n", ret);
+    return ret;
+  }
+
+  priv->ignore_control_write = true;
+  ret = __v4l2_ctrl_s_ctrl_int64(ctrl, value64);
+  priv->ignore_control_write = false;
+
+  return ret;
+}
+
+
+static int avt_ioctl_s_ctrl(struct v4l2_subdev *sd, struct v4l2_ext_control *vc)
+{
+	int ret = 0;
+	unsigned int reg = 0;
+	int length = 0;
+	__s64 value_bkp = 0;
+	struct v4l2_queryctrl qctrl;
+	struct v4l2_query_ext_ctrl qctrl_ext;
+	//struct v4l2_ctrl *vctrl_handle;
+	struct avt_csi2_priv *priv = avt_get_priv(sd);
+	struct i2c_client *client = v4l2_get_subdevdata(sd);
+
+	CLEAR(qctrl);
+	CLEAR(qctrl_ext);
+
+	qctrl.id = vc->id;
+	qctrl_ext.id = vc->id;
+
+	switch (vc->id) {
+
+	case V4L2_CID_DO_WHITE_BALANCE:
+		avt_dbg(sd, "V4L2_CID_DO_WHITE_BALANCE vc->value %u\n",
+				vc->value);
+		reg = BCRM_WHITE_BALANCE_AUTO_8RW;
+		length = AV_CAM_DATA_SIZE_8;
+		vc->value = 1; /* Set 'once' in White Balance Auto Register. */
+		break;
+
+/* BLACK LEVEL is deprecated and thus we use Brightness */
+	case V4L2_CID_BRIGHTNESS:
+		avt_dbg(sd, "V4L2_CID_BRIGHTNESS vc->value %u\n", vc->value);
+		reg = BCRM_BLACK_LEVEL_32RW;
+		length = AV_CAM_DATA_SIZE_32;
+
+		ret = ioctl_queryctrl(sd, &qctrl);
+
+		if (ret < 0) {
+			avt_err(sd, "queryctrl failed: ret %d\n", ret);
+			return ret;
+		}
+		vc->value = convert_s_ctrl(vc->value,
+				qctrl.minimum, qctrl.maximum, qctrl.step);
+		break;
+
+	case V4L2_CID_CONTRAST:
+		avt_dbg(sd, "V4L2_CID_CONTRAST vc->value %u\n", vc->value);
+		reg = BCRM_CONTRAST_VALUE_32RW;
+		length = AV_CAM_DATA_SIZE_32;
+
+		ret = ioctl_queryctrl(sd, &qctrl);
+
+		if (ret < 0) {
+			avt_err(sd, "queryctrl failed: ret %d\n", ret);
+			return ret;
+		}
+
+		vc->value = convert_s_ctrl(vc->value,
+				qctrl.minimum, qctrl.maximum, qctrl.step);
+		break;
+	case V4L2_CID_SATURATION:
+		avt_dbg(sd, "V4L2_CID_SATURATION vc->value %u\n", vc->value);
+		reg = BCRM_SATURATION_32RW;
+		length = AV_CAM_DATA_SIZE_32;
+
+		ret = ioctl_queryctrl(sd, &qctrl);
+
+		if (ret < 0) {
+			avt_err(sd, "queryctrl failed: ret %d\n", ret);
+			return ret;
+		}
+
+		vc->value = convert_s_ctrl(vc->value,
+				qctrl.minimum, qctrl.maximum, qctrl.step);
+		break;
+	case V4L2_CID_HUE:
+		avt_dbg(sd, "V4L2_CID_HUE vc->value %u\n", vc->value);
+		reg = BCRM_HUE_32RW;
+		length = AV_CAM_DATA_SIZE_32;
+
+		ret = ioctl_queryctrl(sd, &qctrl);
+
+		if (ret < 0) {
+			avt_err(sd, "queryctrl failed: ret %d\n", ret);
+			return ret;
+		}
+
+		vc->value = convert_s_ctrl(vc->value,
+				qctrl.minimum, qctrl.maximum, qctrl.step);
+
+		break;
+	case V4L2_CID_RED_BALANCE:
+		avt_dbg(sd, "V4L2_CID_RED_BALANCE vc->value64 %llu\n", vc->value64);
+		reg = BCRM_RED_BALANCE_RATIO_64RW;
+		length = AV_CAM_DATA_SIZE_64;
+
+		ret = ioctl_queryctrl64(sd, &qctrl_ext);
+
+		if (ret < 0) {
+			avt_err(sd, "queryctrl failed: ret %d\n", ret);
+			return ret;
+		}
+
+		vc->value64 = convert_s_ctrl64(&qctrl_ext, vc->value64);
+		break;
+	case V4L2_CID_BLUE_BALANCE:
+		avt_dbg(sd, "V4L2_CID_BLUE_BALANCE vc->value64 %llu\n", vc->value64);
+		reg = BCRM_BLUE_BALANCE_RATIO_64RW;
+		length = AV_CAM_DATA_SIZE_64;
+
+		ret = ioctl_queryctrl64(sd, &qctrl_ext);
+
+		if (ret < 0) {
+			avt_err(sd, "queryctrl failed: ret %d\n", ret);
+			return ret;
+		}
+
+		vc->value64 = convert_s_ctrl64(&qctrl_ext, vc->value64);
+		break;
+
+	case V4L2_CID_AUTO_WHITE_BALANCE:
+		avt_dbg(sd, "V4L2_CID_AUTO_WHITE_BALANCE vc->value %u\n",
+				vc->value);
+		reg = BCRM_WHITE_BALANCE_AUTO_8RW;
+		length = AV_CAM_DATA_SIZE_8;
+
+		/* BCRM Auto White balance changes	*/
+		if (vc->value == true)
+			vc->value = 2;/* Continouous mode */
+		else
+			vc->value = 0;/* 1; OFF/once mode */
+
+		break;
+	case V4L2_CID_GAMMA:
+		avt_dbg(sd, "V4L2_CID_GAMMA vc->value64 %llu\n", vc->value64);
+		reg = BCRM_GAMMA_64RW;
+		length = AV_CAM_DATA_SIZE_64;
+
+		ret = ioctl_queryctrl64(sd, &qctrl_ext);
+
+		if (ret < 0) {
+			avt_err(sd, "queryctrl failed: ret %d\n", ret);
+			return ret;
+		}
+
+		vc->value64 = convert_s_ctrl64(&qctrl_ext, vc->value64);
+		break;
+	case V4L2_CID_EXPOSURE:
+		avt_dbg(sd, "V4L2_CID_EXPOSURE, cci_reg.bcrm_addr 0x%x, vc->value64 %llu\n",
+				priv->cci_reg.bcrm_addr, vc->value64);
+
+		value_bkp = vc->value64;/* backup the actual value */
+
+		/*  i) Setting 'Manual' in Exposure Auto reg. Refer to BCRM
+		 *  document
+		 */
+		vc->value = 0;
+
+		avt_dbg(sd, "V4L2_CID_EXPOSURE, cci_reg.bcrm_addr 0x%x, vc->value %u\n",
+				priv->cci_reg.bcrm_addr, vc->value);
+
+		ret = ioctl_bcrm_i2cwrite_reg(client,
+				vc, BCRM_EXPOSURE_AUTO_8RW + priv->cci_reg.bcrm_addr,
+				AV_CAM_DATA_SIZE_8);
+
+		if (ret < 0) {
+			avt_err(sd, "queryctrl failed: ret %d\n", ret);
+			return ret;
+		}
+
+		/* ii) Setting value in Exposure reg. */
+		vc->value64 = value_bkp;/* restore the actual value */
+		reg = BCRM_EXPOSURE_TIME_64RW;
+		length = AV_CAM_DATA_SIZE_64;
+
+		ret = ioctl_queryctrl64(sd, &qctrl_ext);
+
+		if (ret < 0) {
+			avt_err(sd, "queryctrl failed: ret %d\n", ret);
+			return ret;
+		}
+		vc->value64 = convert_s_ctrl64(&qctrl_ext, vc->value64);
+
+		/* Implicitly update exposure absolute */
+		priv->cross_update = true;
+		ret = __v4l2_ctrl_s_ctrl(avt_get_control(sd, V4L2_CID_EXPOSURE_ABSOLUTE), (int32_t)(vc->value64 / EXP_ABS));
+		if (ret) {
+			avt_err(sd, "failed to update exposure absolute: %d\n", ret);
+		}
+		priv->cross_update = false;
+
+		break;
+
+	case V4L2_CID_EXPOSURE_ABSOLUTE:
+		{
+			struct v4l2_ctrl *exposure_ctrl;
+			int res;
+
+			if (priv->cross_update) {
+				return 0;
+			}
+
+			exposure_ctrl = avt_get_control(sd,V4L2_CID_EXPOSURE);
+			res = __v4l2_ctrl_s_ctrl_int64(exposure_ctrl,(uint64_t)vc->value * EXP_ABS);
+
+			return res;
+		}
+
+	case V4L2_CID_EXPOSURE_AUTO:
+		avt_dbg(sd, "V4L2_CID_EXPOSURE_AUTO vc->value %u\n", vc->value);
+		reg = BCRM_EXPOSURE_AUTO_8RW;
+		length = AV_CAM_DATA_SIZE_8;
+
+		/* BCRM Auto Gain changes */
+		if (vc->value == V4L2_EXPOSURE_AUTO) {
+			vc->value = 2;/* Continouous mode */
+		} else {
+			vc->value = 0;/* 1; OFF/once mode */
+		}
+
+		break;
+
+	case V4L2_CID_AUTOGAIN:
+		avt_dbg(sd, "V4L2_CID_AUTOGAIN vc->value %u\n", vc->value);
+		reg = BCRM_GAIN_AUTO_8RW;
+		length = AV_CAM_DATA_SIZE_8;
+
+		/* BCRM Auto Gain changes */
+		if (vc->value == true)
+			vc->value = 2;/* Continouous mode */
+		else
+			vc->value = 0;/* 1; OFF/once mode */
+
+		break;
+	case V4L2_CID_GAIN:
+		avt_dbg(sd, "V4L2_CID_GAIN, vc->value64 %llu\n", vc->value64);
+		reg = BCRM_GAIN_64RW;
+		length = AV_CAM_DATA_SIZE_64;
+
+		ret = ioctl_queryctrl64(sd, &qctrl_ext);
+
+		if (ret < 0) {
+			avt_err(sd, "queryctrl failed: ret %d\n", ret);
+			return ret;
+		}
+
+		vc->value64 = convert_s_ctrl64(&qctrl_ext, vc->value64);
+
+		break;
+
+	case V4L2_CID_HFLIP:
+		avt_dbg(sd, "V4L2_CID_HFLIP, vc->value %u\n", vc->value);
+		reg = BCRM_IMG_REVERSE_X_8RW;
+		length = AV_CAM_DATA_SIZE_8;
+
+		ret = ioctl_queryctrl(sd, &qctrl);
+
+		if (ret < 0) {
+			avt_err(sd, "queryctrl failed: ret %d\n", ret);
+			return ret;
+		}
+
+		vc->value = convert_s_ctrl(vc->value,
+				qctrl.minimum, qctrl.maximum, qctrl.step);
+		break;
+
+	case V4L2_CID_VFLIP:
+		avt_dbg(sd, "V4L2_CID_VFLIP, vc->value %u\n", vc->value);
+		reg = BCRM_IMG_REVERSE_Y_8RW;
+		length = AV_CAM_DATA_SIZE_8;
+
+		ret = ioctl_queryctrl(sd, &qctrl);
+
+		if (ret < 0) {
+			avt_err(sd, "queryctrl failed: ret %d\n", ret);
+			return ret;
+		}
+
+		vc->value = convert_s_ctrl(vc->value,
+				qctrl.minimum, qctrl.maximum, qctrl.step);
+		break;
+
+	case V4L2_CID_SHARPNESS:
+		avt_dbg(sd, "V4L2_CID_SHARPNESS, vc->value %u\n", vc->value);
+		reg = BCRM_SHARPNESS_32RW;
+		length = AV_CAM_DATA_SIZE_32;
+
+		ret = ioctl_queryctrl(sd, &qctrl);
+
+		if (ret < 0) {
+			avt_err(sd, "queryctrl failed: ret %d\n", ret);
+			return ret;
+		}
+
+		vc->value = convert_s_ctrl(vc->value,
+				qctrl.minimum, qctrl.maximum, qctrl.step);
+		break;
+
+	case V4L2_CID_EXPOSURE_AUTO_MIN:
+		avt_dbg(sd, "V4L2_CID_EXPOSURE_AUTO_MIN, vc->value64 %llu\n", vc->value64);
+		reg = BCRM_EXPOSURE_AUTO_MIN_64RW;
+		length = AV_CAM_DATA_SIZE_64;
+
+		ret = ioctl_queryctrl64(sd, &qctrl_ext);
+
+		if (ret < 0) {
+			avt_err(sd, "queryctrl failed: ret %d\n", ret);
+			return ret;
+		}
+
+		vc->value64 = convert_s_ctrl64(&qctrl_ext, vc->value64);
+		break;
+
+	case V4L2_CID_EXPOSURE_AUTO_MAX:
+		avt_dbg(sd, "V4L2_CID_EXPOSURE_AUTO_MAX, vc->value64 %llu\n", vc->value64);
+		reg = BCRM_EXPOSURE_AUTO_MAX_64RW;
+		length = AV_CAM_DATA_SIZE_64;
+
+		ret = ioctl_queryctrl64(sd, &qctrl_ext);
+
+		if (ret < 0) {
+			avt_err(sd, "queryctrl failed: ret %d\n", ret);
+			return ret;
+		}
+
+		vc->value64 = convert_s_ctrl64(&qctrl_ext, vc->value64);
+		break;
+
+	case V4L2_CID_GAIN_AUTO_MIN:
+		avt_dbg(sd, "V4L2_CID_GAIN_AUTO_MIN, vc->value %llu\n", vc->value64);
+		reg = BCRM_GAIN_AUTO_MIN_64RW;
+		length = AV_CAM_DATA_SIZE_64;
+
+		qctrl.id = V4L2_CID_GAIN_AUTO_MIN;
+		ret = ioctl_queryctrl64(sd, &qctrl_ext);
+
+		if (ret < 0) {
+			avt_err(sd, "queryctrl failed: ret %d\n", ret);
+			return ret;
+		}
+
+		vc->value64 = convert_s_ctrl64(&qctrl_ext, vc->value64);
+		break;
+
+	case V4L2_CID_GAIN_AUTO_MAX:
+		avt_dbg(sd, "V4L2_CID_GAIN_AUTO_MAX, vc->value %llu\n", vc->value64);
+		reg = BCRM_GAIN_AUTO_MAX_64RW;
+		length = AV_CAM_DATA_SIZE_64;
+
+		qctrl.id = V4L2_CID_GAIN_AUTO_MAX;
+		ret = ioctl_queryctrl64(sd, &qctrl_ext);
+
+		if (ret < 0) {
+			avt_err(sd, "queryctrl failed: ret %d\n", ret);
+			return ret;
+		}
+
+		vc->value64 = convert_s_ctrl64(&qctrl_ext, vc->value64);
+		break;
+
+	case V4L2_CID_EXPOSURE_ACTIVE_LINE_MODE:
+		return avt_set_acquisition_active_mode(sd, vc->value);
+
+	case V4L2_CID_EXPOSURE_ACTIVE_LINE_SELECTOR:
+		return avt_set_acquitision_active_line(sd, vc->value);
+
+	case V4L2_CID_EXPOSURE_ACTIVE_INVERT:
+		return avt_set_acquisition_active_invert(sd, vc->value);
+
+	case V4L2_CID_TRIGGER_MODE:
+		avt_dbg(sd, "case V4L2_CID_TRIGGER_MODE vc->value %u\n", vc->value);
+		if(vc->value==0)
+		{/*trigger mode off*/
+			ret = avt_reg_write(client,
+					priv->cci_reg.bcrm_addr + BCRM_FRAME_START_TRIGGER_MODE_8RW, 0);
+			if (ret < 0) {
+				return ret;
+			}
+			set_channel_trigger_mode(sd, false);
+			set_channel_timeout(sd, CAPTURE_TIMEOUT_MS);
+			priv->trigger_mode=false;
+		}
+		else
+		{/*trigger mode off*/
+			ret = avt_reg_write(client,
+					priv->cci_reg.bcrm_addr + BCRM_FRAME_START_TRIGGER_MODE_8RW, 1);
+			if (ret < 0) {
+				return ret;
+			}
+			set_channel_trigger_mode(sd, true);
+			set_channel_timeout(sd, AVT_TEGRA_TIMEOUT_DISABLED);
+			priv->trigger_mode=true;
+		}
+		return 0;
+		
+	case V4L2_CID_TRIGGER_ACTIVATION:
+		avt_dbg(sd, "case V4L2_CID_TRIGGER_ACTIVATION vc->value %u\n", vc->value);
+        /* Setting Frame Start Trigger Activation */
+        ret = avt_reg_write(client,
+            priv->cci_reg.bcrm_addr + BCRM_FRAME_START_TRIGGER_ACTIVATION_8RW, vc->value);
+
+        if (ret < 0) {
+            return ret;
+        }
+		return 0;
+		
+	case V4L2_CID_TRIGGER_SOURCE:
+	{
+		u8 cur_trigger_source;
+		u8 trigger_source_reg=vc->value;
+		avt_dbg(sd, "case V4L2_CID_TRIGGER_SOURCE vc->value %u\n", vc->value);
+		if(trigger_source_reg > V4L2_TRIGGER_SOURCE_SOFTWARE)
+		{
+			avt_err(sd, " invalid trigger source (%d)", trigger_source_reg);
+            return -1;
+		}
+		/* Check if we need to write to Trigger Source register.
+		* If we do this more than once in the power cycle,
+		* triggering non-empty frames is not  possible.
+		*/
+		ret = avt_reg_read(client,
+			priv->cci_reg.bcrm_addr +
+			BCRM_FRAME_START_TRIGGER_SOURCE_8RW,
+			AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_8,
+			(char *) &cur_trigger_source);
+
+		if (ret < 0) {
+			return ret;
+		}
+
+		if (cur_trigger_source == trigger_source_reg) {
+			avt_err(sd, " Trigger source already set!\n");
+			return 0;
+		}
+
+		ret = avt_reg_write(client,
+			priv->cci_reg.bcrm_addr + BCRM_FRAME_START_TRIGGER_SOURCE_8RW, trigger_source_reg);
+
+		if (ret < 0) {
+			return ret;
+		}
+		return 0;
+	}		
+	case V4L2_CID_TRIGGER_SOFTWARE:
+	{
+		u8 trigger_source;
+		avt_dbg(sd, "case V4L2_CID_TRIGGER_SOFTWARE\n");
+
+        ret = avt_reg_read(client, priv->cci_reg.bcrm_addr + BCRM_FRAME_START_TRIGGER_SOURCE_8RW, 
+			AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_8, (char *) &trigger_source);
+
+        if (ret < 0) {
+            return ret;
+        }
+
+        if (trigger_source != AV_CAM_SOFTWARE_TRIGGER) {
+            return -EPERM;
+        }
+
+		/* Check if stream is already on */
+		if (!priv->stream_on)
+			return -EAGAIN;
+
+		/* Generate Trigger */
+		ret = avt_reg_write(client,
+			priv->cci_reg.bcrm_addr + BCRM_FRAME_START_TRIGGER_SOFTWARE_8W, 1);
+    
+		if (ret < 0) {
+			avt_err(sd, "generating trigger failed (%d)\n", ret);
+			return ret;
+		}
+		set_channel_pending_trigger(sd);
+		return 0;
+	}
+
+	default:
+		avt_err(sd, "case default or not supported\n");
+		ret = -EPERM;
+		return ret;
+	}
+
+	ret = ioctl_bcrm_i2cwrite_reg(client,
+			vc, reg + priv->cci_reg.bcrm_addr, length);
+
+	if (ret < 0) {
+		avt_err(sd, "i2c write failed failed (%d)\n", ret);
+		return ret;
+	}
+
+	if (vc->id == V4L2_CID_EXPOSURE)
+	{
+		uint64_t value64;
+		struct v4l2_fract *tpf = (&priv->streamcap.timeperframe);
+
+		ret = avt_reg_read(client,
+						   priv->cci_reg.bcrm_addr + BCRM_ACQUISITION_FRAME_RATE_64RW,
+						   AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+						   (char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "BCRM_ACQUISITION_FRAME_RATE_64RW: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		tpf->numerator = FRAQ_NUM;
+		tpf->denominator = value64 / FRAQ_NUM;
+	}
+
+	if(register_readback_required(vc->id)) {
+		ret = register_readback64(sd, vc->id, reg);
+	}
+
+	return ret < 0 ? ret : 0;
+}
+
+static int avt_s_ctrl(struct v4l2_ctrl *ctrl)
+{
+	struct v4l2_subdev *sd;
+	struct v4l2_ext_control c;
+
+	struct avt_csi2_priv *priv;
+
+	if (ctrl->flags & V4L2_CTRL_FLAG_INACTIVE)
+		return 0;
+
+	priv = container_of(ctrl->handler, struct avt_csi2_priv, hdl);
+	sd = priv->subdev;
+
+
+	if(priv->ignore_control_write) {
+		return 0;
+	}
+
+	c.id = ctrl->id;
+	c.value = ctrl->val;
+	/* For 64-bit extended V4L2 controls,
+	 * new value comes in this pointer
+	 */
+	c.value64 = *(ctrl->p_new.p_s64);
+
+	return avt_ioctl_s_ctrl(sd, &c);
+}
+
+static int avt_g_volatile_ctrl(struct v4l2_ctrl *ctrl)
+{
+	struct v4l2_subdev *sd;
+	struct v4l2_ext_control c;
+	struct avt_csi2_priv *priv;
+	int ret;
+
+	priv = container_of(ctrl->handler, struct avt_csi2_priv, hdl);
+	sd = priv->subdev;
+
+	c.id = ctrl->id;
+	ret = avt_ioctl_g_ctrl(sd, &c);
+	ctrl->val = c.value;
+	*(ctrl->p_new.p_s64)=c.value64;
+
+	if(ret < 0) {
+		return ret;
+	}
+
+	return 0;
+}
+
+static const struct v4l2_ctrl_ops avt_ctrl_ops = {
+	.g_volatile_ctrl = avt_g_volatile_ctrl,
+	.s_ctrl		= avt_s_ctrl,
+};
+
+static int read_max_resolution(struct v4l2_subdev *sd, uint32_t *max_width, uint32_t *max_height)
+{
+	struct i2c_client *client = v4l2_get_subdevdata(sd);
+	int ret = 0;
+
+	ret = avt_get_param(client, V4L2_AV_CSI2_WIDTH_MAXVAL_R, max_width);
+	if (ret < 0)
+		return ret;
+
+	ret = avt_get_param(client, V4L2_AV_CSI2_HEIGHT_MAXVAL_R, max_height);
+	if (ret < 0)
+		return ret;
+
+	return ret;
+}
+
+static int avt_cropcap(struct v4l2_subdev *sd, struct v4l2_cropcap *cc)
+{
+	uint32_t max_width = 0, max_height = 0;
+
+	if (cc->pixelaspect.numerator != 1 ||
+			cc->type != V4L2_BUF_TYPE_VIDEO_CAPTURE) {
+		return -EINVAL;
+	}
+
+	if(read_max_resolution(sd, &max_width, &max_height) < 0)
+	{
+		return -EINVAL;
+	}
+
+	cc->bounds.top = cc->bounds.left = 0;
+	cc->defrect.top = cc->defrect.left = 0;
+
+	cc->bounds.width = cc->defrect.width = max_width;
+	cc->bounds.height = cc->defrect.height = max_height;
+
+	// align defrect if alignment is enabled
+	cc->defrect.width = avt_align_width(sd, cc->defrect.width);
+    avt_info(sd, "Default crop rect width %d\n", cc->defrect.width);
+
+	return 0;
+}
+
+static int avt_get_selection(struct v4l2_subdev *sd,
+		struct v4l2_subdev_pad_config *cfg,
+		struct v4l2_subdev_selection *sel)
+{
+	struct avt_csi2_priv *priv = avt_get_priv(sd);
+	uint32_t max_width = 0, max_height = 0;
+
+	if(read_max_resolution(sd, &max_width, &max_height) < 0)
+	{
+		return -EINVAL;
+	}
+    
+ 	switch (sel->target) {
+	case V4L2_SEL_TGT_COMPOSE_DEFAULT:
+	case V4L2_SEL_TGT_COMPOSE_BOUNDS:
+	case V4L2_SEL_TGT_COMPOSE:
+	case V4L2_SEL_TGT_CROP:
+		sel->r = priv->frmp.r;
+		break;
+	case V4L2_SEL_TGT_CROP_DEFAULT:
+	case V4L2_SEL_TGT_NATIVE_SIZE:
+	case V4L2_SEL_TGT_CROP_BOUNDS:
+		sel->r.top = sel->r.left = 0;
+		sel->r.width = max_width;
+		sel->r.height = max_height;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	sel->flags = V4L2_SEL_FLAG_LE;
+
+	return 0;
+}
+
+static int avt_g_crop(struct v4l2_subdev *sd, struct v4l2_crop *crop)
+{
+	struct v4l2_subdev_selection sel;
+
+	sel.target = V4L2_SEL_TGT_CROP;
+
+	avt_get_selection(sd, NULL, &sel);
+
+	memcpy(&crop->c, &sel.r, sizeof(struct v4l2_rect));
+
+	return 0;
+}
+
+static int avt_get_align_width(struct v4l2_subdev *sd)
+{
+    struct avt_csi2_priv *priv = avt_get_priv(sd);
+    int width_align = 0;
+
+	if (priv->crop_align_enabled) {
+		/*
+		* Align with VI capabilities
+		*
+		* For each format line length has to be aligned to specific
+		* value
+		*/
+		switch (priv->mbus_fmt_code) {
+		case MEDIA_BUS_FMT_RGB888_1X24:
+		case MEDIA_BUS_FMT_BGR888_1X24:
+			width_align = 16;
+            break;
+
+		case MEDIA_BUS_FMT_VYUY8_2X8:
+		case MEDIA_BUS_FMT_RGB565_1X16:
+			width_align = 32;
+            break;
+
+		case MEDIA_BUS_FMT_SRGGB8_1X8:
+        case MEDIA_BUS_FMT_SGBRG8_1X8:
+        case MEDIA_BUS_FMT_SGRBG8_1X8:
+        case MEDIA_BUS_FMT_SBGGR8_1X8:
+            width_align = 16;
+            break;
+
+		default:
+			width_align = 64;
+            break;
+		}
+	}
+
+    /* Use kernel param override? */
+    if (v4l2_width_align != 0)
+    {
+        width_align = v4l2_width_align;
+        avt_warn(sd, "v4l2_width_align override: %d\n", width_align);
+    }
+
+	return width_align;
+}
+
+static int avt_align_width(struct v4l2_subdev *sd, int width)
+{
+    struct avt_csi2_priv *priv = avt_get_priv(sd);
+    avt_dbg(sd, "input width: %d\n", width);
+	if (priv->crop_align_enabled) {
+		int const align_size = avt_get_align_width(sd);
+        avt_dbg(sd, "align_size: %d\n", align_size);
+
+		width = roundup(width, align_size);
+		if (width > priv->frmp.maxw) {
+			width -= align_size;
+		}
+        avt_dbg(sd, "output width: %d\n", width);
+    }
+    else
+    {
+        avt_dbg(sd, "crop_align_enabled DISABLED\n");
+    }
+    
+	return width;
+}
+
+static int avt_set_selection(struct v4l2_subdev *sd,
+		struct v4l2_subdev_pad_config *cfg,
+		struct v4l2_subdev_selection *sel)
+{
+	struct i2c_client *client = v4l2_get_subdevdata(sd);
+	struct avt_csi2_priv *priv = avt_get_priv(sd);
+
+	// update width, height, offset x/y restrictions from camera
+	avt_init_frame_param(sd);
+
+	switch (sel->target) {
+	case V4L2_SEL_TGT_CROP:
+
+		if (priv->crop_align_enabled) {
+			sel->r.width = avt_align_width(sd, sel->r.width);
+		}
+
+/*
+*       As per the crop concept document, the following steps should be followed before setting crop to the sensor.
+*
+* i)    If new width is less or equal than current width, write the width register first then write offset X (left) register,
+*       both values should be within the range (min, max and inc).
+* ii)   If new width is higher than current width, write the offset X (left) register first then write the width register,
+*       both values should be within the range (min, max, and inc)
+* iii)  If new height is less or equal than current height, write the height register first then write offset Y (top) register,
+*       both values should be within the range (min, max and inc).
+* iv)   If new height is higher than current height, write the offset Y (top) register first then write the height register,
+*       both values should be within the range (min, max, and inc)
+*/
+
+		if (sel->r.width <= priv->frmp.r.width) { /* case i) New width is lesser or equal than current */
+
+			// write width
+			sel->r.width = clamp(roundup(sel->r.width, priv->frmp.sw), priv->frmp.minw, priv->frmp.maxw);
+			avt_set_param(client, V4L2_AV_CSI2_WIDTH_W, sel->r.width);
+
+			// update width, height, offset x/y restrictions from camera
+			avt_init_frame_param(sd);
+
+			// write offset x
+			sel->r.left = clamp(roundup(sel->r.left, priv->frmp.swoff), priv->frmp.minwoff, priv->frmp.maxwoff);
+			avt_set_param(client, V4L2_AV_CSI2_OFFSET_X_W, sel->r.left);
+		}
+		else { /* case ii) New width is higher than current */
+
+			// write offset x
+			sel->r.left = clamp(roundup(sel->r.left, priv->frmp.swoff), priv->frmp.minwoff, priv->frmp.maxwoff);
+			avt_set_param(client, V4L2_AV_CSI2_OFFSET_X_W, sel->r.left);
+
+			// update width, height, offset x/y restrictions from camera
+			avt_init_frame_param(sd);
+
+			// write width
+			sel->r.width = clamp(roundup(sel->r.width, priv->frmp.sw), priv->frmp.minw, priv->frmp.maxw);
+			avt_set_param(client, V4L2_AV_CSI2_WIDTH_W, sel->r.width);
+		}
+
+		if (sel->r.height <= priv->frmp.r.height) { /* case iii) New height is lesser or equal than current */
+			// write height
+			sel->r.height = clamp(roundup(sel->r.height, priv->frmp.sh), priv->frmp.minh, priv->frmp.maxh);
+			avt_set_param(client, V4L2_AV_CSI2_HEIGHT_W, sel->r.height);
+
+			// update width, height, offset x/y restrictions from camera
+			avt_init_frame_param(sd);
+
+			// write offset y
+			sel->r.top = clamp(roundup(sel->r.top, priv->frmp.shoff), priv->frmp.minhoff, priv->frmp.maxhoff);
+			avt_set_param(client, V4L2_AV_CSI2_OFFSET_Y_W, sel->r.top);
+		}
+		else { /* case iv) New height is higher than current */
+
+			// write offset y
+			sel->r.top = clamp(roundup(sel->r.top, priv->frmp.shoff), priv->frmp.minhoff, priv->frmp.maxhoff);
+			avt_set_param(client, V4L2_AV_CSI2_OFFSET_Y_W, sel->r.top);
+
+			// update width, height, offset x/y restrictions from camera
+			avt_init_frame_param(sd);
+
+			// write height
+			sel->r.height = clamp(roundup(sel->r.height, priv->frmp.sh), priv->frmp.minh, priv->frmp.maxh);
+			avt_set_param(client, V4L2_AV_CSI2_HEIGHT_W, sel->r.height);
+		}
+
+		// update width, height, offset x/y restrictions from camera
+		avt_init_frame_param(sd);
+
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static int avt_s_crop(struct v4l2_subdev *sd, const struct v4l2_crop *crop)
+{
+	struct v4l2_subdev_selection sel;
+
+	sel.target = V4L2_SEL_TGT_CROP;
+
+	memcpy(&sel.r, &crop->c, sizeof(struct v4l2_rect));
+
+	return avt_set_selection(sd, NULL, &sel);
+}
+
+static int avt_s_parm(struct v4l2_subdev *sd, struct v4l2_streamparm *parm)
+{
+	struct i2c_client *client = v4l2_get_subdevdata(sd);
+	struct camera_common_data *s_data = to_camera_common_data(&client->dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+	struct v4l2_fract *tpf = &(priv->streamcap.timeperframe);
+	struct v4l2_ext_control vc;
+	int ret;
+    struct v4l2_query_ext_ctrl qctrl;
+    u64 value64;
+	union bcrm_feature_reg feature_inquiry_reg;
+
+    parm->parm.capture.capability = V4L2_CAP_TIMEPERFRAME;
+    parm->parm.capture.readbuffers = 1;
+
+	/* reading the Feature inquiry register */
+	ret = read_feature_register(sd, &feature_inquiry_reg);
+	if (ret < 0) {
+		avt_err(sd, "i2c read failed (%d)\n", ret);
+		return ret;
+	}
+
+	/* Check if setting acquisition frame rate is available */
+	if(!feature_inquiry_reg.feature_inq.acquisition_frame_rate) {
+			avt_info(sd, "Acquisition frame rate setting not supported by firmware\n");
+			return 0;
+	}
+
+	/* Copy new settings to internal structure */
+	memcpy(&priv->streamcap, &parm->parm.capture, sizeof(struct v4l2_captureparm));
+
+
+	avt_dbg(sd, "[mjsob] %u/%u\n", tpf->denominator, tpf->numerator);
+
+	if (tpf->numerator == 0 || tpf->denominator == 0) {
+
+		/* Enable auto frame rate */
+		vc.value = 0;
+		ret = ioctl_bcrm_i2cwrite_reg(client, &vc, priv->cci_reg.bcrm_addr + BCRM_ACQUISITION_FRAME_RATE_ENABLE_8RW, AV_CAM_DATA_SIZE_8);
+		if (ret < 0) {
+			avt_err(sd, "ACQUISITION_FRAME_RATE_64RW: i2c write failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+        ret = avt_reg_read(client,
+                           priv->cci_reg.bcrm_addr + BCRM_ACQUISITION_FRAME_RATE_64RW,
+                           AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+                           (char *) &value64);
+        if (ret < 0) {
+            avt_err(sd, "BCRM_ACQUISITION_FRAME_RATE_64RW: i2c read failed (%d)\n",
+                    ret);
+            return ret;
+        }
+
+        tpf->numerator = FRAQ_NUM;
+        tpf->denominator = 0;
+
+        /* Copy modified settings back */
+        memcpy(&parm->parm.capture, &priv->streamcap, sizeof(struct v4l2_captureparm));
+
+	} else {
+		/* Enable and set manual frame rate */
+
+		/* reading the Minimum Frame Rate Level */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_ACQUISITION_FRAME_RATE_MIN_64R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "ACQUISITION_FRAME_RATE_MIN_64R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl.minimum = value64;
+
+		/* reading the Maximum Frame Rate Level */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_ACQUISITION_FRAME_RATE_MAX_64R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "ACQUISITION_FRAME_RATE_MAX_64R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+        qctrl.maximum = value64;
+
+		/* reading the Frame Rate Level step increment */
+		ret = avt_reg_read(client,
+				priv->cci_reg.bcrm_addr + BCRM_ACQUISITION_FRAME_RATE_INC_64R,
+				AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+				(char *) &value64);
+		if (ret < 0) {
+			avt_err(sd, "ACQUISITION_FRAME_RATE_INCREMENT_64R: i2c read failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		qctrl.step = value64;
+
+		/* Set step to 1 uHz because zero value came from camera register */
+		if(!qctrl.step)
+            qctrl.step = 1;
+
+		if (qctrl.minimum > qctrl.maximum) {
+			avt_err(sd, "Frame rate: min > max! (%llu > %llu)\n",
+                    qctrl.minimum, qctrl.maximum);
+			return -EINVAL;
+		}
+		if (qctrl.step <= 0) {
+			avt_err(sd, "Frame rate: non-positive step value (%llu)!\n",
+                    qctrl.step);
+			return -EINVAL;
+		}
+
+		/* Translate timeperframe to frequency
+		 * by inverting the fraction
+		 */
+        value64 = (tpf->denominator * UHZ_TO_HZ) / tpf->numerator;
+        value64 = convert_s_ctrl64(&qctrl,value64);
+
+        if (value64 < 0) {
+			avt_err(sd, "Frame rate: non-positive value (%llu)!\n",
+					value64);
+			return -EINVAL;
+		}
+
+		/* Enable manual frame rate */
+		vc.value = 1;
+		ret = ioctl_bcrm_i2cwrite_reg(client, &vc, priv->cci_reg.bcrm_addr + BCRM_ACQUISITION_FRAME_RATE_ENABLE_8RW, AV_CAM_DATA_SIZE_8);
+		if (ret < 0) {
+			avt_err(sd, "ACQUISITION_FRAME_RATE_64RW: i2c write failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+		/* Save new frame rate to camera register */
+		vc.value64 = value64;
+		ret = ioctl_bcrm_i2cwrite_reg(client, &vc, priv->cci_reg.bcrm_addr + BCRM_ACQUISITION_FRAME_RATE_64RW, AV_CAM_DATA_SIZE_64);
+		if (ret < 0) {
+			avt_err(sd, "ACQUISITION_FRAME_RATE_64RW: i2c write failed (%d)\n",
+					ret);
+			return ret;
+		}
+
+        //Check if result of division will be between 0 and 1, if it is so increase numerator
+        if (value64 < FRAQ_NUM) {
+            tpf->numerator = FRAQ_NUM * FRAQ_NUM;
+            tpf->denominator = value64;
+        }
+        else {
+            tpf->numerator = FRAQ_NUM;
+            tpf->denominator = value64 / FRAQ_NUM;
+        }
+
+		/* Copy modified settings back */
+		memcpy(&parm->parm.capture, &priv->streamcap, sizeof(struct v4l2_captureparm));
+	}
+
+	return 0;
+}
+
+static int avt_g_parm(struct v4l2_subdev *sd, struct v4l2_streamparm *parm)
+{
+	struct i2c_client *client = v4l2_get_subdevdata(sd);
+	struct camera_common_data *s_data = to_camera_common_data(&client->dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+
+	memcpy(&parm->parm.capture, &priv->streamcap, sizeof(struct v4l2_captureparm));
+
+	return 0;
+}
+
+static int avt_csi2_open(struct v4l2_subdev *sd, struct v4l2_subdev_fh *fh)
+{
+	// called when userspace app calls 'open'
+	struct avt_csi2_priv *priv = avt_get_priv(sd);
+	int ret;
+	uint32_t i2c_reg;
+	uint32_t i2c_reg_size;
+	uint32_t i2c_reg_count;
+    const uint32_t poll_delay_ms = 2;
+    const uint32_t timeout_ms = 3000;
+    unsigned long timeout_jiffies = 0;
+	uint8_t bcm_mode = 0;
+	char *i2c_reg_buf;
+
+	// set stride align
+	if (priv->stride_align_enabled)
+		set_channel_stride_align_for_format(sd, priv->mbus_fmt_code);
+	else
+		set_channel_stride_align(sd, 1);
+
+	// set BCRM mode if required
+	ret = avt_reg_read(priv->client, CCI_CURRENT_MODE_8R, AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_8, &bcm_mode);
+    if (ret < 0) {
+        avt_err(sd, "Failed to get device mode: i2c read failed (%d)\n", ret);
+        return ret;
+    }
+    else
+    {
+        avt_dbg(sd, "Initial device mode=%u (%s)\n", bcm_mode, (bcm_mode==0) ? "BCRM" : "GenCP");
+    }
+
+	if (bcm_mode != OPERATION_MODE_BCRM)
+	{
+                // GenCP mode -> Switch back to BCRM
+		CLEAR(i2c_reg);
+        bcm_mode = OPERATION_MODE_BCRM;
+		i2c_reg = CCI_CHANGE_MODE_8W;
+		i2c_reg_size = AV_CAM_REG_SIZE;
+		i2c_reg_count = AV_CAM_DATA_SIZE_8;
+		i2c_reg_buf = (char *)&bcm_mode;
+        timeout_jiffies = jiffies + msecs_to_jiffies(timeout_ms);
+
+		ret = ioctl_gencam_i2cwrite_reg(priv->client,
+						i2c_reg, i2c_reg_size,
+						i2c_reg_count, i2c_reg_buf);
+		if (ret < 0)
+		{
+			avt_err(sd, "Failed to set BCM mode: i2c write failed (%d)\n", ret);
+			return ret;
+		}
+
+        // Wait for mode change
+        do
+        {
+            usleep_range(poll_delay_ms*1000, (poll_delay_ms*1000)+1);
+            ret = avt_reg_read(priv->client, CCI_CURRENT_MODE_8R, AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_8, &bcm_mode);
+        } while ((ret >=0 ) && (bcm_mode != OPERATION_MODE_BCRM) && time_before(jiffies, timeout_jiffies));
+
+        if (bcm_mode != OPERATION_MODE_BCRM)
+        {
+            return -EINVAL;
+        }
+	}
+
+	priv->mode = AVT_BCRM_MODE;
+
+	return 0;
+}
+
+int avt_csi2_reset(struct v4l2_subdev *sd, u32 val)
+{
+    struct avt_csi2_priv *priv = avt_get_priv(sd);
+
+    if (0 == val)
+    {
+        int ret = soft_reset(priv->client);
+
+        if (ret < 0)
+        {
+            return ret;
+        }
+
+        set_channel_avt_cam_mode(sd,0);
+
+        return avt_init_mode(sd);
+    }
+
+    return -EINVAL;
+}
+
+
+static const struct v4l2_subdev_core_ops avt_csi2_core_ops = {
+	.subscribe_event = avt_csi2_subscribe_event,
+	.unsubscribe_event = v4l2_event_subdev_unsubscribe,
+	.ioctl = avt_csi2_ioctl,
+    .reset = avt_csi2_reset,
+};
+
+static const struct v4l2_subdev_internal_ops avt_csi2_int_ops = {
+	.open = avt_csi2_open,
+};
+
+static const struct v4l2_subdev_video_ops avt_csi2_video_ops = {
+	.g_mbus_config = avt_csi2_g_mbus_config,
+	.s_stream = avt_csi2_s_stream,
+	.cropcap = avt_cropcap,
+	.s_crop = avt_s_crop,
+	.g_crop = avt_g_crop,
+	.s_parm = avt_s_parm,
+	.g_parm = avt_g_parm,
+};
+
+static const struct v4l2_subdev_pad_ops avt_csi2_pad_ops = {
+	.set_fmt = avt_csi2_set_fmt,
+	.get_fmt = avt_csi2_get_fmt,
+	.enum_mbus_code = avt_csi2_enum_mbus_code,
+	.enum_frame_size = avt_csi2_enum_framesizes,
+	.enum_frame_interval = avt_csi2_enum_frameintervals,
+	.get_selection = avt_get_selection,
+	.set_selection = avt_set_selection,
+};
+
+static const struct v4l2_subdev_ops avt_csi2_subdev_ops = {
+	.core = &avt_csi2_core_ops,
+	.video = &avt_csi2_video_ops,
+	.pad = &avt_csi2_pad_ops,
+};
+
+static const struct media_entity_operations avt_csi2_media_ops = {
+	.link_validate = v4l2_subdev_link_validate,
+};
+
+const struct of_device_id avt_csi2_of_match[] = {
+	{ .compatible = "alliedvision,avt_csi2",},
+	{ },
+};
+
+MODULE_DEVICE_TABLE(of, avt_csi2_of_match);
+
+static int read_cci_registers(struct i2c_client *client)
+{
+	struct camera_common_data *s_data = to_camera_common_data(&client->dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+
+	int ret = 0;
+	uint32_t crc = 0;
+	uint32_t crc_byte_count = 0;
+
+	uint32_t i2c_reg;
+	uint32_t i2c_reg_size;
+	uint32_t i2c_reg_count;
+
+	char *i2c_reg_buf;
+
+	i2c_reg = cci_cmd_tbl[CCI_REGISTER_LAYOUT_VERSION].address;
+	i2c_reg_size = AV_CAM_REG_SIZE;
+	/*
+	 * Avoid last 4 bytes read as its WRITE only register except
+	 * CURRENT MODE REG
+	 */
+	i2c_reg_count = sizeof(priv->cci_reg) - 4;
+
+	i2c_reg_buf = (char *)&priv->cci_reg;
+	/* Calculate CRC from each reg up to the CRC reg */
+	crc_byte_count =
+		(uint32_t)((char *)&priv->cci_reg.checksum - (char *)&priv->cci_reg);
+
+	dev_info(&client->dev, "crc_byte_count = %d, i2c_reg.count = %d\n",
+			crc_byte_count, i2c_reg_count);
+
+	/* read CCI registers */
+	ret = i2c_read(client, i2c_reg, i2c_reg_size,
+			i2c_reg_count, i2c_reg_buf);
+
+	if (ret < 0) {
+		dev_err(&client->dev, "Camera not responding. Error=%d\n", ret);
+		return ret;
+	}
+
+        /* CRC calculation */
+	crc = crc32(U32_MAX, &priv->cci_reg, crc_byte_count);
+
+        /* Swap bytes if neccessary */
+	cpu_to_be32s(&priv->cci_reg.layout_version);
+	cpu_to_be64s(&priv->cci_reg.device_capabilities);
+	cpu_to_be16s(&priv->cci_reg.gcprm_address);
+	cpu_to_be16s(&priv->cci_reg.bcrm_addr);
+	cpu_to_be32s(&priv->cci_reg.checksum);
+
+        /* Check the checksum of received with calculated. */
+	if (crc != priv->cci_reg.checksum) {
+		dev_err(&client->dev,
+			"wrong CCI CRC value! calculated = 0x%08x, received = 0x%08x\n",
+			crc, priv->cci_reg.checksum);
+		return -EINVAL;
+	}
+
+	dev_info(&client->dev, "cci layout version: 0x%08x\n",
+			priv->cci_reg.layout_version);
+	dev_info(&client->dev, "cci device capabilities: 0x%016llx\n",
+			priv->cci_reg.device_capabilities);
+    dev_info(&client->dev, "cci device guid: %s\n",
+            priv->cci_reg.device_guid);
+    dev_info(&client->dev, "cci gcprm_address: 0x%04x\n",
+            priv->cci_reg.gcprm_address);
+    dev_info(&client->dev, "cci bcrm_address: 0x%04x\n",
+            priv->cci_reg.bcrm_addr);
+    dev_info(&client->dev, "cci device guid: %s\n",
+            priv->cci_reg.device_guid);
+    dev_info(&client->dev, "cci manufacturer_name: %s\n",
+            priv->cci_reg.manufacturer_name);
+    dev_info(&client->dev, "cci model_name: %s\n",
+            priv->cci_reg.model_name);
+    dev_info(&client->dev, "cci family_name: %s\n",
+            priv->cci_reg.family_name);
+    dev_info(&client->dev, "cci device_version: %s\n",
+            priv->cci_reg.device_version);
+    dev_info(&client->dev, "cci manufacturer_info: %s\n",
+            priv->cci_reg.manufacturer_info);
+    dev_info(&client->dev, "cci serial_number: %s\n",
+            priv->cci_reg.serial_number);
+    dev_info(&client->dev, "cci user_defined_name: %s\n",
+            priv->cci_reg.user_defined_name);
+
+	return 0;
+}
+
+static int read_gencp_registers(struct i2c_client *client)
+{
+	struct camera_common_data *s_data = to_camera_common_data(&client->dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+
+	int ret = 0;
+	uint32_t crc = 0;
+	uint32_t crc_byte_count = 0;
+
+	uint32_t i2c_reg;
+	uint32_t i2c_reg_size;
+	uint32_t i2c_reg_count;
+
+	char *i2c_reg_buf;
+
+	i2c_reg = priv->cci_reg.gcprm_address + 0x0000;
+	i2c_reg_size = AV_CAM_REG_SIZE;
+	i2c_reg_count = sizeof(priv->gencp_reg);
+	i2c_reg_buf = (char *)&priv->gencp_reg;
+
+	/* Calculate CRC from each reg up to the CRC reg */
+	crc_byte_count =
+		(uint32_t)((char *)&priv->gencp_reg.checksum - (char *)&priv->gencp_reg);
+
+	ret = i2c_read(client, i2c_reg, i2c_reg_size,
+			i2c_reg_count, i2c_reg_buf);
+
+	crc = crc32(U32_MAX, &priv->gencp_reg, crc_byte_count);
+
+	if (ret < 0) {
+		pr_err("%s : I2C read failed, ret %d\n", __func__, ret);
+		return ret;
+	}
+
+	be32_to_cpus(&priv->gencp_reg.gcprm_layout_version);
+	be16_to_cpus(&priv->gencp_reg.gencp_out_buffer_address);
+	be16_to_cpus(&priv->gencp_reg.gencp_in_buffer_address);
+	be16_to_cpus(&priv->gencp_reg.gencp_out_buffer_size);
+	be16_to_cpus(&priv->gencp_reg.gencp_in_buffer_size);
+	be32_to_cpus(&priv->gencp_reg.checksum);
+
+	if (crc != priv->gencp_reg.checksum) {
+		dev_warn(&client->dev,
+			"wrong GENCP CRC value! calculated = 0x%08x, received = 0x%08x\n",
+			crc, priv->gencp_reg.checksum);
+	}
+
+	dev_info(&client->dev, "gcprm layout version: 0x%08x\n",
+		priv->gencp_reg.gcprm_layout_version);
+	dev_info(&client->dev, "gcprm out buf addr: 0x%04x\n",
+		priv->gencp_reg.gencp_out_buffer_address);
+	dev_info(&client->dev, "gcprm out buf size: 0x%04x\n",
+		priv->gencp_reg.gencp_out_buffer_size);
+	dev_info(&client->dev, "gcprm in buf addr: 0x%04x\n",
+		priv->gencp_reg.gencp_in_buffer_address);
+	dev_info(&client->dev, "gcprm in buf size: 0x%04x\n",
+		priv->gencp_reg.gencp_in_buffer_size);
+
+	return 0;
+}
+
+static int cci_version_check(struct i2c_client *client)
+{
+	struct camera_common_data *s_data = to_camera_common_data(&client->dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+	uint32_t cci_minor_ver, cci_major_ver;
+
+	cci_minor_ver = (priv->cci_reg.layout_version & CCI_REG_LAYOUT_MINVER_MASK)
+				>> CCI_REG_LAYOUT_MINVER_SHIFT;
+
+    /* We need at least the minor version defined */
+	if (cci_minor_ver >= CCI_REG_LAYOUT_MINVER) {
+		dev_dbg(&client->dev, "%s: valid cci register minor version: read: %d, expected minimum: %d\n",
+				__func__, cci_minor_ver, CCI_REG_LAYOUT_MINVER);
+	} else {
+		dev_err(&client->dev, "%s: cci reg minor version mismatch! read: %d (0x%x), expected: %d\n",
+				__func__, cci_minor_ver, priv->cci_reg.layout_version,
+				CCI_REG_LAYOUT_MINVER);
+		return -EINVAL;
+	}
+
+	cci_major_ver = (priv->cci_reg.layout_version & CCI_REG_LAYOUT_MAJVER_MASK)
+				>> CCI_REG_LAYOUT_MAJVER_SHIFT;
+
+    /* We need the exact major version */
+	if (cci_major_ver == CCI_REG_LAYOUT_MAJVER) {
+		dev_dbg(&client->dev, "%s: valid cci register major version: read: %d, expected: %d)\n",
+				__func__, cci_major_ver, CCI_REG_LAYOUT_MAJVER);
+	} else {
+		dev_err(&client->dev, "%s: cci reg major version mismatch! read: %d (0x%x), expected: %d\n",
+				__func__, cci_major_ver, priv->cci_reg.layout_version,
+				CCI_REG_LAYOUT_MAJVER);
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static int bcrm_version_check(struct i2c_client *client)
+{
+	struct camera_common_data *s_data = to_camera_common_data(&client->dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+	u32 value = 0;
+	int ret;
+
+	/* reading the BCRM version */
+	ret = avt_reg_read(client,
+			priv->cci_reg.bcrm_addr + BCRM_VERSION_32R,
+			AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_32,
+			(char *) &value);
+
+	if (ret < 0) {
+		dev_err(&client->dev, "i2c read failed (%d)\n", ret);
+		return ret;
+	}
+
+	dev_info(&client->dev, "bcrm version (driver): 0x%08x (%d.%d)\n",
+						BCRM_DEVICE_VERSION,
+						BCRM_MAJOR_VERSION,
+						BCRM_MINOR_VERSION);
+
+	dev_info(&client->dev, "bcrm version (camera): 0x%08x (%d.%d)\n",
+						value,
+						(value & 0xffff0000) >> 16,
+						(value & 0x0000ffff));
+
+	return (value >> 16) == BCRM_MAJOR_VERSION ? 1 : 0;
+}
+
+static int gcprm_version_check(struct i2c_client *client)
+{
+
+	struct camera_common_data *s_data = to_camera_common_data(&client->dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+	u32 value = priv->gencp_reg.gcprm_layout_version;
+
+	dev_info(&client->dev, "gcprm layout version (driver): 0x%08x (%d.%d)\n",
+						GCPRM_DEVICE_VERSION,
+						GCPRM_MAJOR_VERSION,
+						GCPRM_MINOR_VERSION);
+
+	dev_info(&client->dev, "gcprm layout version (camera): 0x%08x (%d.%d)\n",
+						value,
+						(value & 0xffff0000) >> 16,
+						(value & 0x0000ffff));
+
+	return (value & 0xffff0000) >> 16 == GCPRM_MAJOR_VERSION ? 1 : 0;
+}
+
+static void bcrm_dump(struct i2c_client *client)
+{
+    return; /* DISABLED. DEBUG ONLY */
+
+	/* Dump all BCRM registers (client, except write only ones) */
+	dump_bcrm_reg_32(client, BCRM_VERSION_32R, 				            "BCRM_VERSION_32R");
+	dump_bcrm_reg_64(client, BCRM_FEATURE_INQUIRY_64R, 			        "BCRM_FEATURE_INQUIRY_64R");
+	dump_bcrm_reg_64(client, BCRM_DEVICE_FIRMWARE_VERSION_64R, 		    "BCRM_DEVICE_FIRMWARE_VERSION_64R");
+	dump_bcrm_reg_8(client, BCRM_WRITE_HANDSHAKE_8RW, 			        "BCRM_WRITE_HANDSHAKE_8RW");
+
+	/* Streaming Control Registers */
+	dump_bcrm_reg_8(client, BCRM_SUPPORTED_CSI2_LANE_COUNTS_8R, 		"BCRM_SUPPORTED_CSI2_LANE_COUNTS_8R");
+	dump_bcrm_reg_8(client, BCRM_CSI2_LANE_COUNT_8RW, 			        "BCRM_CSI2_LANE_COUNT_8RW");
+	dump_bcrm_reg_32(client, BCRM_CSI2_CLOCK_MIN_32R, 			        "BCRM_CSI2_CLOCK_MIN_32R");
+	dump_bcrm_reg_32(client, BCRM_CSI2_CLOCK_MAX_32R, 			        "BCRM_CSI2_CLOCK_MAX_32R");
+	dump_bcrm_reg_32(client, BCRM_CSI2_CLOCK_32RW, 				        "BCRM_CSI2_CLOCK_32RW");
+	dump_bcrm_reg_32(client, BCRM_BUFFER_SIZE_32R, 				        "BCRM_BUFFER_SIZE_32R");
+	dump_bcrm_reg_32(client, BCRM_PHY_RESET_8RW, 			            "BCRM_PHY_RESET_8RW");
+
+	/* Acquisition Control Registers */
+	dump_bcrm_reg_8(client, BCRM_ACQUISITION_START_8RW, 			    "BCRM_ACQUISITION_START_8RW");
+	dump_bcrm_reg_8(client, BCRM_ACQUISITION_STOP_8RW, 			        "BCRM_ACQUISITION_STOP_8RW");
+	dump_bcrm_reg_8(client, BCRM_ACQUISITION_ABORT_8RW, 			    "BCRM_ACQUISITION_ABORT_8RW");
+	dump_bcrm_reg_8(client, BCRM_ACQUISITION_STATUS_8R,			        "BCRM_ACQUISITION_STATUS_8R");
+	dump_bcrm_reg_64(client, BCRM_ACQUISITION_FRAME_RATE_64RW, 		    "BCRM_ACQUISITION_FRAME_RATE_64RW");
+	dump_bcrm_reg_64(client, BCRM_ACQUISITION_FRAME_RATE_MIN_64R, 		"BCRM_ACQUISITION_FRAME_RATE_MIN_64R");
+	dump_bcrm_reg_64(client, BCRM_ACQUISITION_FRAME_RATE_MAX_64R, 		"BCRM_ACQUISITION_FRAME_RATE_MAX_64R");
+	dump_bcrm_reg_64(client, BCRM_ACQUISITION_FRAME_RATE_INC_64R, 		"BCRM_ACQUISITION_FRAME_RATE_INC_64R");
+	dump_bcrm_reg_8(client, BCRM_ACQUISITION_FRAME_RATE_ENABLE_8RW, 	"BCRM_ACQUISITION_FRAME_RATE_ENABLE_8RW");
+
+	dump_bcrm_reg_8(client, BCRM_FRAME_START_TRIGGER_MODE_8RW, 		    "BCRM_FRAME_START_TRIGGER_MODE_8RW");
+	dump_bcrm_reg_8(client, BCRM_FRAME_START_TRIGGER_SOURCE_8RW,		"BCRM_FRAME_START_TRIGGER_SOURCE_8RW");
+	dump_bcrm_reg_8(client, BCRM_FRAME_START_TRIGGER_ACTIVATION_8RW,	"BCRM_FRAME_START_TRIGGER_ACTIVATION_8RW");
+
+    dump_bcrm_reg_8(client, BCRM_EXPOSURE_ACTIVE_LINE_MODE_8RW,	        "BCRM_EXPOSURE_ACTIVE_LINE_MODE_8RW");
+	dump_bcrm_reg_8(client, BCRM_EXPOSURE_ACTIVE_OUTPUT_LINE_8RW,	    "BCRM_EXPOSURE_ACTIVE_OUTPUT_LINE_8RW");
+    dump_bcrm_reg_32(client, BCRM_LINE_CONFIGURATION_32RW,	            "BCRM_LINE_CONFIGURATION_32RW");
+    dump_bcrm_reg_8(client, BCRM_LINE_STATUS_8R,	                    "BCRM_LINE_STATUS_8R");
+
+	/* Image Format Control Registers */
+	dump_bcrm_reg_32(client, BCRM_IMG_WIDTH_32RW, 				    "BCRM_IMG_WIDTH_32RW");
+	dump_bcrm_reg_32(client, BCRM_IMG_WIDTH_MIN_32R, 			    "BCRM_IMG_WIDTH_MIN_32R");
+	dump_bcrm_reg_32(client, BCRM_IMG_WIDTH_MAX_32R, 			    "BCRM_IMG_WIDTH_MAX_32R");
+	dump_bcrm_reg_32(client, BCRM_IMG_WIDTH_INC_32R, 			    "BCRM_IMG_WIDTH_INC_32R");
+
+	dump_bcrm_reg_32(client, BCRM_IMG_HEIGHT_32RW,				    "BCRM_IMG_HEIGHT_32RW");
+	dump_bcrm_reg_32(client, BCRM_IMG_HEIGHT_MIN_32R,			    "BCRM_IMG_HEIGHT_MIN_32R");
+	dump_bcrm_reg_32(client, BCRM_IMG_HEIGHT_MAX_32R,			    "BCRM_IMG_HEIGHT_MAX_32R");
+	dump_bcrm_reg_32(client, BCRM_IMG_HEIGHT_INC_32R, 			    "BCRM_IMG_HEIGHT_INC_32R");
+	dump_bcrm_reg_32(client, BCRM_IMG_OFFSET_X_32RW, 			    "BCRM_IMG_OFFSET_X_32RW");
+	dump_bcrm_reg_32(client, BCRM_IMG_OFFSET_X_MIN_32R, 			"BCRM_IMG_OFFSET_X_MIN_32R");
+	dump_bcrm_reg_32(client, BCRM_IMG_OFFSET_X_MAX_32R, 			"BCRM_IMG_OFFSET_X_MAX_32R");
+	dump_bcrm_reg_32(client, BCRM_IMG_OFFSET_X_INC_32R, 			"BCRM_IMG_OFFSET_X_INC_32R");
+
+	dump_bcrm_reg_32(client, BCRM_IMG_OFFSET_Y_32RW, 			    "BCRM_IMG_OFFSET_Y_32RW");
+	dump_bcrm_reg_32(client, BCRM_IMG_OFFSET_Y_MIN_32R, 			"BCRM_IMG_OFFSET_Y_MIN_32R");
+	dump_bcrm_reg_32(client, BCRM_IMG_OFFSET_Y_MAX_32R, 			"BCRM_IMG_OFFSET_Y_MAX_32R");
+	dump_bcrm_reg_32(client, BCRM_IMG_OFFSET_Y_INC_32R, 			"BCRM_IMG_OFFSET_Y_INC_32R");
+
+	dump_bcrm_reg_32(client, BCRM_IMG_MIPI_DATA_FORMAT_32RW, 		    "BCRM_IMG_MIPI_DATA_FORMAT_32RW");
+	dump_bcrm_reg_64(client, BCRM_IMG_AVAILABLE_MIPI_DATA_FORMATS_64R, 	"BCRM_IMG_AVAILABLE_MIPI_DATA_FORMATS_64R");
+
+	dump_bcrm_reg_8(client, BCRM_IMG_BAYER_PATTERN_INQUIRY_8R, 		"BCRM_IMG_BAYER_PATTERN_INQUIRY_8R");
+	dump_bcrm_reg_8(client, BCRM_IMG_BAYER_PATTERN_8RW, 			"BCRM_IMG_BAYER_PATTERN_8RW");
+
+	dump_bcrm_reg_8(client, BCRM_IMG_REVERSE_X_8RW, 			    "BCRM_IMG_REVERSE_X_8RW");
+	dump_bcrm_reg_8(client, BCRM_IMG_REVERSE_Y_8RW, 			    "BCRM_IMG_REVERSE_Y_8RW");
+
+	dump_bcrm_reg_32(client, BCRM_SENSOR_WIDTH_32R, 			    "BCRM_SENSOR_WIDTH_32R");
+	dump_bcrm_reg_32(client, BCRM_SENSOR_HEIGHT_32R, 			    "BCRM_SENSOR_HEIGHT_32R");
+
+	dump_bcrm_reg_32(client, BCRM_WIDTH_MAX_32R, 				    "BCRM_WIDTH_MAX_32R");
+	dump_bcrm_reg_32(client, BCRM_HEIGHT_MAX_32R, 				    "BCRM_HEIGHT_MAX_32R");
+
+	/* Brightness Control Registers */
+	dump_bcrm_reg_64(client, BCRM_EXPOSURE_TIME_64RW, 			    "BCRM_EXPOSURE_TIME_64RW");
+	dump_bcrm_reg_64(client, BCRM_EXPOSURE_TIME_MIN_64R, 			"BCRM_EXPOSURE_TIME_MIN_64R");
+	dump_bcrm_reg_64(client, BCRM_EXPOSURE_TIME_MAX_64R, 			"BCRM_EXPOSURE_TIME_MAX_64R");
+	dump_bcrm_reg_64(client, BCRM_EXPOSURE_TIME_INC_64R, 			"BCRM_EXPOSURE_TIME_INC_64R");
+	dump_bcrm_reg_8(client, BCRM_EXPOSURE_AUTO_8RW, 			    "BCRM_EXPOSURE_AUTO_8RW");
+
+	dump_bcrm_reg_8(client, BCRM_INTENSITY_AUTO_PRECEDENCE_8RW, 		"BCRM_INTENSITY_AUTO_PRECEDENCE_8RW");
+	dump_bcrm_reg_32(client, BCRM_INTENSITY_AUTO_PRECEDENCE_VALUE_32RW, "BCRM_INTENSITY_AUTO_PRECEDENCE_VALUE_32RW");
+	dump_bcrm_reg_32(client, BCRM_INTENSITY_AUTO_PRECEDENCE_MIN_32R, 	"BCRM_INTENSITY_AUTO_PRECEDENCE_MIN_32R");
+	dump_bcrm_reg_32(client, BCRM_INTENSITY_AUTO_PRECEDENCE_MAX_32R, 	"BCRM_INTENSITY_AUTO_PRECEDENCE_MAX_32R");
+	dump_bcrm_reg_32(client, BCRM_INTENSITY_AUTO_PRECEDENCE_INC_32R, 	"BCRM_INTENSITY_AUTO_PRECEDENCE_INC_32R");
+
+	dump_bcrm_reg_32(client, BCRM_BLACK_LEVEL_32RW, 			    "BCRM_BLACK_LEVEL_32RW");
+	dump_bcrm_reg_32(client, BCRM_BLACK_LEVEL_MIN_32R, 			    "BCRM_BLACK_LEVEL_MIN_32R");
+	dump_bcrm_reg_32(client, BCRM_BLACK_LEVEL_MAX_32R, 			    "BCRM_BLACK_LEVEL_MAX_32R");
+	dump_bcrm_reg_32(client, BCRM_BLACK_LEVEL_INC_32R, 			    "BCRM_BLACK_LEVEL_INC_32R");
+
+	dump_bcrm_reg_64(client, BCRM_GAIN_64RW, 				        "BCRM_GAIN_64RW");
+	dump_bcrm_reg_64(client, BCRM_GAIN_MIN_64R,			 	        "BCRM_GAIN_MIN_64R");
+	dump_bcrm_reg_64(client, BCRM_GAIN_MAX_64R, 				    "BCRM_GAIN_MAX_64R");
+	dump_bcrm_reg_64(client, BCRM_GAIN_INC_64R, 				    "BCRM_GAIN_INC_64R");
+	dump_bcrm_reg_8(client, BCRM_GAIN_AUTO_8RW, 				    "BCRM_GAIN_AUTO_8RW");
+
+	dump_bcrm_reg_64(client, BCRM_GAMMA_64RW, 				        "BCRM_GAMMA_64RW");
+	dump_bcrm_reg_64(client, BCRM_GAMMA_MIN_64R, 				    "BCRM_GAMMA_MIN_64R");
+	dump_bcrm_reg_64(client, BCRM_GAMMA_MAX_64R, 				    "BCRM_GAMMA_MAX_64R");
+	dump_bcrm_reg_64(client, BCRM_GAMMA_INC_64R, 				    "BCRM_GAMMA_INC_64R");
+
+	dump_bcrm_reg_32(client, BCRM_CONTRAST_VALUE_32RW, 			    "BCRM_CONTRAST_VALUE_32RW");
+	dump_bcrm_reg_32(client, BCRM_CONTRAST_VALUE_MIN_32R, 			"BCRM_CONTRAST_VALUE_MIN_32R");
+	dump_bcrm_reg_32(client, BCRM_CONTRAST_VALUE_MAX_32R, 			"BCRM_CONTRAST_VALUE_MAX_32R");
+	dump_bcrm_reg_32(client, BCRM_CONTRAST_VALUE_INC_32R, 			"BCRM_CONTRAST_VALUE_INC_32R");
+
+	/* Color Management Registers */
+	dump_bcrm_reg_32(client, BCRM_SATURATION_32RW,				    "BCRM_SATURATION_32RW");
+	dump_bcrm_reg_32(client, BCRM_SATURATION_MIN_32R,			    "BCRM_SATURATION_MIN_32R");
+	dump_bcrm_reg_32(client, BCRM_SATURATION_MAX_32R, 			    "BCRM_SATURATION_MAX_32R");
+	dump_bcrm_reg_32(client, BCRM_SATURATION_INC_32R, 			    "BCRM_SATURATION_INC_32R");
+
+	dump_bcrm_reg_32(client, BCRM_HUE_32RW,				 	        "BCRM_HUE_32RW");
+	dump_bcrm_reg_32(client, BCRM_HUE_MIN_32R, 				        "BCRM_HUE_MIN_32R");
+	dump_bcrm_reg_32(client, BCRM_HUE_MAX_32R,				        "BCRM_HUE_MAX_32R");
+	dump_bcrm_reg_32(client, BCRM_HUE_INC_32R, 				        "BCRM_HUE_INC_32R");
+
+	dump_bcrm_reg_64(client, BCRM_RED_BALANCE_RATIO_64RW, 			"BCRM_RED_BALANCE_RATIO_64RW");
+	dump_bcrm_reg_64(client, BCRM_RED_BALANCE_RATIO_MIN_64R, 		"BCRM_RED_BALANCE_RATIO_MIN_64R");
+	dump_bcrm_reg_64(client, BCRM_RED_BALANCE_RATIO_MAX_64R, 		"BCRM_RED_BALANCE_RATIO_MAX_64R");
+	dump_bcrm_reg_64(client, BCRM_RED_BALANCE_RATIO_INC_64R, 		"BCRM_RED_BALANCE_RATIO_INC_64R");
+
+	dump_bcrm_reg_64(client, BCRM_GREEN_BALANCE_RATIO_64RW,			"BCRM_GREEN_BALANCE_RATIO_64RW");
+	dump_bcrm_reg_64(client, BCRM_GREEN_BALANCE_RATIO_MIN_64R,		"BCRM_GREEN_BALANCE_RATIO_MIN_64R");
+	dump_bcrm_reg_64(client, BCRM_GREEN_BALANCE_RATIO_MAX_64R, 		"BCRM_GREEN_BALANCE_RATIO_MAX_64R");
+	dump_bcrm_reg_64(client, BCRM_GREEN_BALANCE_RATIO_INC_64R,		"BCRM_GREEN_BALANCE_RATIO_INC_64R");
+
+	dump_bcrm_reg_64(client, BCRM_BLUE_BALANCE_RATIO_64RW, 			"BCRM_BLUE_BALANCE_RATIO_64RW");
+	dump_bcrm_reg_64(client, BCRM_BLUE_BALANCE_RATIO_MIN_64R, 		"BCRM_BLUE_BALANCE_RATIO_MIN_64R");
+	dump_bcrm_reg_64(client, BCRM_BLUE_BALANCE_RATIO_MAX_64R, 		"BCRM_BLUE_BALANCE_RATIO_MAX_64R");
+	dump_bcrm_reg_64(client, BCRM_BLUE_BALANCE_RATIO_INC_64R, 		"BCRM_BLUE_BALANCE_RATIO_INC_64R");
+
+	dump_bcrm_reg_8(client, BCRM_WHITE_BALANCE_AUTO_8RW, 			"BCRM_WHITE_BALANCE_AUTO_8RW");
+
+	/* Other Registers */
+	dump_bcrm_reg_32(client, BCRM_SHARPNESS_32RW, 				    "BCRM_SHARPNESS_32RW");
+	dump_bcrm_reg_32(client, BCRM_SHARPNESS_MIN_32R, 			    "BCRM_SHARPNESS_MIN_32R");
+	dump_bcrm_reg_32(client, BCRM_SHARPNESS_MAX_32R, 			    "BCRM_SHARPNESS_MAX_32R");
+	dump_bcrm_reg_32(client, BCRM_SHARPNESS_INC_32R, 			    "BCRM_SHARPNESS_INC_32R");
+
+	dump_bcrm_reg_32(client, BCRM_DEVICE_TEMPERATURE_32R, 			"BCRM_DEVICE_TEMPERATURE_32R");
+
+    dump_bcrm_reg_64(client, BCRM_EXPOSURE_AUTO_MIN_64RW, 		    "BCRM_EXPOSURE_AUTO_MIN_64RW");
+    dump_bcrm_reg_64(client, BCRM_EXPOSURE_AUTO_MAX_64RW, 		    "BCRM_EXPOSURE_AUTO_MAX_64RW");
+    dump_bcrm_reg_64(client, BCRM_GAIN_AUTO_MIN_64RW, 		        "BCRM_GAIN_AUTO_MIN_64RW");
+    dump_bcrm_reg_64(client, BCRM_GAIN_AUTO_MAX_64RW, 		        "BCRM_GAIN_AUTO_MAX_64RW");
+
+	dump_bcrm_reg_32(client, BCRM_AUTO_REGION_WIDTH_32RW, 			"BCRM_AUTO_REGION_WIDTH_32RW");
+	dump_bcrm_reg_32(client, BCRM_AUTO_REGION_WIDTH_MIN_32R, 		"BCRM_AUTO_REGION_WIDTH_MIN_32R");
+	dump_bcrm_reg_32(client, BCRM_AUTO_REGION_WIDTH_MAX_32R, 		"BCRM_AUTO_REGION_WIDTH_MAX_32R");
+	dump_bcrm_reg_32(client, BCRM_AUTO_REGION_WIDTH_INC_32R, 		"BCRM_AUTO_REGION_WIDTH_INC_32R");
+
+	dump_bcrm_reg_32(client, BCRM_AUTO_REGION_HEIGHT_32RW, 			"BCRM_AUTO_REGION_HEIGHT_32RW");
+	dump_bcrm_reg_32(client, BCRM_AUTO_REGION_HEIGHT_MIN_32R, 		"BCRM_AUTO_REGION_HEIGHT_MIN_32R");
+	dump_bcrm_reg_32(client, BCRM_AUTO_REGION_HEIGHT_MAX_32R, 		"BCRM_AUTO_REGION_HEIGHT_MAX_32R");
+	dump_bcrm_reg_32(client, BCRM_AUTO_REGION_HEIGHT_INC_32R, 		"BCRM_AUTO_REGION_HEIGHT_INC_32R");
+
+    dump_bcrm_reg_32(client, BCRM_AUTO_REGION_OFFSET_X_32RW, 		"BCRM_AUTO_REGION_OFFSET_X_32RW");
+	dump_bcrm_reg_32(client, BCRM_AUTO_REGION_OFFSET_X_MIN_32R, 	"BCRM_AUTO_REGION_OFFSET_X_MIN_32R");
+	dump_bcrm_reg_32(client, BCRM_AUTO_REGION_OFFSET_X_MAX_32R, 	"BCRM_AUTO_REGION_OFFSET_X_MAX_32R");
+	dump_bcrm_reg_32(client, BCRM_AUTO_REGION_OFFSET_X_INC_32R, 	"BCRM_AUTO_REGION_OFFSET_X_INC_32R");
+
+    dump_bcrm_reg_32(client, BCRM_AUTO_REGION_OFFSET_Y_32RW, 		"BCRM_AUTO_REGION_OFFSET_Y_32RW");
+	dump_bcrm_reg_32(client, BCRM_AUTO_REGION_OFFSET_Y_MIN_32R, 	"BCRM_AUTO_REGION_OFFSET_Y_MIN_32R");
+	dump_bcrm_reg_32(client, BCRM_AUTO_REGION_OFFSET_Y_MAX_32R, 	"BCRM_AUTO_REGION_OFFSET_Y_MAX_32R");
+	dump_bcrm_reg_32(client, BCRM_AUTO_REGION_OFFSET_Y_INC_32R, 	"BCRM_AUTO_REGION_OFFSET_Y_INC_32R");
+}
+
+static void dump_bcrm_reg_8(struct i2c_client *client, u16 nOffset, const char *pRegName)
+{
+    struct camera_common_data *s_data = to_camera_common_data(&client->dev);
+    struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+    int status = 0;
+    u8 data = 0;
+    uint32_t nReg = 0;
+
+    if (!priv)
+        return;
+
+    nReg = priv->cci_reg.bcrm_addr + nOffset;
+    status = i2c_read(client, nReg, AV_CAM_REG_SIZE,
+            AV_CAM_DATA_SIZE_8, (char *)&data);
+
+    if (status >= 0)
+                dev_info(&client->dev, "%s (0x%04x): %u (0x%x)", pRegName, nReg, data, data);
+    else
+        dev_err(&client->dev, "%s: ERROR", pRegName);
+}
+
+static void dump_bcrm_reg_32(struct i2c_client *client, u16 nOffset, const char *pRegName)
+{
+    struct camera_common_data *s_data = to_camera_common_data(&client->dev);
+    struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+    int status = 0;
+    u32 data = 0;
+    uint32_t nReg = 0;
+
+    if (!priv)
+        return;
+
+    nReg = priv->cci_reg.bcrm_addr + nOffset;
+    status = i2c_read(client, priv->cci_reg.bcrm_addr + nOffset, AV_CAM_REG_SIZE,
+              AV_CAM_DATA_SIZE_32, (char *)&data);
+
+    swapbytes(&data, sizeof(data));
+    if (status >= 0)
+                dev_info(&client->dev, "%s (0x%04x): %u (0x%08x)", pRegName, nReg, data, data);
+    else
+        dev_err(&client->dev, "%s: ERROR", pRegName);
+}
+
+static void dump_bcrm_reg_64(struct i2c_client *client, u16 nOffset, const char *pRegName)
+{
+    struct camera_common_data *s_data = to_camera_common_data(&client->dev);
+    struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+    int status = 0;
+    u64 data = 0;
+    uint32_t nReg = 0;
+
+    if (!priv)
+        return;
+
+    nReg = priv->cci_reg.bcrm_addr + nOffset;
+    status = i2c_read(client, priv->cci_reg.bcrm_addr + nOffset, AV_CAM_REG_SIZE,
+              AV_CAM_DATA_SIZE_64, (char *)&data);
+
+    swapbytes(&data, sizeof(data));
+    if (status >= 0)
+                dev_info(&client->dev, "%s (0x%04x): %llu (0x%016llx)", pRegName, nReg, data, data);
+    else
+        dev_err(&client->dev, "%s: ERROR", pRegName);
+}
+
+static void dump_camera_firmware_version(struct i2c_client *client)
+{
+    struct camera_common_data *s_data = to_camera_common_data(&client->dev);
+    struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+    int status = 0;
+    u64 data = 0;
+
+    if (!priv)
+        return;
+
+    status = i2c_read(client, priv->cci_reg.bcrm_addr + BCRM_DEVICE_FIRMWARE_VERSION_64R, AV_CAM_REG_SIZE,
+              AV_CAM_DATA_SIZE_64, (char *)&data);
+
+    swapbytes(&data, sizeof(data));
+
+    if (status >= 0)
+        if ((u32)((data >> 32) & 0xFFFFFFFF) < 50000)
+        {
+            dev_info(&client->dev, "Camera firmware version: %u.%u.%hu.%u (0x%016llx)",     (u8)(data & 0xFF),
+                                                                                            (u8)((data >> 8) & 0xFF),
+                                                                                            (u16)((data >> 16) & 0xFFFF),
+                                                                                            (u32)((data >> 32) & 0xFFFFFFFF), data);
+        }
+        else
+        {
+            /* Show git commit as hex */
+            dev_info(&client->dev, "Camera firmware version: %u.%u.%hu.%x (0x%016llx)",     (u8)(data & 0xFF),
+                                                                                            (u8)((data >> 8) & 0xFF),
+                                                                                            (u16)((data >> 16) & 0xFFFF),
+                                                                                            (u32)((data >> 32) & 0xFFFFFFFF), data);
+        }
+    else
+    {
+        dev_err(&client->dev, "Error while retrieving camera firmware version");
+    }
+}
+
+/* Check if the device is answering to an I2C read request */
+static bool device_present(struct i2c_client *client)
+{
+    int status = 0;
+    u64 data = 0;
+
+    status = i2c_read(client, CCI_DEVICE_CAP_64R, AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,  (char *)&data);         
+
+    return ((status < 0) || (data == 0)) ? false : true;
+}
+
+static int soft_reset(struct i2c_client *client)
+{
+    int status = 0;
+    uint8_t reset_val = 1;
+    static const uint8_t default_heartbeat_val = 0x80;
+    uint8_t heartbeat_val = default_heartbeat_val;
+    uint64_t duration_ms = 0;
+    static const uint8_t heartbeat_low_limit = 0;
+    static const uint32_t delay_ms = 400;
+    static const uint32_t max_time_ms = 10000;
+    uint64_t start_jiffies = get_jiffies_64();
+    bool device_available = false;
+    bool heartbeat_available = false;
+
+    /* Check, if heartbeat register is available (write default value and read it back)*/
+    status = i2c_write(client, CCI_HEARTBEAT_8RW, AV_CAM_REG_SIZE, sizeof(heartbeat_val), (char*)&heartbeat_val);
+    heartbeat_available = (i2c_read(client, CCI_HEARTBEAT_8RW, AV_CAM_REG_SIZE, sizeof(heartbeat_val), (char*)&heartbeat_val) < 0) ? false : true;
+    /* If camera does not support heartbeat it delivers always 0 */
+    heartbeat_available = ((heartbeat_val != 0) && (status != 0)) ? true : false;
+    dev_info(&client->dev, "Heartbeat %ssupported", (heartbeat_available) ? "" : "NOT ");
+
+    /* Execute soft reset */
+    status = i2c_write(client, CCI_SOFT_RESET_8W, AV_CAM_REG_SIZE, sizeof(reset_val), (char*)&reset_val);
+        
+	if (status >= 0)
+    {
+        dev_info(&client->dev, "Soft reset executed. Initializing camera...");
+    }
+	else
+    {
+        dev_err(&client->dev, "Soft reset ERROR");   
+        return -EIO; 
+    }
+
+    /* Poll camera register to check if camera is back again */
+    do
+    {
+        usleep_range(delay_ms*1000, (delay_ms*1000)+1);
+        device_available = device_present(client);
+        duration_ms = jiffies_to_msecs(get_jiffies_64() - start_jiffies);       
+    } while((duration_ms < max_time_ms) && !device_available);
+
+    if (!heartbeat_available)
+    {
+        /* Camera might need a few more seconds to be fully booted */
+        usleep_range(add_wait_time_ms*1000, (add_wait_time_ms*1000)+1);
+    }
+    else
+    {
+        /* Heartbeat is supported. Poll heartbeat register until value is lower than the default value again */
+        do
+        {
+            usleep_range(delay_ms*1000, (delay_ms*1000)+1);
+            status = i2c_read(client, CCI_HEARTBEAT_8RW, AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_8, (char*)&heartbeat_val);
+            //dev_info(&client->dev, "Heartbeat val=0x%02X", heartbeat_val);
+            duration_ms = jiffies_to_msecs(get_jiffies_64() - start_jiffies);       
+            if ((heartbeat_val > heartbeat_low_limit) && (heartbeat_val < default_heartbeat_val) && (status >= 0))
+            {
+                /* Heartbeat active -> Camera alive */
+                dev_info(&client->dev, "Heartbeat active!");
+                break;
+            }
+        } while (duration_ms < max_time_ms);
+    }
+
+    dev_info(&client->dev, "Camera boot time: %llums", duration_ms);
+    if (!device_available)
+            dev_err(&client->dev, "Camera not reconnected");   
+
+    return 0;
+}
+
+static ssize_t cci_register_layout_version_show(struct device *dev,
+			struct device_attribute *attr, char *buf)
+{
+	struct camera_common_data *s_data = to_camera_common_data(dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+
+	return sprintf(buf, "%d\n", priv->cci_reg.layout_version);
+}
+
+static ssize_t csi_clock_show(struct device *dev,
+			struct device_attribute *attr, char *buf)
+{
+	struct camera_common_data *s_data = to_camera_common_data(dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+
+	return sprintf(buf, "%d\n", priv->csi_clk_freq);
+}
+
+static ssize_t device_capabilities_show(struct device *dev,
+			struct device_attribute *attr, char *buf)
+{
+	struct camera_common_data *s_data = to_camera_common_data(dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+
+	return sprintf(buf, "%llu\n", priv->cci_reg.device_capabilities);
+}
+
+static ssize_t device_guid_show(struct device *dev,
+			struct device_attribute *attr, char *buf)
+{
+	struct camera_common_data *s_data = to_camera_common_data(dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+
+	return sprintf(buf, "%s\n", priv->cci_reg.device_guid);
+}
+
+static ssize_t manufacturer_name_show(struct device *dev,
+			struct device_attribute *attr, char *buf)
+{
+	struct camera_common_data *s_data = to_camera_common_data(dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+
+	return sprintf(buf, "%s\n", priv->cci_reg.manufacturer_name);
+}
+
+static ssize_t model_name_show(struct device *dev,
+			struct device_attribute *attr, char *buf)
+{
+	struct camera_common_data *s_data = to_camera_common_data(dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+
+	return sprintf(buf, "%s\n", priv->cci_reg.model_name);
+}
+
+static ssize_t family_name_show(struct device *dev,
+			struct device_attribute *attr, char *buf)
+{
+	struct camera_common_data *s_data = to_camera_common_data(dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+
+	return sprintf(buf, "%s\n", priv->cci_reg.family_name);
+}
+
+static ssize_t lane_count_show(struct device *dev,
+			struct device_attribute *attr, char *buf)
+{
+	struct camera_common_data *s_data = to_camera_common_data(dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+
+	return sprintf(buf, "%d\n", priv->s_data->numlanes);
+}
+
+static ssize_t device_version_show(struct device *dev,
+			struct device_attribute *attr, char *buf)
+{
+	struct camera_common_data *s_data = to_camera_common_data(dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+
+	return sprintf(buf, "%s\n", priv->cci_reg.device_version);
+}
+
+static ssize_t manufacturer_info_show(struct device *dev,
+			struct device_attribute *attr, char *buf)
+{
+	struct camera_common_data *s_data = to_camera_common_data(dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+
+	return sprintf(buf, "%s\n", priv->cci_reg.manufacturer_info);
+}
+
+static ssize_t serial_number_show(struct device *dev,
+			struct device_attribute *attr, char *buf)
+{
+	struct camera_common_data *s_data = to_camera_common_data(dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+
+	return sprintf(buf, "%s\n", priv->cci_reg.serial_number);
+}
+
+static ssize_t user_defined_name_show(struct device *dev,
+			struct device_attribute *attr, char *buf)
+{
+	struct camera_common_data *s_data = to_camera_common_data(dev);
+	struct avt_csi2_priv *priv = (struct avt_csi2_priv *)s_data->priv;
+
+	return sprintf(buf, "%s\n", priv->cci_reg.user_defined_name);
+}
+
+static ssize_t driver_version_show(struct device *dev,
+		struct device_attribute *attr, char *buf)
+{
+	return sprintf(buf, "%d.%d.%d.%d\n",
+			DRV_VER_MAJOR, DRV_VER_MINOR, DRV_VER_PATCH, DRV_VER_BUILD);
+}
+
+static ssize_t debug_en_show(struct device *dev,
+		struct device_attribute *attr, char *buf)
+{
+	return sprintf(buf, "%d\n", debug);
+}
+
+static ssize_t debug_en_store(struct device *dev,
+		struct device_attribute *attr, const char *buf, size_t count)
+{
+	int ret;
+
+	ret = kstrtoint(buf, 10, &debug);
+	if (ret < 0)
+		return ret;
+
+	return count;
+}
+
+static DEVICE_ATTR_RO(cci_register_layout_version);
+static DEVICE_ATTR_RO(csi_clock);
+static DEVICE_ATTR_RO(device_capabilities);
+static DEVICE_ATTR_RO(device_guid);
+static DEVICE_ATTR_RO(device_version);
+static DEVICE_ATTR_RO(driver_version);
+static DEVICE_ATTR_RO(family_name);
+static DEVICE_ATTR_RO(lane_count);
+static DEVICE_ATTR_RO(manufacturer_info);
+static DEVICE_ATTR_RO(manufacturer_name);
+static DEVICE_ATTR_RO(model_name);
+static DEVICE_ATTR_RO(serial_number);
+static DEVICE_ATTR_RO(user_defined_name);
+static DEVICE_ATTR_RW(debug_en);
+
+static struct attribute *avt_csi2_attrs[] = {
+	&dev_attr_cci_register_layout_version.attr,
+	&dev_attr_csi_clock.attr,
+	&dev_attr_device_capabilities.attr,
+	&dev_attr_device_guid.attr,
+	&dev_attr_device_version.attr,
+	&dev_attr_driver_version.attr,
+	&dev_attr_family_name.attr,
+	&dev_attr_lane_count.attr,
+	&dev_attr_manufacturer_info.attr,
+	&dev_attr_manufacturer_name.attr,
+	&dev_attr_model_name.attr,
+	&dev_attr_serial_number.attr,
+	&dev_attr_user_defined_name.attr,
+	&dev_attr_debug_en.attr,
+	NULL
+};
+
+static struct attribute_group avt_csi2_attr_grp = {
+	.attrs = avt_csi2_attrs,
+};
+
+static bool common_range(uint32_t nMin1, uint32_t nMax1, uint32_t nInc1,
+				uint32_t nMin2, uint32_t nMax2, uint32_t nInc2,
+				uint32_t *rMin, uint32_t *rMax, uint32_t *rInc)
+{
+	bool bResult = false;
+
+	uint32_t nMin = max(nMin1, nMin2);
+	uint32_t nMax = min(nMax1, nMax2);
+
+	/* Check if it is overlapping at all */
+	if (nMax >= nMin) {
+		/* if both minima are equal,
+		 * then the computation is a bit simpler
+		 */
+		if (nMin1 == nMin2) {
+			uint32_t nLCM = lcm(nInc1, nInc2);
+			*rMin = nMin;
+			*rMax = nMax - ((nMax - nMin) % nLCM);
+
+			if (*rMin == *rMax)
+				*rInc = 1;
+			else
+				*rInc = nLCM;
+
+			bResult = true;
+		} else if (nMin1 > nMin2) {
+			/* Find the first value that is ok for Host and BCRM */
+			uint32_t nMin1Shifted = nMin1 - nMin2;
+			uint32_t nMaxShifted = nMax - nMin2;
+			uint32_t nValue = nMin1Shifted;
+
+			for (; nValue <= nMaxShifted; nValue += nInc1) {
+				if ((nValue % nInc2) == 0)
+					break;
+			}
+
+			/* Compute common increment and maximum */
+			if (nValue <= nMaxShifted) {
+				uint32_t nLCM = lcm(nInc1, nInc2);
+				*rMin = nValue + nMin2;
+				*rMax = nMax - ((nMax - *rMin) % nLCM);
+
+				if (*rMin == *rMax)
+					*rInc = 1;
+				else
+					*rInc = nLCM;
+
+				bResult = true;
+			}
+		} else {
+			/* Find the first value that is ok for Host and BCRM */
+			uint32_t nMin2Shifted = nMin2 - nMin1;
+			uint32_t nMaxShifted = nMax - nMin1;
+			uint32_t nValue = nMin2Shifted;
+
+			for (; nValue <= nMaxShifted; nValue += nInc2) {
+				if ((nValue % nInc1) == 0)
+					break;
+			}
+
+			/* Compute common increment and maximum */
+			if (nValue <= nMaxShifted) {
+				uint32_t nLCM = lcm(nInc2, nInc1);
+				*rMin = nValue + nMin1;
+				*rMax = nMax - ((nMax - *rMin) % nLCM);
+				if (*rMin == *rMax)
+					*rInc = 1;
+				else
+					*rInc = nLCM;
+
+				bResult = true;
+			}
+		}
+	}
+
+	return bResult;
+}
+
+static void dump_frame_param(struct v4l2_subdev *sd)
+{
+    struct avt_csi2_priv *priv = avt_get_priv(sd);
+    avt_dbg(sd, "\n");
+    avt_dbg(sd, "priv->frmp.minh=%d\n", priv->frmp.minh);
+    avt_dbg(sd, "priv->frmp.maxh=%d\n", priv->frmp.maxh);
+    avt_dbg(sd, "priv->frmp.sh=%d\n", priv->frmp.sh);
+    avt_dbg(sd, "priv->frmp.minw=%d\n", priv->frmp.minw);
+    avt_dbg(sd, "priv->frmp.maxw=%d\n", priv->frmp.maxw);
+    avt_dbg(sd, "priv->frmp.sw=%d\n", priv->frmp.sw);
+    avt_dbg(sd, "priv->frmp.minhoff=%d\n", priv->frmp.minhoff);
+    avt_dbg(sd, "priv->frmp.maxhoff=%d\n", priv->frmp.maxhoff);
+    avt_dbg(sd, "priv->frmp.shoff=%d\n", priv->frmp.shoff);
+    avt_dbg(sd, "priv->frmp.minwoff=%d\n", priv->frmp.minwoff);
+    avt_dbg(sd, "priv->frmp.maxwoff=%d\n", priv->frmp.maxwoff);
+    avt_dbg(sd, "priv->frmp.swoff=%d\n", priv->frmp.swoff);
+    avt_dbg(sd, "priv->frmp.r.width=%d\n", priv->frmp.r.width);
+    avt_dbg(sd, "priv->frmp.r.height=%d\n", priv->frmp.r.height);
+    avt_dbg(sd, "priv->frmp.r.left=%d\n", priv->frmp.r.left);
+    avt_dbg(sd, "priv->frmp.r.top=%d\n", priv->frmp.r.top);
+}
+
+static int avt_init_frame_param(struct v4l2_subdev *sd)
+{
+    struct avt_csi2_priv *priv = avt_get_priv(sd);
+    dump_frame_param(sd);
+	if (avt_get_param(priv->client, V4L2_AV_CSI2_HEIGHT_MINVAL_R,
+				&priv->frmp.minh))
+		return -EINVAL;
+
+	if (avt_get_param(priv->client, V4L2_AV_CSI2_HEIGHT_MAXVAL_R,
+				&priv->frmp.maxh))
+		return -EINVAL;
+
+	if (avt_get_param(priv->client, V4L2_AV_CSI2_HEIGHT_INCVAL_R,
+				&priv->frmp.sh))
+		return -EINVAL;
+
+	if (avt_get_param(priv->client, V4L2_AV_CSI2_WIDTH_MINVAL_R,
+				&priv->frmp.minw))
+		return -EINVAL;
+
+	if (avt_get_param(priv->client, V4L2_AV_CSI2_WIDTH_MAXVAL_R,
+				&priv->frmp.maxw))
+		return -EINVAL;
+
+	if (avt_get_param(priv->client, V4L2_AV_CSI2_WIDTH_INCVAL_R,
+				&priv->frmp.sw))
+		return -EINVAL;
+
+	if (avt_get_param(priv->client, V4L2_AV_CSI2_OFFSET_Y_MIN_R,
+				&priv->frmp.minhoff))
+		return -EINVAL;
+
+	if (avt_get_param(priv->client, V4L2_AV_CSI2_OFFSET_Y_MAX_R,
+				&priv->frmp.maxhoff))
+		return -EINVAL;
+
+	if (avt_get_param(priv->client, V4L2_AV_CSI2_OFFSET_Y_INC_R,
+				&priv->frmp.shoff))
+		return -EINVAL;
+
+	if (avt_get_param(priv->client, V4L2_AV_CSI2_OFFSET_X_MIN_R,
+				&priv->frmp.minwoff))
+		return -EINVAL;
+
+	if (avt_get_param(priv->client, V4L2_AV_CSI2_OFFSET_X_MAX_R,
+				&priv->frmp.maxwoff))
+		return -EINVAL;
+
+	if (avt_get_param(priv->client, V4L2_AV_CSI2_OFFSET_X_INC_R,
+				&priv->frmp.swoff))
+		return -EINVAL;
+
+	if (avt_get_param(priv->client, V4L2_AV_CSI2_WIDTH_R,
+				&priv->frmp.r.width))
+		return -EINVAL;
+
+	if (avt_get_param(priv->client, V4L2_AV_CSI2_HEIGHT_R,
+				&priv->frmp.r.height))
+		return -EINVAL;
+
+	if (avt_get_param(priv->client, V4L2_AV_CSI2_OFFSET_X_R,
+				&priv->frmp.r.left))
+		return -EINVAL;
+
+	if (avt_get_param(priv->client, V4L2_AV_CSI2_OFFSET_Y_R,
+				&priv->frmp.r.top))
+		return -EINVAL;
+
+    /* We might need to correct some values */
+    /* Tegra doesn't seem to accept offsets that are not divisible by 8. */
+    roundup(priv->frmp.swoff, OFFSET_INC_W);
+    roundup(priv->frmp.shoff, OFFSET_INC_H);
+    /* Tegra doesn't allow image resolutions smaller than 64x32 */
+    priv->frmp.minw = max_t(uint32_t, priv->frmp.minw, FRAMESIZE_MIN_W);
+    priv->frmp.minh = max_t(uint32_t, priv->frmp.minh, FRAMESIZE_MIN_H);
+   
+    priv->frmp.maxw = min_t(uint32_t, priv->frmp.maxw, FRAMESIZE_MAX_W);
+    priv->frmp.maxh = min_t(uint32_t, priv->frmp.maxh, FRAMESIZE_MAX_H);
+  
+   //max_height = rounddown(max_height, FRAMESIZE_INC_H);
+
+    /* Take care of image width alignment*/
+    if (priv->crop_align_enabled) {
+        priv->frmp.maxwoff = avt_align_width(sd, priv->frmp.maxwoff);
+
+        priv->frmp.maxw = avt_align_width(sd, priv->frmp.maxw);
+    }
+
+    dump_frame_param(sd);
+	return 0;
+}
+
+/* Read image format from camera,
+ * should be only called once, during initialization
+ * */
+static int avt_read_fmt_from_device(struct v4l2_subdev *sd, uint32_t *fmt)
+{
+	struct avt_csi2_priv *priv = avt_get_priv(sd);
+	struct i2c_client *client = priv->client;
+	uint32_t avt_img_fmt = 0;
+	uint8_t bayer_pattern;
+	int ret = 0;
+
+	ret = avt_reg_read(client,
+			priv->cci_reg.bcrm_addr + BCRM_IMG_BAYER_PATTERN_8RW,
+			AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_8,
+			(char *) &bayer_pattern);
+
+	if (ret < 0) {
+		dev_err(&client->dev, "i2c read failed (%d)\n", ret);
+		return ret;
+	}
+    dev_dbg(&client->dev, "Camera bayer_pattern=0x%X", bayer_pattern);
+
+	ret = avt_reg_read(client,
+			priv->cci_reg.bcrm_addr + BCRM_IMG_MIPI_DATA_FORMAT_32RW,
+			AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_32,
+			(char *) &avt_img_fmt);
+
+	if (ret < 0) {
+		dev_err(&client->dev, "i2c read failed (%d)\n", ret);
+		return ret;
+	}
+
+    dev_dbg(&client->dev, "BCRM_IMG_MIPI_DATA_FORMAT_32RW=0x%08X\n", avt_img_fmt);
+
+	switch (avt_img_fmt) {
+		case	MIPI_DT_RGB888:
+			avt_img_fmt = MEDIA_BUS_FMT_RGB888_1X24;
+			break;
+		case	MIPI_DT_RGB565:
+			avt_img_fmt = MEDIA_BUS_FMT_RGB565_1X16;
+			break;
+		case	MIPI_DT_YUV422:
+			avt_img_fmt = MEDIA_BUS_FMT_VYUY8_2X8;
+			break;
+		case	MIPI_DT_CUSTOM:
+			avt_img_fmt = MEDIA_BUS_FMT_CUSTOM;
+			break;
+		case	MIPI_DT_RAW8:
+				switch (bayer_pattern) {
+				case	monochrome:
+					avt_img_fmt =
+						MEDIA_BUS_FMT_Y8_1X8;
+					break;
+				case	bayer_gr:
+					avt_img_fmt =
+						MEDIA_BUS_FMT_SGRBG8_1X8;
+					break;
+				case	bayer_rg:
+					avt_img_fmt =
+						MEDIA_BUS_FMT_SRGGB8_1X8;
+					break;
+				case	bayer_gb:
+					avt_img_fmt =
+						MEDIA_BUS_FMT_SGBRG8_1X8;
+					break;
+				case	bayer_bg:
+					avt_img_fmt =
+						MEDIA_BUS_FMT_SBGGR8_1X8;
+					break;
+				default:
+					dev_err(&client->dev, "%s:Unknown RAW8 pixelformat read, bayer_pattern %d\n",
+							__func__,
+							bayer_pattern);
+					return -EINVAL;
+				}
+			break;
+		case	MIPI_DT_RAW10:
+				switch (bayer_pattern) {
+				case	monochrome:
+					avt_img_fmt =
+						MEDIA_BUS_FMT_Y10_1X10;
+					break;
+				case	bayer_gr:
+					avt_img_fmt =
+						MEDIA_BUS_FMT_SGRBG10_1X10;
+					break;
+				case	bayer_rg:
+					avt_img_fmt =
+						MEDIA_BUS_FMT_SRGGB10_1X10;
+					break;
+				case	bayer_gb:
+					avt_img_fmt =
+						MEDIA_BUS_FMT_SGBRG10_1X10;
+					break;
+				case	bayer_bg:
+					avt_img_fmt =
+						MEDIA_BUS_FMT_SBGGR10_1X10;
+					break;
+				default:
+					dev_err(&client->dev, "%s:Unknown RAW10 pixelformat read, bayer_pattern %d\n",
+							__func__,
+							bayer_pattern);
+					return -EINVAL;
+				}
+			break;
+		case	MIPI_DT_RAW12:
+				switch (bayer_pattern) {
+				case	monochrome:
+					avt_img_fmt =
+						MEDIA_BUS_FMT_Y12_1X12;
+					break;
+				case	bayer_gr:
+					avt_img_fmt =
+						MEDIA_BUS_FMT_SGRBG12_1X12;
+					break;
+				case	bayer_rg:
+					avt_img_fmt =
+						MEDIA_BUS_FMT_SRGGB12_1X12;
+					break;
+				case	bayer_gb:
+					avt_img_fmt =
+						MEDIA_BUS_FMT_SGBRG12_1X12;
+					break;
+				case	bayer_bg:
+					avt_img_fmt =
+						MEDIA_BUS_FMT_SBGGR12_1X12;
+					break;
+				default:
+					dev_err(&client->dev, "%s:Unknown RAW12 pixelformat read, bayer_pattern %d\n",
+							__func__,
+							bayer_pattern);
+					return -EINVAL;
+				}
+			break;
+
+                case 0:
+                        /* Pixelformat 0 -> Probably fallback app running -> Emulate RAW888 */
+                        avt_img_fmt = MEDIA_BUS_FMT_RGB888_1X24;
+                        dev_warn(&client->dev, "Invalid pixelformat detected (0). Fallback app running?");
+                        break;
+
+		default:
+			dev_err(&client->dev, "%s:Unknown pixelformat read, avt_img_fmt 0x%x\n",
+					__func__, avt_img_fmt);
+			return -EINVAL;
+		}
+
+	*fmt = avt_img_fmt;
+
+	return 0;
+}
+
+static int avt_init_mode(struct v4l2_subdev *sd)
+{
+    struct avt_csi2_priv *priv = avt_get_priv(sd);
+    int ret = 0;
+    uint32_t common_min_clk = 0;
+    uint32_t common_max_clk = 0;
+    uint32_t common_inc_clk = 0;
+    uint32_t avt_min_clk = 0;
+    uint32_t avt_max_clk = 0;
+    uint8_t avt_supported_lane_counts = 0;
+
+    uint32_t i2c_reg;
+    uint32_t i2c_reg_size;
+    uint32_t i2c_reg_count;
+    uint32_t clk;
+    uint8_t bcm_mode = 0;
+
+    char *i2c_reg_buf;
+    struct v4l2_subdev_selection sel;
+
+    /* Check if requested number of lanes is supported */
+    ret = avt_reg_read(priv->client,
+            priv->cci_reg.bcrm_addr + BCRM_SUPPORTED_CSI2_LANE_COUNTS_8R,
+            AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_8,
+            (char *) &avt_supported_lane_counts);
+    if (ret < 0) {
+        avt_err(sd, "i2c read failed (%d)\n", ret);
+        return ret;
+    }
+
+    avt_info(sd, "Camera supported lane counts value: 0x%x\n", avt_supported_lane_counts);
+
+    if (!priv->fallback_app_running)
+    {
+        uint32_t requested_lanes = (priv->csi_fixed_lanes > 0) ? priv->csi_fixed_lanes : priv->s_data->numlanes;
+        if (priv->csi_fixed_lanes > 0) {
+          avt_info(sd, "Lane count overridden in device tree: %u\n", requested_lanes);
+        }
+
+        if(!(test_bit(requested_lanes - 1, (const long *)(&avt_supported_lane_counts)))) {
+            avt_err(sd, "requested number of lanes (%u) not supported by this camera!\n",
+                    requested_lanes);
+            return -EINVAL;
+        }
+
+        /* Set number of lanes */
+        ret = avt_reg_write(priv->client,
+                priv->cci_reg.bcrm_addr + BCRM_CSI2_LANE_COUNT_8RW,
+                requested_lanes);
+        if (ret < 0) {
+            avt_err(sd, "i2c write failed (%d)\n", ret);
+            return ret;
+        }
+
+        priv->numlanes = requested_lanes;
+
+        ret = avt_reg_read(priv->client,
+                priv->cci_reg.bcrm_addr + BCRM_CSI2_CLOCK_MIN_32R,
+                AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_32,
+                (char *) &avt_min_clk);
+
+        if (ret < 0) {
+            avt_err(sd, "i2c read failed (%d)\n", ret);
+            return ret;
+        }
+
+        ret = avt_reg_read(priv->client,
+                priv->cci_reg.bcrm_addr + BCRM_CSI2_CLOCK_MAX_32R,
+                AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_32,
+                (char *) &avt_max_clk);
+
+        if (ret < 0) {
+            avt_err(sd, "i2c read failed (%d)\n", ret);
+            return ret;
+        }
+
+        avt_dbg(sd, "csi clock camera range: %d:%d Hz, host range: %d:%d Hz\n",
+            avt_min_clk, avt_max_clk,
+            CSI_HOST_CLK_MIN_FREQ, CSI_HOST_CLK_MAX_FREQ);
+
+        if (common_range(avt_min_clk, avt_max_clk, 1,
+                CSI_HOST_CLK_MIN_FREQ, CSI_HOST_CLK_MAX_FREQ, 1,
+                &common_min_clk, &common_max_clk, &common_inc_clk)
+                == false) {
+            avt_err(sd, "no common clock range for camera and host possible!\n");
+            return -EINVAL;
+        }
+
+        avt_dbg(sd, "camera/host common csi clock range: %d:%d Hz\n",
+                common_min_clk, common_max_clk);
+
+        if (priv->csi_clk_freq == 0) {
+            avt_dbg(sd, "no csi clock requested, using common max (%d Hz)\n",
+                    common_max_clk);
+            priv->csi_clk_freq = common_max_clk;
+        } else {
+            avt_dbg(sd, "using csi clock from dts: %u Hz\n",
+                    priv->csi_clk_freq);
+        }
+
+        if ((priv->csi_clk_freq < common_min_clk) ||
+                (priv->csi_clk_freq > common_max_clk)) {
+            avt_err(sd, "unsupported csi clock frequency (%d Hz, range: %d:%d Hz)!\n",
+                    priv->csi_clk_freq, common_min_clk,
+                    common_max_clk);
+            return -EINVAL;
+        }
+
+        CLEAR(i2c_reg);
+        clk = priv->csi_clk_freq;
+        swapbytes(&clk, AV_CAM_DATA_SIZE_32);
+        i2c_reg = priv->cci_reg.bcrm_addr + BCRM_CSI2_CLOCK_32RW;
+        i2c_reg_size = AV_CAM_REG_SIZE;
+        i2c_reg_count = AV_CAM_DATA_SIZE_32;
+        i2c_reg_buf = (char *) &clk;
+        ret = ioctl_gencam_i2cwrite_reg(priv->client, i2c_reg, i2c_reg_size,
+                        i2c_reg_count, i2c_reg_buf);
+
+        ret = avt_reg_read(priv->client,
+                priv->cci_reg.bcrm_addr + BCRM_CSI2_CLOCK_32RW,
+                AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_32,
+                (char *) &avt_max_clk);
+
+        if (ret < 0) {
+            avt_err(sd, "i2c read failed (%d)\n", ret);
+            return ret;
+        }
+
+        avt_dbg(sd, "csi clock read from camera: %d Hz\n", avt_max_clk);
+    }
+
+    ret = avt_read_fmt_from_device(sd, &(priv->mbus_fmt_code));
+    if (ret < 0)
+        return ret;
+
+    ret = avt_init_frame_param(sd);
+    if (ret < 0)
+        return ret;
+
+    sel.target = V4L2_SEL_TGT_CROP;
+    sel.r = priv->frmp.r;
+    ret = avt_set_selection(sd, NULL, &sel);
+    if (ret < 0)
+        return ret;
+
+    // set BCRM mode
+    CLEAR(i2c_reg);
+    i2c_reg = CCI_CHANGE_MODE_8W;
+    i2c_reg_size = AV_CAM_REG_SIZE;
+    i2c_reg_count = AV_CAM_DATA_SIZE_8;
+    i2c_reg_buf = (char *) &bcm_mode;
+
+    ret = ioctl_gencam_i2cwrite_reg(priv->client,
+            i2c_reg, i2c_reg_size,
+            i2c_reg_count, i2c_reg_buf);
+    if (ret < 0) {
+        avt_err(sd, "Failed to set BCM mode: i2c write failed (%d)\n", ret);
+        return ret;
+    }
+    priv->mode = AVT_BCRM_MODE;
+
+
+    return 0;
+}
+
+static int avt_initialize_controls(struct i2c_client *client, struct avt_csi2_priv *priv) {
+    struct v4l2_queryctrl qctrl;
+    struct v4l2_query_ext_ctrl qctrl_ext;
+    struct v4l2_ctrl *ctrl;
+    int j, i, ret;
+
+    v4l2_ctrl_handler_init(&priv->hdl, ARRAY_SIZE(avt_ctrl_mappings));
+
+    for (i = 0, j = 0; j < ARRAY_SIZE(avt_ctrl_mappings); ++j) {
+        CLEAR(qctrl);
+        CLEAR(qctrl_ext);
+        qctrl.id = avt_ctrl_mappings[j].id;
+        qctrl_ext.id = avt_ctrl_mappings[j].id;
+        if(avt_ctrl_mappings[j].data_size == AV_CAM_DATA_SIZE_64) {
+            ret = ioctl_queryctrl64(priv->subdev, &qctrl_ext);
+            if (ret < 0) {
+                continue;
+            }
+
+            dev_dbg(&client->dev, "Checking caps: %s - Range: %lld-%lld s: %llu d: %lld - %sabled\n",
+                avt_ctrl_mappings[j].attr.name,
+                qctrl_ext.minimum,
+                qctrl_ext.maximum,
+                qctrl_ext.step,
+                qctrl_ext.default_value,
+                (qctrl_ext.flags & V4L2_CTRL_FLAG_DISABLED) ?
+                "dis" : "en");
+            if (qctrl_ext.flags & V4L2_CTRL_FLAG_DISABLED) {
+                continue;
+            }
+
+            priv->ctrl_cfg[i].type = qctrl_ext.type;
+
+            priv->ctrl_cfg[i].min = qctrl_ext.minimum;
+            priv->ctrl_cfg[i].max = qctrl_ext.maximum;
+            priv->ctrl_cfg[i].def = qctrl_ext.default_value;
+            priv->ctrl_cfg[i].step = qctrl_ext.step;
+            priv->ctrl_cfg[i].flags = qctrl_ext.flags;
+
+            if (qctrl_ext.type == V4L2_CTRL_TYPE_INTEGER64) {
+                priv->ctrl_cfg[i].flags |= V4L2_CTRL_FLAG_SLIDER;
+            }
+
+        } else {
+            ret = ioctl_queryctrl(priv->subdev, &qctrl);
+            if (ret < 0) {
+                continue;
+            }
+
+            dev_dbg(&client->dev, "Checking caps: %s - Range: %d-%d s: %d d: %d - %sabled\n",
+                avt_ctrl_mappings[j].attr.name,
+                qctrl.minimum,
+                qctrl.maximum,
+                qctrl.step,
+                qctrl.default_value,
+                (qctrl.flags & V4L2_CTRL_FLAG_DISABLED) ?
+                "dis" : "en");
+
+            if (qctrl.flags & V4L2_CTRL_FLAG_DISABLED) {
+                continue;
+            }
+
+            priv->ctrl_cfg[i].type = qctrl.type;
+            priv->ctrl_cfg[i].min = qctrl.minimum;
+            priv->ctrl_cfg[i].max = qctrl.maximum;
+            priv->ctrl_cfg[i].def = qctrl.default_value;
+            priv->ctrl_cfg[i].step = qctrl.step;
+            priv->ctrl_cfg[i].flags = qctrl.flags;
+
+            if ((qctrl.type == V4L2_CTRL_TYPE_INTEGER)
+                && !(qctrl.flags & V4L2_CTRL_FLAG_VOLATILE)) {
+                priv->ctrl_cfg[i].flags |= V4L2_CTRL_FLAG_SLIDER;
+            }
+        }
+
+        priv->ctrl_cfg[i].ops = &avt_ctrl_ops;
+        priv->ctrl_cfg[i].name = avt_ctrl_mappings[j].attr.name;
+        priv->ctrl_cfg[i].id = avt_ctrl_mappings[j].id;
+        priv->hdl.error = 0;
+
+        if (priv->ctrl_cfg[i].id == V4L2_CID_TRIGGER_ACTIVATION)
+        {
+            priv->ctrl_cfg[i].qmenu = v4l2_triggeractivation_menu;
+            priv->ctrl_cfg[i].menu_skip_mask = 0;
+        }
+
+        if (priv->ctrl_cfg[i].id == V4L2_CID_TRIGGER_SOURCE)
+        {
+            priv->ctrl_cfg[i].qmenu = v4l2_triggersource_menu;
+            priv->ctrl_cfg[i].menu_skip_mask = 0;
+        }
+
+        ctrl = v4l2_ctrl_new_custom(&priv->hdl, &priv->ctrl_cfg[i], (void *)&avt_ctrl_mappings[j]);
+
+        if (ctrl == NULL) {
+            dev_err(&client->dev, "Failed to init %s ctrl (%d)\n", priv->ctrl_cfg[i].name, priv->hdl.error);
+            continue;
+        }
+
+        priv->ctrls[i] = ctrl;
+        i++;
+    }
+
+    for (j = 0; j < ARRAY_SIZE(avt_tegra_ctrl); ++j, ++i) {
+        ctrl = v4l2_ctrl_new_custom(&priv->hdl, &avt_tegra_ctrl[j], NULL);
+
+        if (ctrl == NULL) {
+            dev_err(&client->dev, "Failed to init %s ctrl\n",avt_tegra_ctrl[j].name);
+            continue;
+        }
+
+        priv->ctrls[i] = ctrl;
+    }
+
+    return i;
+}
+
+
+static int avt_csi2_probe(struct i2c_client *client,
+			const struct i2c_device_id *id)
+{
+    struct avt_csi2_priv *priv;
+    struct device *dev = &client->dev;
+    int ret;
+    struct v4l2_of_endpoint *endpoint;
+    struct device_node *ep;
+    struct camera_common_data *common_data;
+    union cci_device_caps_reg device_caps;
+    union bcrm_feature_reg feature_inquiry_reg;
+    
+    v4l_dbg(1, debug, client, "chip found @ 0x%x (%s)\n",
+        client->addr << 1, client->adapter->name);
+
+    common_data = devm_kzalloc(&client->dev, sizeof(struct camera_common_data), GFP_KERNEL);
+    if (!common_data) {
+        return -ENOMEM;
+    }
+
+    priv = devm_kzalloc(&client->dev, sizeof(struct avt_csi2_priv), GFP_KERNEL);
+    if (!priv) {
+        return -ENOMEM;
+    }
+
+    priv->subdev = &common_data->subdev;
+    priv->subdev->ctrl_handler = &priv->hdl;
+    priv->client = client;
+    priv->s_data = common_data;
+
+    ep = of_graph_get_next_endpoint(dev->of_node, NULL);
+    if (!ep) {
+        dev_err(dev, "missing endpoint node\n");
+        return -EINVAL;
+    }
+
+    endpoint = v4l2_of_alloc_parse_endpoint(ep);
+    if (IS_ERR(endpoint)) {
+        dev_err(dev, "failed to parse endpoint\n");
+        return PTR_ERR(endpoint);
+    }
+
+    v4l2_i2c_subdev_init(priv->subdev, client, &avt_csi2_subdev_ops);
+
+    priv->subdev->internal_ops = &avt_csi2_int_ops;
+    priv->subdev->dev = &client->dev;
+
+    /* Set owner to NULL so we can unload the driver module */
+    priv->subdev->owner = NULL;
+
+    common_data->priv = priv;
+    common_data->dev = &client->dev;
+    common_data->ctrl_handler = &priv->hdl;
+    common_data->ctrls = priv->ctrls;
+
+    atomic_set(&priv->force_value_update, 0);
+    priv->value_update_interval = 1000;
+    init_waitqueue_head(&priv->value_update_wq);
+
+
+	priv->streamcap.capability = V4L2_CAP_TIMEPERFRAME;
+	priv->streamcap.capturemode = 0;
+	priv->streamcap.timeperframe.denominator = DEFAULT_FPS;
+	priv->streamcap.timeperframe.numerator = 1;
+    priv->streamcap.readbuffers = 1;
+
+    if (!device_present(client)) {
+        dev_err(dev, "No camera detected (driver V%s)", DRIVER_VERSION);
+        return -ENXIO;
+    } else {
+        dev_info(dev, "Camera detected! (driver V%s)", DRIVER_VERSION);
+    }
+
+    /* Execute softreset to ensure camera is not in GenCP mode anymore */
+    ret = soft_reset(client);
+    if (ret < 0) {
+        return ret;
+    }
+
+    ret = read_cci_registers(client);
+    dump_camera_firmware_version(client);
+
+    /* Check if camera is running fallback app */
+    priv->fallback_app_running = is_fallback_app_running(client);
+
+    /* DEBUG: Dump all BCRM registers */
+    bcrm_dump(client);
+
+    /* Set subdev name */
+    snprintf(priv->subdev->name, sizeof(priv->subdev->name), "%s %s %s%d-%x",
+        priv->cci_reg.family_name, priv->cci_reg.model_name,
+        priv->fallback_app_running ? "FB " : "",
+        i2c_adapter_id(client->adapter), client->addr);
+
+    if (ret < 0) {
+        dev_err(dev, "%s: read_cci_registers failed: %d\n", __func__, ret);
+        return -EIO;
+    }
+
+    ret = cci_version_check(client);
+    if (ret < 0) {
+        dev_err(&client->dev, "cci version mismatch!\n");
+        return -EINVAL;
+    }
+
+    ret = bcrm_version_check(client);
+    if (ret < 0) {
+        dev_err(&client->dev, "bcrm version mismatch!\n");
+        return -EINVAL;
+    }
+
+    dev_dbg(&client->dev, "correct bcrm version\n");
+
+    priv->write_handshake_available = bcrm_get_write_handshake_availibility(client);
+
+    avt_init_avail_formats(priv->subdev);
+
+	device_caps.value = priv->cci_reg.device_capabilities;
+
+    if (device_caps.caps.gencp) {
+        ret = read_gencp_registers(client);
+        if (ret < 0) {
+            dev_err(dev, "%s: read_gencp_registers failed: %d\n", __func__, ret);
+            return ret;
+        }
+
+        ret = gcprm_version_check(client);
+        if (ret < 0) {
+            dev_err(&client->dev, "gcprm version mismatch!\n");
+            return ret;
+        }
+
+        dev_dbg(&client->dev, "correct gcprm version\n");
+    }
+
+    ret = sysfs_create_group(&dev->kobj, &avt_csi2_attr_grp);
+    if (ret) {
+        dev_err(dev, "Failed to create sysfs group (%d)\n", ret);
+        return ret;
+    }
+
+    priv->pad.flags = MEDIA_PAD_FL_SOURCE;
+    priv->subdev->entity.ops = &avt_csi2_media_ops;
+    ret = tegra_media_entity_init(&priv->subdev->entity, 1, &priv->pad, true, true);
+    if (ret < 0) {
+        return ret;
+    }
+
+    ret = camera_common_initialize(common_data, "avt_csi2");
+    if (ret) {
+        dev_err(&client->dev, "Failed to initialize tegra common for avt.\n");
+        return ret;
+    }
+
+    if (of_property_read_u32(dev->of_node, "csi_clk_freq", &priv->csi_clk_freq)) {
+        priv->csi_clk_freq = 0;
+    }
+  
+    if (of_property_read_u32(dev->of_node, "csi_lanes", &priv->csi_fixed_lanes)) {
+        priv->csi_fixed_lanes = 0;
+    }
+
+    priv->numlanes = priv->s_data->numlanes;
+    priv->stream_on = false;
+    priv->cross_update = false;
+    priv->stride_align_enabled = true;
+    priv->crop_align_enabled = true;
+    ret = avt_init_mode(priv->subdev);
+    if (ret < 0) {
+        return ret;
+    }
+
+    ret = read_feature_register(priv->subdev, &feature_inquiry_reg);
+    if (ret < 0) {
+      dev_err(&client->dev, "failed to read feature reqister: %d\n", ret);
+      return ret;
+    }
+
+    /* Workaround for firmware not initializing auto exposure limits when exposure limits change */
+    if (feature_inquiry_reg.feature_inq.exposure_auto) {
+      u64 value;
+      ret = avt_reg_read(client,
+          priv->cci_reg.bcrm_addr + BCRM_EXPOSURE_TIME_MIN_64R,
+          AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+          (char *) &value);
+      if (ret < 0) {
+        avt_err(priv->subdev, "BCRM_EXPOSURE_TIME_MIN_64R: i2c read failed (%d)\n",
+            ret);
+        return ret;
+      }
+
+      swapbytes(&value, 8);
+      ret = ioctl_gencam_i2cwrite_reg(client, BCRM_EXPOSURE_AUTO_MIN_64RW + priv->cci_reg.bcrm_addr,
+        AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64, (char*) &value);
+
+      if (ret < 0) {
+        avt_err(priv->subdev, "Failed to initialize exposure auto minimum: %d\n", ret);
+      }
+
+      /* reading the Maximum Exposure time */
+      ret = avt_reg_read(client,
+          priv->cci_reg.bcrm_addr + BCRM_EXPOSURE_TIME_MAX_64R,
+          AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64,
+          (char *) &value);
+      if (ret < 0) {
+        avt_err(priv->subdev, "BCRM_EXPOSURE_TIME_MAX_64R: i2c read failed (%d)\n",
+            ret);
+        return ret;
+      }
+
+      swapbytes(&value, 8);
+      ret = ioctl_gencam_i2cwrite_reg(client, BCRM_EXPOSURE_AUTO_MAX_64RW + priv->cci_reg.bcrm_addr,
+        AV_CAM_REG_SIZE, AV_CAM_DATA_SIZE_64, (char*) &value);
+
+      if (ret < 0) {
+        avt_err(priv->subdev, "Failed to initialize exposure auto maximum: %d\n", ret);
+      }
+    }
+
+    common_data->numctrls = avt_initialize_controls(client, priv);
+
+	ret = read_framerate(priv->subdev, &(priv->streamcap.timeperframe));
+
+	if(ret < 0) {
+		return ret;
+	}
+
+	priv->ignore_control_write = false;
+
+	ret = v4l2_async_register_subdev(priv->subdev);
+    if (ret < 0) {
+        return ret;
+    }
+
+    dev_info(&client->dev, "sensor %s registered\n", priv->subdev->name);
+
+    return 0;
+}
+
+static int avt_csi2_remove(struct i2c_client *client)
+{
+	struct v4l2_subdev *sd = i2c_get_clientdata(client);
+
+	sysfs_remove_group(&client->dev.kobj, &avt_csi2_attr_grp);
+
+	v4l2_async_unregister_subdev(sd);
+	v4l2_device_unregister_subdev(sd);
+	media_entity_cleanup(&sd->entity);
+
+	return 0;
+}
+
+static struct i2c_device_id avt_csi2_id[] = {
+	{"avt_csi2", 0},
+	{}
+};
+
+MODULE_DEVICE_TABLE(i2c, avt_csi2_id);
+
+static struct i2c_driver avt_csi2_driver = {
+	.driver = {
+		.name = "avt_csi2",
+		.owner = THIS_MODULE,
+		.of_match_table = of_match_ptr(avt_csi2_of_match),
+	},
+	.probe = avt_csi2_probe,
+	.remove = avt_csi2_remove,
+	.id_table = avt_csi2_id,
+};
+
+module_i2c_driver(avt_csi2_driver);
+
+MODULE_AUTHOR("Allied Vision Technologies GmbH");
+MODULE_DESCRIPTION("Allied Vision MIPI CSI-2 Camera Driver");
+MODULE_LICENSE("GPL");
+MODULE_VERSION(DRIVER_VERSION);
diff --git a/drivers/media/i2c/avt_csi2.h b/drivers/media/i2c/avt_csi2.h
new file mode 100644
index 000000000000..e23558ba3904
--- /dev/null
+++ b/drivers/media/i2c/avt_csi2.h
@@ -0,0 +1,604 @@
+/*
+ * Allied Vision CSI2 Camera
+ *
+ * This program is free software; you may redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ *
+ */
+
+#ifndef __AVT_CSI2_H__
+#define __AVT_CSI2_H__
+
+
+#include <media/camera_common.h>
+#include "alvium_regs.h"
+#include "alvium_helper.h"
+
+#define AVT_MAX_CTRLS 50
+struct avt_frame_param {
+    /* crop settings */
+    struct v4l2_rect r;
+
+    /* min/max/step values for frame size */
+    uint32_t minh;
+    uint32_t maxh;
+    uint32_t sh;
+    uint32_t minw;
+    uint32_t maxw;
+    uint32_t sw;
+    uint32_t minhoff;
+    uint32_t maxhoff;
+    uint32_t shoff;
+    uint32_t minwoff;
+    uint32_t maxwoff;
+    uint32_t swoff;
+};
+
+enum avt_mode {
+    AVT_BCRM_MODE,
+    AVT_GENCP_MODE,
+};
+struct avt_csi2_priv {
+    struct v4l2_subdev *subdev;
+    struct media_pad pad;
+    struct i2c_client *client;
+    u32 mbus_fmt_code;
+
+    struct v4l2_captureparm streamcap;
+    struct v4l2_ctrl_handler hdl;
+    struct camera_common_data *s_data;
+
+    struct v4l2_ctrl_config ctrl_cfg[AVT_MAX_CTRLS];
+    struct v4l2_ctrl *ctrls[AVT_MAX_CTRLS];
+
+    bool stream_on;
+    bool cross_update;
+    bool write_handshake_available;
+    bool stride_align_enabled;
+    bool crop_align_enabled;
+    bool trigger_mode;
+    bool fallback_app_running;
+
+    uint32_t csi_fixed_lanes;
+    uint32_t csi_clk_freq;
+    int numlanes;
+    struct avt_frame_param frmp;
+
+    struct cci_reg cci_reg;
+    struct gencp_reg gencp_reg;
+
+    enum avt_mode mode;
+
+    int32_t *available_fmts;
+    uint32_t available_fmts_cnt;
+
+    struct task_struct *trig_thread;
+    struct v4l2_trigger_rate *trigger_rate;
+
+    int acquisition_active_invert;
+
+    struct task_struct *value_update_thread;
+    wait_queue_head_t value_update_wq;
+    atomic_t force_value_update;
+    int value_update_interval;
+
+    bool ignore_control_write;
+};
+struct avt_ctrl {
+    __u32       id;
+    __u32       value0;
+    __u32       value1;
+};
+
+#define V4L2_AV_CSI2_BASE               0x1000
+#define V4L2_AV_CSI2_WIDTH_R            (V4L2_AV_CSI2_BASE+0x0001)
+#define V4L2_AV_CSI2_WIDTH_W            (V4L2_AV_CSI2_BASE+0x0002)
+#define V4L2_AV_CSI2_WIDTH_MINVAL_R     (V4L2_AV_CSI2_BASE+0x0003)
+#define V4L2_AV_CSI2_WIDTH_MAXVAL_R     (V4L2_AV_CSI2_BASE+0x0004)
+#define V4L2_AV_CSI2_WIDTH_INCVAL_R     (V4L2_AV_CSI2_BASE+0x0005)
+#define V4L2_AV_CSI2_HEIGHT_R           (V4L2_AV_CSI2_BASE+0x0006)
+#define V4L2_AV_CSI2_HEIGHT_W           (V4L2_AV_CSI2_BASE+0x0007)
+#define V4L2_AV_CSI2_HEIGHT_MINVAL_R    (V4L2_AV_CSI2_BASE+0x0008)
+#define V4L2_AV_CSI2_HEIGHT_MAXVAL_R    (V4L2_AV_CSI2_BASE+0x0009)
+#define V4L2_AV_CSI2_HEIGHT_INCVAL_R    (V4L2_AV_CSI2_BASE+0x000A)
+#define V4L2_AV_CSI2_PIXELFORMAT_R      (V4L2_AV_CSI2_BASE+0x000B)
+#define V4L2_AV_CSI2_PIXELFORMAT_W      (V4L2_AV_CSI2_BASE+0x000C)
+#define V4L2_AV_CSI2_PALYLOADSIZE_R     (V4L2_AV_CSI2_BASE+0x000D)
+#define V4L2_AV_CSI2_STREAMON_W         (V4L2_AV_CSI2_BASE+0x000E)
+#define V4L2_AV_CSI2_STREAMOFF_W        (V4L2_AV_CSI2_BASE+0x000F)
+#define V4L2_AV_CSI2_ABORT_W            (V4L2_AV_CSI2_BASE+0x0010)
+#define V4L2_AV_CSI2_ACQ_STATUS_R       (V4L2_AV_CSI2_BASE+0x0011)
+#define V4L2_AV_CSI2_HFLIP_R            (V4L2_AV_CSI2_BASE+0x0012)
+#define V4L2_AV_CSI2_HFLIP_W            (V4L2_AV_CSI2_BASE+0x0013)
+#define V4L2_AV_CSI2_VFLIP_R            (V4L2_AV_CSI2_BASE+0x0014)
+#define V4L2_AV_CSI2_VFLIP_W            (V4L2_AV_CSI2_BASE+0x0015)
+#define V4L2_AV_CSI2_OFFSET_X_W         (V4L2_AV_CSI2_BASE+0x0016)
+#define V4L2_AV_CSI2_OFFSET_X_R         (V4L2_AV_CSI2_BASE+0x0017)
+#define V4L2_AV_CSI2_OFFSET_X_MIN_R     (V4L2_AV_CSI2_BASE+0x0018)
+#define V4L2_AV_CSI2_OFFSET_X_MAX_R     (V4L2_AV_CSI2_BASE+0x0019)
+#define V4L2_AV_CSI2_OFFSET_X_INC_R     (V4L2_AV_CSI2_BASE+0x001A)
+#define V4L2_AV_CSI2_OFFSET_Y_W         (V4L2_AV_CSI2_BASE+0x001B)
+#define V4L2_AV_CSI2_OFFSET_Y_R         (V4L2_AV_CSI2_BASE+0x001C)
+#define V4L2_AV_CSI2_OFFSET_Y_MIN_R     (V4L2_AV_CSI2_BASE+0x001D)
+#define V4L2_AV_CSI2_OFFSET_Y_MAX_R     (V4L2_AV_CSI2_BASE+0x001E)
+#define V4L2_AV_CSI2_OFFSET_Y_INC_R     (V4L2_AV_CSI2_BASE+0x001F)
+#define V4L2_AV_CSI2_SENSOR_WIDTH_R     (V4L2_AV_CSI2_BASE+0x0020)
+#define V4L2_AV_CSI2_SENSOR_HEIGHT_R    (V4L2_AV_CSI2_BASE+0x0021)
+#define V4L2_AV_CSI2_MAX_WIDTH_R        (V4L2_AV_CSI2_BASE+0x0022)
+#define V4L2_AV_CSI2_MAX_HEIGHT_R       (V4L2_AV_CSI2_BASE+0x0023)
+#define V4L2_AV_CSI2_CURRENTMODE_R      (V4L2_AV_CSI2_BASE+0x0024)
+#define V4L2_AV_CSI2_CHANGEMODE_W       (V4L2_AV_CSI2_BASE+0x0025)
+#define V4L2_AV_CSI2_BAYER_PATTERN_R    (V4L2_AV_CSI2_BASE+0x0026)
+#define V4L2_AV_CSI2_BAYER_PATTERN_W    (V4L2_AV_CSI2_BASE+0x0027)
+
+/* Driver release version */
+#define STR_HELPER(x) #x
+#define STR(x) STR_HELPER(x)
+
+/* Driver release version */
+#define DRV_VER_MAJOR           4
+#define DRV_VER_MINOR           0
+#define DRV_VER_PATCH           0
+#define DRV_VER_BUILD           0
+#define DRIVER_VERSION          STR(DRV_VER_MAJOR) "." STR(DRV_VER_MINOR) "." STR(DRV_VER_PATCH) "." STR(DRV_VER_BUILD)
+
+#define BCRM_DEVICE_VERSION     0x00010000
+#define BCRM_MAJOR_VERSION      0x0001
+#define BCRM_MINOR_VERSION      0x0000
+
+#define GCPRM_DEVICE_VERSION    0x00010000
+#define GCPRM_MAJOR_VERSION     0x0001
+#define GCPRM_MINOR_VERSION     0x0000
+
+/* MIPI CSI-2 data types */
+#define MIPI_DT_YUV420          0x18 /* YYY.../UYVY.... */
+#define MIPI_DT_YUV420_LEGACY   0x1a /* UYY.../VYY...   */
+#define MIPI_DT_YUV422          0x1e /* UYVY...         */
+#define MIPI_DT_RGB444          0x20
+#define MIPI_DT_RGB555          0x21
+#define MIPI_DT_RGB565          0x22
+#define MIPI_DT_RGB666          0x23
+#define MIPI_DT_RGB888          0x24
+#define MIPI_DT_RAW6            0x28
+#define MIPI_DT_RAW7            0x29
+#define MIPI_DT_RAW8            0x2a
+#define MIPI_DT_RAW10           0x2b
+#define MIPI_DT_RAW12           0x2c
+#define MIPI_DT_RAW14           0x2d
+#define MIPI_DT_CUSTOM          0x31
+
+enum bayer_format {
+    monochrome,/* 0 */
+    bayer_gr,
+    bayer_rg,
+    bayer_gb,
+    bayer_bg,
+};
+struct bcrm_to_v4l2 {
+    int64_t min_bcrm;
+    int64_t max_bcrm;
+    int64_t step_bcrm;
+    int32_t min_v4l2;
+    int32_t max_v4l2;
+    int32_t step_v4l2;
+};
+
+enum convert_type {
+    min_enum,/* 0 */
+    max_enum,
+    step_enum,
+};
+
+#define CLEAR(x)        memset(&(x), 0, sizeof(x))
+
+#define EXP_ABS         100000UL
+#define UHZ_TO_HZ       1000000UL
+#define FRAQ_NUM        1000
+
+#define CCI_REG_LAYOUT_MINVER_MASK  (0x0000ffff)
+#define CCI_REG_LAYOUT_MINVER_SHIFT (0)
+#define CCI_REG_LAYOUT_MAJVER_MASK  (0xffff0000)
+#define CCI_REG_LAYOUT_MAJVER_SHIFT (16)
+
+#define CCI_REG_LAYOUT_MINVER   0
+#define CCI_REG_LAYOUT_MAJVER   1
+
+#define AV_ATTR_REVERSE_X                       {"Reverse X",                       0}
+#define AV_ATTR_REVERSE_Y                       {"Reverse Y",                       1}
+#define AV_ATTR_INTENSITY_AUTO                  {"Intensity Auto",                  2}
+#define AV_ATTR_BRIGHTNESS                      {"Brightness",                      3}
+/* Red & Blue balance features are enabled by default since it doesn't have
+ * option in BCRM FEATURE REGISTER
+ */
+#define AV_ATTR_RED_BALANCE                     {"Red Balance",                     3}
+#define AV_ATTR_BLUE_BALANCE                    {"Blue Balance",                    3}
+#define AV_ATTR_GAIN                            {"Gain",                            4}
+#define AV_ATTR_GAMMA                           {"Gamma",                           5}
+#define AV_ATTR_CONTRAST                        {"Contrast",                        6}
+#define AV_ATTR_SATURATION                      {"Saturation",                      7}
+#define AV_ATTR_HUE                             {"Hue",                             8}
+#define AV_ATTR_WHITEBALANCE                    {"White Balance",                   9}
+#define AV_ATTR_SHARPNESS                       {"Sharpnesss",                      10}
+#define AV_ATTR_EXPOSURE_AUTO                   {"Exposure Auto",                   11}
+#define AV_ATTR_EXPOSURE_AUTO_MIN               {"Exposure Auto Min",               11}
+#define AV_ATTR_EXPOSURE_AUTO_MAX               {"Exposure Auto Max",               11}
+#define AV_ATTR_AUTOGAIN                        {"Gain Auto",                       12}
+#define AV_ATTR_GAIN_AUTO_MIN                   {"Gain Auto Min",                   12}
+#define AV_ATTR_GAIN_AUTO_MAX                   {"Gain Auto Max",                   12}
+#define AV_ATTR_EXPOSURE                        {"Exposure",                        0}
+#define AV_ATTR_EXPOSURE_ABSOLUTE               {"Exposure Absolute",               0}
+#define AV_ATTR_WHITEBALANCE_AUTO               {"Auto White Balance",              13}
+#define AV_ATTR_EXPOSURE_ACTIVE_LINE_MODE       {"Exposure Active Line Mode",       18}
+#define AV_ATTR_EXPOSURE_ACTIVE_LINE_SELECTOR   {"Exposure Active Line Selector",   18}
+#define AV_ATTR_EXPOSURE_ACTIVE_INVERT          {"Exposure Active Invert",          18}
+
+#define AV_ATTR_TRIGGER_MODE                    {"Trigger Mode",                    17}
+#define AV_ATTR_TRIGGER_ACTIVATION              {"Trigger Activation",              17}
+#define AV_ATTR_TRIGGER_SOURCE                  {"Trigger Source",                  17}
+#define AV_ATTR_TRIGGER_SOFTWARE                {"Trigger Software",                17}
+#define AV_ATTR_DEVICE_TEMPERATURE              {"Device Temperature",              14}
+
+struct avt_ctrl_mapping {
+    u8  reg_size;
+    u8  data_size;
+    u16 min_offset;
+    u16 max_offset;
+    u16 reg_offset;
+    u16 step_offset;
+    u32 id;
+    u32 type;
+    u32 flags;
+    struct {
+        s8  *name;
+        u8  feature_avail;
+    } attr;
+    bool disabled_while_streaming : 1;
+};
+
+#define V4L2_CID_EXPOSURE_AUTO_MIN              (V4L2_CID_CAMERA_CLASS_BASE+40)
+#define V4L2_CID_EXPOSURE_AUTO_MAX              (V4L2_CID_CAMERA_CLASS_BASE+41)
+#define V4L2_CID_GAIN_AUTO_MIN                  (V4L2_CID_CAMERA_CLASS_BASE+42)
+#define V4L2_CID_GAIN_AUTO_MAX                  (V4L2_CID_CAMERA_CLASS_BASE+43)
+#define V4L2_CID_EXPOSURE_ACTIVE_LINE_MODE      (V4L2_CID_CAMERA_CLASS_BASE+44)
+#define V4L2_CID_EXPOSURE_ACTIVE_LINE_SELECTOR  (V4L2_CID_CAMERA_CLASS_BASE+45)
+#define V4L2_CID_EXPOSURE_ACTIVE_INVERT         (V4L2_CID_CAMERA_CLASS_BASE+46)
+
+/* Trigger mode to ON/OFF */
+#define V4L2_CID_TRIGGER_MODE                   (V4L2_CID_CAMERA_CLASS_BASE+47)
+
+/* trigger activation: edge_rising, edge_falling, edge_any, level_high, level_low */
+#define V4L2_CID_TRIGGER_ACTIVATION             (V4L2_CID_CAMERA_CLASS_BASE+48)
+
+/* trigger source: software, gpio0, gpio1 */
+#define V4L2_CID_TRIGGER_SOURCE                 (V4L2_CID_CAMERA_CLASS_BASE+49)
+
+/* Execute a software trigger */
+#define V4L2_CID_TRIGGER_SOFTWARE               (V4L2_CID_CAMERA_CLASS_BASE+50)
+
+/* Camera temperature readout */
+#define V4L2_CID_DEVICE_TEMPERATURE             (V4L2_CID_CAMERA_CLASS_BASE+51)
+
+const struct avt_ctrl_mapping avt_ctrl_mappings[] = {
+    {
+        .id             = V4L2_CID_BRIGHTNESS,
+        .attr           = AV_ATTR_BRIGHTNESS,
+        .min_offset     = BCRM_BLACK_LEVEL_MIN_32R,
+        .max_offset     = BCRM_BLACK_LEVEL_MAX_32R,
+        .reg_offset     = BCRM_BLACK_LEVEL_32RW,
+        .step_offset    = BCRM_BLACK_LEVEL_INC_32R,
+        .reg_size       = AV_CAM_REG_SIZE,
+        .data_size      = AV_CAM_DATA_SIZE_32,
+        .type           = V4L2_CTRL_TYPE_INTEGER,
+        .flags          = 0,
+        .disabled_while_streaming = true,
+    },
+    {
+        .id             = V4L2_CID_CONTRAST,
+        .attr           = AV_ATTR_CONTRAST,
+        .min_offset     = BCRM_CONTRAST_VALUE_MIN_32R,
+        .max_offset     = BCRM_CONTRAST_VALUE_MAX_32R,
+        .reg_offset     = BCRM_CONTRAST_VALUE_32RW,
+        .step_offset    = BCRM_CONTRAST_VALUE_INC_32R,
+        .reg_size       = AV_CAM_REG_SIZE,
+        .data_size      = AV_CAM_DATA_SIZE_32,
+        .type           = V4L2_CTRL_TYPE_INTEGER,
+        .flags          = 0,
+    },
+    {
+        .id             = V4L2_CID_SATURATION,
+        .attr           = AV_ATTR_SATURATION,
+        .min_offset     = BCRM_SATURATION_MIN_32R,
+        .max_offset     = BCRM_SATURATION_MAX_32R,
+        .reg_offset     = BCRM_SATURATION_32RW,
+        .step_offset    = BCRM_SATURATION_INC_32R,
+        .reg_size       = AV_CAM_REG_SIZE,
+        .data_size      = AV_CAM_DATA_SIZE_32,
+        .type           = V4L2_CTRL_TYPE_INTEGER,
+        .flags          = 0,
+    },
+    {
+        .id             = V4L2_CID_HUE,
+        .attr           = AV_ATTR_HUE,
+        .min_offset     = BCRM_HUE_MIN_32R,
+        .max_offset     = BCRM_HUE_MAX_32R,
+        .reg_offset     = BCRM_HUE_32RW,
+        .step_offset    = BCRM_HUE_INC_32R,
+        .reg_size       = AV_CAM_REG_SIZE,
+        .data_size      = AV_CAM_DATA_SIZE_32,
+        .type           = V4L2_CTRL_TYPE_INTEGER,
+        .flags          = 0,
+    },
+    {
+        .id             = V4L2_CID_AUTO_WHITE_BALANCE,
+        .attr           = AV_ATTR_WHITEBALANCE_AUTO,
+        .reg_offset     = BCRM_WHITE_BALANCE_AUTO_8RW,
+        .reg_size       = AV_CAM_REG_SIZE,
+        .data_size      = AV_CAM_DATA_SIZE_8,
+        .type           = V4L2_CTRL_TYPE_BOOLEAN,
+        .flags          = 0,
+    },
+    {
+        .id             = V4L2_CID_DO_WHITE_BALANCE,
+        .attr           = AV_ATTR_WHITEBALANCE,
+        .reg_offset     = BCRM_WHITE_BALANCE_AUTO_8RW,
+        .reg_size       = AV_CAM_REG_SIZE,
+        .data_size      = AV_CAM_DATA_SIZE_8,
+        .type           = V4L2_CTRL_TYPE_BUTTON,
+        .flags          = 0,
+    },
+    {
+        .id             = V4L2_CID_RED_BALANCE,
+        .attr           = AV_ATTR_RED_BALANCE,
+        .min_offset     = BCRM_RED_BALANCE_RATIO_MIN_64R,
+        .max_offset     = BCRM_RED_BALANCE_RATIO_MAX_64R,
+        .reg_offset     = BCRM_RED_BALANCE_RATIO_64RW,
+        .step_offset    = BCRM_RED_BALANCE_RATIO_INC_64R,
+        .reg_size       = AV_CAM_REG_SIZE,
+        .data_size      = AV_CAM_DATA_SIZE_64,
+        .type           = V4L2_CTRL_TYPE_INTEGER64,
+        .flags          = 0,
+    },
+    {
+        .id             = V4L2_CID_BLUE_BALANCE,
+        .attr           = AV_ATTR_BLUE_BALANCE,
+        .min_offset     = BCRM_BLUE_BALANCE_RATIO_MIN_64R,
+        .max_offset     = BCRM_BLUE_BALANCE_RATIO_MAX_64R,
+        .reg_offset     = BCRM_BLUE_BALANCE_RATIO_64RW,
+        .step_offset    = BCRM_BLUE_BALANCE_RATIO_INC_64R,
+        .reg_size       = AV_CAM_REG_SIZE,
+        .data_size      = AV_CAM_DATA_SIZE_64,
+        .type           = V4L2_CTRL_TYPE_INTEGER64,
+        .flags          = 0,
+    },
+    {
+        .id             = V4L2_CID_GAMMA,
+        .attr           = AV_ATTR_GAMMA,
+        .min_offset     = BCRM_GAMMA_MIN_64R,
+        .max_offset     = BCRM_GAMMA_MAX_64R,
+        .reg_offset     = BCRM_GAMMA_64RW,
+        .step_offset    = BCRM_GAMMA_INC_64R,
+        .reg_size       = AV_CAM_REG_SIZE,
+        .data_size      = AV_CAM_DATA_SIZE_64,
+        .type           = V4L2_CTRL_TYPE_INTEGER64,
+        .flags          = 0,
+    },
+    {
+        .id             = V4L2_CID_EXPOSURE_ABSOLUTE,
+        .attr           = AV_ATTR_EXPOSURE_ABSOLUTE,
+        .reg_size       = AV_CAM_REG_SIZE,
+        .data_size      = AV_CAM_DATA_SIZE_32,
+        .type           = V4L2_CTRL_TYPE_INTEGER,
+        .flags          = 0,
+    },
+    {
+        .id             = V4L2_CID_EXPOSURE,
+        .attr           = AV_ATTR_EXPOSURE,
+        .min_offset     = BCRM_EXPOSURE_TIME_MIN_64R,
+        .max_offset     = BCRM_EXPOSURE_TIME_MAX_64R,
+        .reg_offset     = BCRM_EXPOSURE_TIME_64RW,
+        .step_offset    = BCRM_EXPOSURE_TIME_INC_64R,
+        .reg_size       = AV_CAM_REG_SIZE,
+        .data_size      = AV_CAM_DATA_SIZE_64,
+        .type           = V4L2_CTRL_TYPE_INTEGER64,
+        .flags          = 0,
+    },
+    {
+        .id             = V4L2_CID_AUTOGAIN,
+        .attr           = AV_ATTR_AUTOGAIN,
+        .reg_offset     = BCRM_GAIN_AUTO_8RW,
+        .reg_size       = AV_CAM_REG_SIZE,
+        .data_size      = AV_CAM_DATA_SIZE_8,
+        .type           = V4L2_CTRL_TYPE_BOOLEAN,
+        .flags          = 0,
+    },
+    {
+        .id             = V4L2_CID_GAIN,
+        .attr           = AV_ATTR_GAIN,
+        .min_offset     = BCRM_GAIN_MIN_64R,
+        .max_offset     = BCRM_GAIN_MAX_64R,
+        .reg_offset     = BCRM_GAIN_64RW,
+        .step_offset    = BCRM_GAIN_INC_64R,
+        .reg_size       = AV_CAM_REG_SIZE,
+        .data_size      = AV_CAM_DATA_SIZE_64,
+        .type           = V4L2_CTRL_TYPE_INTEGER64,
+        .flags          = 0,
+    },
+    {
+        .id             = V4L2_CID_HFLIP,
+        .attr           = AV_ATTR_REVERSE_X,
+        .reg_offset     = BCRM_IMG_REVERSE_X_8RW,
+        .reg_size       = AV_CAM_REG_SIZE,
+        .data_size      = AV_CAM_DATA_SIZE_8,
+        .type           = V4L2_CTRL_TYPE_BOOLEAN,
+        .flags          = 0,
+        .disabled_while_streaming = true,
+    },
+    {
+        .id             = V4L2_CID_VFLIP,
+        .attr           = AV_ATTR_REVERSE_Y,
+        .reg_offset     = BCRM_IMG_REVERSE_Y_8RW,
+        .reg_size       = AV_CAM_REG_SIZE,
+        .data_size      = AV_CAM_DATA_SIZE_8,
+        .type           = V4L2_CTRL_TYPE_BOOLEAN,
+        .flags          = 0,
+        .disabled_while_streaming = true,
+    },
+    {
+        .id             = V4L2_CID_SHARPNESS,
+        .attr           = AV_ATTR_SHARPNESS,
+        .min_offset     = BCRM_SHARPNESS_MIN_32R,
+        .max_offset     = BCRM_SHARPNESS_MAX_32R,
+        .reg_offset     = BCRM_SHARPNESS_32RW,
+        .step_offset        = BCRM_SHARPNESS_INC_32R,
+        .reg_size       = AV_CAM_REG_SIZE,
+        .data_size      = AV_CAM_DATA_SIZE_32,
+        .type           = V4L2_CTRL_TYPE_INTEGER,
+        .flags          = 0,
+    },
+    {
+        .id             = V4L2_CID_EXPOSURE_AUTO,
+        .attr           = AV_ATTR_EXPOSURE_AUTO,
+        .reg_offset     = BCRM_EXPOSURE_AUTO_8RW,
+        .reg_size       = AV_CAM_REG_SIZE,
+        .data_size      = AV_CAM_DATA_SIZE_8,
+        .type           = V4L2_CTRL_TYPE_MENU,
+        .flags          = 0,
+    },
+    {
+        .id             = V4L2_CID_EXPOSURE_AUTO_MIN,
+        .attr           = AV_ATTR_EXPOSURE_AUTO_MIN,
+        .reg_offset     = BCRM_EXPOSURE_AUTO_MIN_64RW,
+        .reg_size       = AV_CAM_REG_SIZE,
+        .data_size      = AV_CAM_DATA_SIZE_64,
+        .type           = V4L2_CTRL_TYPE_INTEGER64,
+        .flags          = 0,
+    },
+    {
+        .id             = V4L2_CID_EXPOSURE_AUTO_MAX,
+        .attr           = AV_ATTR_EXPOSURE_AUTO_MAX,
+        .reg_offset     = BCRM_EXPOSURE_AUTO_MAX_64RW,
+        .reg_size       = AV_CAM_REG_SIZE,
+        .data_size      = AV_CAM_DATA_SIZE_64,
+        .type           = V4L2_CTRL_TYPE_INTEGER64,
+        .flags          = 0,
+    },
+    {
+        .id             = V4L2_CID_GAIN_AUTO_MIN,
+        .attr           = AV_ATTR_GAIN_AUTO_MIN,
+        .reg_offset     = BCRM_GAIN_AUTO_MIN_64RW,
+        .reg_size       = AV_CAM_REG_SIZE,
+        .data_size      = AV_CAM_DATA_SIZE_64,
+        .type           = V4L2_CTRL_TYPE_INTEGER64,
+        .flags          = 0,
+    },
+    {
+        .id             = V4L2_CID_GAIN_AUTO_MAX,
+        .attr           = AV_ATTR_GAIN_AUTO_MAX,
+        .reg_offset     = BCRM_GAIN_AUTO_MAX_64RW,
+        .reg_size       = AV_CAM_REG_SIZE,
+        .data_size      = AV_CAM_DATA_SIZE_64,
+        .type           = V4L2_CTRL_TYPE_INTEGER64,
+        .flags          = 0,
+    },
+    {
+        .id             = V4L2_CID_EXPOSURE_ACTIVE_LINE_MODE,
+        .attr           = AV_ATTR_EXPOSURE_ACTIVE_LINE_MODE,
+        .reg_offset     = BCRM_EXPOSURE_ACTIVE_LINE_MODE_8RW,
+        .reg_size       = AV_CAM_REG_SIZE,
+        .data_size      = AV_CAM_DATA_SIZE_8,
+        .type           = V4L2_CTRL_TYPE_BOOLEAN,
+        .flags          = 0,
+        .disabled_while_streaming = true,
+	},
+    {
+        .id             = V4L2_CID_EXPOSURE_ACTIVE_LINE_SELECTOR,
+        .attr           = AV_ATTR_EXPOSURE_ACTIVE_LINE_SELECTOR,
+        .reg_offset     = BCRM_EXPOSURE_ACTIVE_OUTPUT_LINE_8RW,
+        .reg_size       = AV_CAM_REG_SIZE,
+        .data_size      = AV_CAM_DATA_SIZE_8,
+        .type           = V4L2_CTRL_TYPE_INTEGER,
+        .flags          = 0,
+        .disabled_while_streaming = true,
+    },
+    {
+        .id             = V4L2_CID_EXPOSURE_ACTIVE_INVERT,
+        .attr           = AV_ATTR_EXPOSURE_ACTIVE_INVERT,
+        .reg_size       = AV_CAM_REG_SIZE,
+        .data_size      = AV_CAM_DATA_SIZE_8,
+        .type           = V4L2_CTRL_TYPE_BOOLEAN,
+        .flags          = 0,
+        .disabled_while_streaming = true,
+    },
+    {
+        .id             = V4L2_CID_TRIGGER_MODE,
+        .attr           = AV_ATTR_TRIGGER_MODE,
+        .reg_offset     = BCRM_FRAME_START_TRIGGER_MODE_8RW,
+        .reg_size       = AV_CAM_REG_SIZE,
+        .data_size      = AV_CAM_DATA_SIZE_8,
+        .type           = V4L2_CTRL_TYPE_BOOLEAN,
+        .flags          = 0,
+        .disabled_while_streaming = true,
+    },
+    {
+        .id             = V4L2_CID_TRIGGER_ACTIVATION,
+        .attr           = AV_ATTR_TRIGGER_ACTIVATION,
+        .reg_offset     = BCRM_FRAME_START_TRIGGER_ACTIVATION_8RW,
+        .reg_size       = AV_CAM_REG_SIZE,
+        .data_size      = AV_CAM_DATA_SIZE_8,
+        .type           = V4L2_CTRL_TYPE_MENU,
+        .flags          = 0,
+        .disabled_while_streaming = true,
+    },
+    {
+        .id             = V4L2_CID_TRIGGER_SOURCE,
+        .attr           = AV_ATTR_TRIGGER_SOURCE,
+        .reg_offset     = BCRM_FRAME_START_TRIGGER_SOURCE_8RW,
+        .reg_size       = AV_CAM_REG_SIZE,
+        .data_size      = AV_CAM_DATA_SIZE_8,
+        .type           = V4L2_CTRL_TYPE_MENU,
+        .flags          = 0,
+        .disabled_while_streaming = true,
+    },
+    {
+        .id             = V4L2_CID_TRIGGER_SOFTWARE,
+        .attr           = AV_ATTR_TRIGGER_SOFTWARE,
+        .reg_offset     = BCRM_FRAME_START_TRIGGER_SOURCE_8RW,
+        .reg_size       = AV_CAM_REG_SIZE,
+        .data_size      = AV_CAM_DATA_SIZE_8,
+        .type           = V4L2_CTRL_TYPE_BUTTON,
+        .flags          = V4L2_CTRL_FLAG_INACTIVE,
+    },
+    {
+        .id             = V4L2_CID_DEVICE_TEMPERATURE,
+        .attr           = AV_ATTR_DEVICE_TEMPERATURE,
+        .reg_offset     = BCRM_DEVICE_TEMPERATURE_32R,
+        .reg_size       = AV_CAM_REG_SIZE,
+        .data_size      = AV_CAM_DATA_SIZE_32,
+        .type           = V4L2_CTRL_TYPE_INTEGER,
+        .flags          = V4L2_CTRL_FLAG_VOLATILE | V4L2_CTRL_FLAG_READ_ONLY,
+    },
+};
+
+#define AVT_TEGRA_TIMEOUT_DEFAULT   CAPTURE_TIMEOUT_MS
+#define AVT_TEGRA_TIMEOUT_DISABLED  -1
+
+#define AVT_TEGRA_CID_BASE          (V4L2_CTRL_CLASS_USER | 0x900)
+
+#define AVT_TEGRA_TIMEOUT                   (AVT_TEGRA_CID_BASE + 200)
+#define AVT_TEGRA_TIMEOUT_VALUE             (AVT_TEGRA_CID_BASE + 201)
+#define AVT_TEGRA_STRIDE_ALIGN              (AVT_TEGRA_CID_BASE + 202)
+#define AVT_TEGRA_CROP_ALIGN                (AVT_TEGRA_CID_BASE + 203)
+#define AVT_TEGRA_VALUE_UPDATE_INTERVAL     (AVT_TEGRA_CID_BASE + 204)
+#define AVT_TEGRA_FORCE_VALUE_UPDATE        (AVT_TEGRA_CID_BASE + 205)
+
+#endif
diff --git a/drivers/media/platform/rcar-vin/rcar-v4l2.c b/drivers/media/platform/rcar-vin/rcar-v4l2.c
index 2bbe6d495fa6..4068d4e3367e 100644
--- a/drivers/media/platform/rcar-vin/rcar-v4l2.c
+++ b/drivers/media/platform/rcar-vin/rcar-v4l2.c
@@ -462,7 +462,7 @@ static int rvin_cropcap(struct file *file, void *priv,
 	if (crop->type != V4L2_BUF_TYPE_VIDEO_CAPTURE)
 		return -EINVAL;
 
-	return v4l2_subdev_call(sd, video, g_pixelaspect, &crop->pixelaspect);
+	return v4l2_subdev_call(sd, video, cropcap, crop);
 }
 
 static int rvin_enum_input(struct file *file, void *priv,
diff --git a/drivers/media/v4l2-core/v4l2-dev.c b/drivers/media/v4l2-core/v4l2-dev.c
index 8be561ab2615..a9bf3cbd26fd 100644
--- a/drivers/media/v4l2-core/v4l2-dev.c
+++ b/drivers/media/v4l2-core/v4l2-dev.c
@@ -30,6 +30,7 @@
 #include <media/v4l2-common.h>
 #include <media/v4l2-device.h>
 #include <media/v4l2-ioctl.h>
+#include <media/videobuf2-core.h>
 
 #define VIDEO_NUM_DEVICES	256
 #define VIDEO_NAME              "video4linux"
@@ -80,10 +81,62 @@ static ssize_t name_show(struct device *cd,
 }
 static DEVICE_ATTR_RO(name);
 
+static ssize_t if_name_show(struct device *cd,
+		struct device_attribute *attr, char *buf)
+{
+	struct video_device *vdev = to_video_device(cd);
+
+	return sprintf(buf, "%s\n", vdev->if_name);
+}
+static DEVICE_ATTR_RO(if_name);
+
+static ssize_t bus_info_show(struct device *cd,
+		struct device_attribute *attr, char *buf)
+{
+	struct video_device *vdev = to_video_device(cd);
+
+	return sprintf(buf, "%s\n", vdev->bus_info);
+}
+static DEVICE_ATTR_RO(bus_info);
+
+static ssize_t flush_show(struct device *cd,
+		struct device_attribute *attr, char *buf)
+{
+	struct video_device *vdev = to_video_device(cd);
+
+	return sprintf(buf, "%s\n", &vdev->flush);
+}
+static DEVICE_ATTR_RO(flush);
+
+static ssize_t availability_show(struct device *cd,
+				 struct device_attribute *attr,
+				 char *buf)
+{
+	struct video_device *vdev = to_video_device(cd);
+
+	return sprintf(buf, "%d\n", vdev->open_count > 0 ? 0 : 1);
+}
+static DEVICE_ATTR_RO(availability);
+
+static ssize_t streamoff_show(struct device *cd,
+			struct device_attribute *attr, char *buf)
+{
+	struct video_device *vdev = to_video_device(cd);
+	struct vb2_queue *q = vdev->queue;
+
+	return sprintf(buf, "%d\n", q->streamoff_state);
+}
+static DEVICE_ATTR_RO(streamoff);
+
 static struct attribute *video_device_attrs[] = {
 	&dev_attr_name.attr,
 	&dev_attr_dev_debug.attr,
 	&dev_attr_index.attr,
+	&dev_attr_if_name.attr,
+	&dev_attr_bus_info.attr,
+	&dev_attr_flush.attr,
+	&dev_attr_availability.attr,
+	&dev_attr_streamoff.attr,
 	NULL,
 };
 ATTRIBUTE_GROUPS(video_device);
@@ -419,6 +472,9 @@ static int v4l2_open(struct inode *inode, struct file *filp)
 	}
 	/* and increase the device refcount */
 	video_get(vdev);
+	if (vdev->open_count++ == 0) {
+		sysfs_notify(&vdev->dev.kobj, NULL, "availability");
+	}
 	mutex_unlock(&videodev_lock);
 	if (vdev->fops->open) {
 		if (video_is_registered(vdev))
@@ -430,9 +486,15 @@ static int v4l2_open(struct inode *inode, struct file *filp)
 	if (vdev->dev_debug & V4L2_DEV_DEBUG_FOP)
 		printk(KERN_DEBUG "%s: open (%d)\n",
 			video_device_node_name(vdev), ret);
-	/* decrease the refcount in case of an error */
-	if (ret)
+	if (ret) {
+		/* decrease the refcount in case of an error */
+		mutex_lock(&videodev_lock);
+		if (--vdev->open_count == 0) {
+			sysfs_notify(&vdev->dev.kobj, NULL, "availability");
+		}
+		mutex_unlock(&videodev_lock);
 		video_put(vdev);
+  }
 	return ret;
 }
 
@@ -448,6 +510,12 @@ static int v4l2_release(struct inode *inode, struct file *filp)
 		printk(KERN_DEBUG "%s: release\n",
 			video_device_node_name(vdev));
 
+	mutex_lock(&videodev_lock);
+	if (--vdev->open_count == 0) {
+		sysfs_notify(&vdev->dev.kobj, NULL, "availability");
+	}
+	mutex_unlock(&videodev_lock);
+
 	/* decrease the refcount unconditionally since the release()
 	   return value is ignored. */
 	video_put(vdev);
diff --git a/drivers/media/v4l2-core/v4l2-ioctl.c b/drivers/media/v4l2-core/v4l2-ioctl.c
index 1bc3128e2384..f0fe2cbb43d1 100644
--- a/drivers/media/v4l2-core/v4l2-ioctl.c
+++ b/drivers/media/v4l2-core/v4l2-ioctl.c
@@ -1256,6 +1256,27 @@ static void v4l_fill_fmtdesc(struct v4l2_fmtdesc *fmt)
 	case V4L2_PIX_FMT_TM6000:	descr = "A/V + VBI Mux Packet"; break;
 	case V4L2_PIX_FMT_CIT_YYVYUY:	descr = "GSPCA CIT YYVYUY"; break;
 	case V4L2_PIX_FMT_KONICA420:	descr = "GSPCA KONICA420"; break;
+	case V4L2_PIX_FMT_CUSTOM:	descr = "0x31 MIPI DATATYPE"; break;
+	case V4L2_PIX_FMT_TX2_Y10:	descr = "10-bit/16-bit Greyscale"; break;
+	case V4L2_PIX_FMT_TX2_Y12:	descr = "12-bit/16-bit Greyscale"; break;
+	case V4L2_PIX_FMT_TX2_SBGGR10:	descr = "10-bit/16-bit Bayer BGBG/GRGR"; break;
+	case V4L2_PIX_FMT_TX2_SGBRG10:	descr = "10-bit/16-bit Bayer GBGB/RGRG"; break;
+	case V4L2_PIX_FMT_TX2_SGRBG10:	descr = "10-bit/16-bit Bayer GRGR/BGBG"; break;
+	case V4L2_PIX_FMT_TX2_SRGGB10:	descr = "10-bit/16-bit Bayer RGRG/GBGB"; break;
+	case V4L2_PIX_FMT_TX2_SBGGR12:	descr = "12-bit/16-bit Bayer BGBG/GRGR"; break;
+	case V4L2_PIX_FMT_TX2_SGBRG12:	descr = "12-bit/16-bit Bayer GBGB/RGRG"; break;
+	case V4L2_PIX_FMT_TX2_SGRBG12:	descr = "12-bit/16-bit Bayer GRGR/BGBG"; break;
+	case V4L2_PIX_FMT_TX2_SRGGB12:	descr = "12-bit/16-bit Bayer RGRG/GBGB"; break;
+	case V4L2_PIX_FMT_XAVIER_Y10:	descr = "10-bit/16-bit Greyscale"; break;
+	case V4L2_PIX_FMT_XAVIER_Y12:	descr = "12-bit/16-bit Greyscale"; break;
+	case V4L2_PIX_FMT_XAVIER_SBGGR10:	descr = "10-bit/16-bit Bayer BGBG/GRGR"; break;
+	case V4L2_PIX_FMT_XAVIER_SGBRG10:	descr = "10-bit/16-bit Bayer GBGB/RGRG"; break;
+	case V4L2_PIX_FMT_XAVIER_SGRBG10:	descr = "10-bit/16-bit Bayer GRGR/BGBG"; break;
+	case V4L2_PIX_FMT_XAVIER_SRGGB10:	descr = "10-bit/16-bit Bayer RGRG/GBGB"; break;
+	case V4L2_PIX_FMT_XAVIER_SBGGR12:	descr = "12-bit/16-bit Bayer BGBG/GRGR"; break;
+	case V4L2_PIX_FMT_XAVIER_SGBRG12:	descr = "12-bit/16-bit Bayer GBGB/RGRG"; break;
+	case V4L2_PIX_FMT_XAVIER_SGRBG12:	descr = "12-bit/16-bit Bayer GRGR/BGBG"; break;
+	case V4L2_PIX_FMT_XAVIER_SRGGB12:	descr = "12-bit/16-bit Bayer RGRG/GBGB"; break;
 	case V4L2_SDR_FMT_CU8:		descr = "Complex U8"; break;
 	case V4L2_SDR_FMT_CU16LE:	descr = "Complex U16LE"; break;
 	case V4L2_SDR_FMT_CS8:		descr = "Complex S8"; break;
diff --git a/drivers/media/v4l2-core/videobuf2-core.c b/drivers/media/v4l2-core/videobuf2-core.c
index 17e2849fea72..64bcb7c831a1 100644
--- a/drivers/media/v4l2-core/videobuf2-core.c
+++ b/drivers/media/v4l2-core/videobuf2-core.c
@@ -329,7 +329,7 @@ static void __setup_offsets(struct vb2_buffer *vb)
  */
 static int __vb2_queue_alloc(struct vb2_queue *q, enum vb2_memory memory,
 			     unsigned int num_buffers, unsigned int num_planes,
-			     const unsigned plane_sizes[VB2_MAX_PLANES])
+			     const unsigned plane_sizes[VB2_MAX_PLANES], bool req_index, int index)
 {
 	unsigned int buffer, plane;
 	struct vb2_buffer *vb;
@@ -350,7 +350,7 @@ static int __vb2_queue_alloc(struct vb2_queue *q, enum vb2_memory memory,
 		vb->state = VB2_BUF_STATE_DEQUEUED;
 		vb->vb2_queue = q;
 		vb->num_planes = num_planes;
-		vb->index = q->num_buffers + buffer;
+		vb->index = req_index ? index + buffer : q->num_buffers + buffer;
 		vb->type = q->type;
 		vb->memory = memory;
 		for (plane = 0; plane < num_planes; ++plane) {
@@ -417,6 +417,22 @@ static void __vb2_free_mem(struct vb2_queue *q, unsigned int buffers)
 	}
 }
 
+static void __vb2_free_mem_single(struct vb2_queue *q, unsigned int index)
+{
+	struct vb2_buffer *vb;
+
+	vb = q->bufs[index];
+	if (!vb)
+		return;
+
+	if (q->memory == VB2_MEMORY_MMAP)
+		__vb2_buf_mem_free(vb);
+	else if (q->memory == VB2_MEMORY_DMABUF)
+		__vb2_buf_dmabuf_put(vb);
+	else
+		__vb2_buf_userptr_put(vb);
+}
+
 /**
  * __vb2_queue_free() - free buffers at the end of the queue - video memory and
  * related information, if no buffers are left return the queue to an
@@ -533,6 +549,44 @@ static int __vb2_queue_free(struct vb2_queue *q, unsigned int buffers)
 	return 0;
 }
 
+int vb2_buffer_free(struct vb2_queue *q, unsigned int index)
+{
+	struct vb2_buffer *vb = q->bufs[index];
+
+	/*
+	 * Sanity check: when preparing a buffer the queue lock is released for
+	 * a short while (see __buf_prepare for the details), which would allow
+	 * a race with a reqbufs which can call this function. Removing the
+	 * buffers from underneath __buf_prepare is obviously a bad idea, so we
+	 * check if any of the buffers is in the state PREPARING, and if so we
+	 * just return -EAGAIN.
+	 */
+	if (q->bufs[index] == NULL)
+			return -EINVAL;
+
+	if (q->bufs[index]->state == VB2_BUF_STATE_PREPARING) {
+		dprintk(1, "preparing buffers, cannot free\n");
+		return -EAGAIN;
+	}
+
+	if (vb && vb->planes[0].mem_priv)
+		call_void_vb_qop(vb, buf_cleanup, vb);
+
+	/* Release video buffer memory */
+	__vb2_free_mem_single(q, index);
+
+	kfree(q->bufs[index]);
+	q->bufs[index] = NULL;
+
+	q->num_buffers--;
+	if (!q->num_buffers) {
+		q->memory = 0;
+		INIT_LIST_HEAD(&q->queued_list);
+	}
+	return 0;
+}
+EXPORT_SYMBOL_GPL(vb2_buffer_free);
+
 bool vb2_buffer_in_use(struct vb2_queue *q, struct vb2_buffer *vb)
 {
 	unsigned int plane;
@@ -719,7 +773,7 @@ int vb2_core_reqbufs(struct vb2_queue *q, enum vb2_memory memory,
 
 	/* Finally, allocate buffers and video memory */
 	allocated_buffers =
-		__vb2_queue_alloc(q, memory, num_buffers, num_planes, plane_sizes);
+		__vb2_queue_alloc(q, memory, num_buffers, num_planes, plane_sizes, false, 0);
 	if (allocated_buffers == 0) {
 		dprintk(1, "memory allocation failed\n");
 		return -ENOMEM;
@@ -782,14 +836,80 @@ int vb2_core_reqbufs(struct vb2_queue *q, enum vb2_memory memory,
 }
 EXPORT_SYMBOL_GPL(vb2_core_reqbufs);
 
+int vb2_core_create_single_buf(struct vb2_queue *q, enum vb2_memory memory,
+		unsigned int *count, unsigned requested_planes,
+		const unsigned requested_sizes[], bool req_index, int index)
+{
+	unsigned int num_planes = 0, num_buffers, allocated_buffers;
+	unsigned plane_sizes[VB2_MAX_PLANES] = { };
+	int ret;
+
+	if (req_index && q->num_buffers > index)
+		return 0;
+
+	if (q->num_buffers == VB2_MAX_FRAME) {
+		dprintk(1, "maximum number of buffers already allocated\n");
+		return -ENOBUFS;
+	}
+
+	if (!q->num_buffers) {
+		memset(q->alloc_devs, 0, sizeof(q->alloc_devs));
+		q->memory = memory;
+		q->waiting_for_buffers = !q->is_output;
+	}
+
+	num_buffers = min(*count, VB2_MAX_FRAME - q->num_buffers);
+
+	if (requested_planes && requested_sizes) {
+		num_planes = requested_planes;
+		memcpy(plane_sizes, requested_sizes, sizeof(plane_sizes));
+	}
+
+	/*
+	 * Ask the driver, whether the requested number of buffers, planes per
+	 * buffer and their sizes are acceptable
+	 */
+	ret = call_qop(q, queue_setup, q, &num_buffers,
+		       &num_planes, plane_sizes, q->alloc_devs);
+	if (ret)
+		return ret;
+
+	/* Finally, allocate buffers and video memory */
+	allocated_buffers = __vb2_queue_alloc(q, memory, *count,
+				num_planes, plane_sizes, req_index, index);
+	if (allocated_buffers == 0) {
+		dprintk(1, "memory allocation failed\n");
+		return -ENOMEM;
+	}
+	mutex_lock(&q->mmap_lock);
+	q->num_buffers += allocated_buffers;
+
+	if (ret < 0) {
+		/*
+		 * Note: __vb2_queue_free() will subtract 'allocated_buffers'
+		 * from q->num_buffers.
+		 */
+		__vb2_queue_free(q, allocated_buffers);
+		mutex_unlock(&q->mmap_lock);
+		return -ENOMEM;
+	}
+	mutex_unlock(&q->mmap_lock);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(vb2_core_create_single_buf);
+
 int vb2_core_create_bufs(struct vb2_queue *q, enum vb2_memory memory,
 		unsigned int *count, unsigned requested_planes,
-		const unsigned requested_sizes[])
+		const unsigned requested_sizes[], bool req_index, int index)
 {
 	unsigned int num_planes = 0, num_buffers, allocated_buffers;
 	unsigned plane_sizes[VB2_MAX_PLANES] = { };
 	int ret;
 
+	if (req_index && q->num_buffers > index)
+		return 0;
+
 	if (q->num_buffers == VB2_MAX_FRAME) {
 		dprintk(1, "maximum number of buffers already allocated\n");
 		return -ENOBUFS;
@@ -819,7 +939,7 @@ int vb2_core_create_bufs(struct vb2_queue *q, enum vb2_memory memory,
 
 	/* Finally, allocate buffers and video memory */
 	allocated_buffers = __vb2_queue_alloc(q, memory, num_buffers,
-				num_planes, plane_sizes);
+				num_planes, plane_sizes, req_index, index);
 	if (allocated_buffers == 0) {
 		dprintk(1, "memory allocation failed\n");
 		return -ENOMEM;
@@ -1470,10 +1590,11 @@ static int __vb2_wait_for_done_vb(struct vb2_queue *q, int nonblocking)
 	for (;;) {
 		int ret;
 
-		if (!q->streaming) {
-			dprintk(1, "streaming off, will not wait for buffers\n");
-			return -EINVAL;
-		}
+		//if (!q->streaming) {
+		//	dprintk(1, "streaming off, will not wait for buffers\n");
+		//	pr_err("streaming off, will not wait for buffers\n");
+		//	return -EINVAL;
+		//}
 
 		if (q->error) {
 			dprintk(1, "Queue in error state, will not wait for buffers\n");
@@ -1614,9 +1735,11 @@ int vb2_core_dqbuf(struct vb2_queue *q, unsigned int *pindex, void *pb,
 	switch (vb->state) {
 	case VB2_BUF_STATE_DONE:
 		dprintk(3, "returning done buffer\n");
+		q->buffer_error = 0;
 		break;
 	case VB2_BUF_STATE_ERROR:
 		dprintk(3, "returning done buffer with errors\n");
+		q->buffer_error = 1;
 		break;
 	default:
 		dprintk(1, "invalid buffer state\n");
@@ -1649,6 +1772,13 @@ int vb2_core_dqbuf(struct vb2_queue *q, unsigned int *pindex, void *pb,
 }
 EXPORT_SYMBOL_GPL(vb2_core_dqbuf);
 
+
+void vb2_core_queue_cancel(struct vb2_queue *q)
+{
+    __vb2_queue_cancel(q);
+}
+EXPORT_SYMBOL_GPL(vb2_core_queue_cancel);
+
 /**
  * __vb2_queue_cancel() - cancel and stop (pause) streaming
  *
@@ -1658,6 +1788,7 @@ EXPORT_SYMBOL_GPL(vb2_core_dqbuf);
 static void __vb2_queue_cancel(struct vb2_queue *q)
 {
 	unsigned int i;
+	int num_buffers = q->num_buffers;
 
 	/*
 	 * Tell driver to stop all transactions and release all queued
@@ -1706,20 +1837,104 @@ static void __vb2_queue_cancel(struct vb2_queue *q)
 	 * call to __fill_user_buffer() after buf_finish(). That order can't
 	 * be changed, so we can't move the buf_finish() to __vb2_dqbuf().
 	 */
-	for (i = 0; i < q->num_buffers; ++i) {
+	for (i = 0; i < num_buffers; ++i) {
 		struct vb2_buffer *vb = q->bufs[i];
 
-		if (vb->state != VB2_BUF_STATE_DEQUEUED) {
-			vb->state = VB2_BUF_STATE_PREPARED;
-			call_void_vb_qop(vb, buf_finish, vb);
+		if (q->bufs[i] != NULL) {
+			if (vb->state != VB2_BUF_STATE_DEQUEUED) {
+				vb->state = VB2_BUF_STATE_PREPARED;
+				call_void_vb_qop(vb, buf_finish, vb);
+			}
+			__vb2_dqbuf(vb);
 		}
-		__vb2_dqbuf(vb);
+		else
+			num_buffers++;
 	}
 }
 
+int vb2_core_streamon_ex(struct vb2_queue *q, unsigned int type)
+{
+	int ret;
+	int drv_count = 0;
+
+	drv_count = atomic_read(&q->owned_by_drv_count);
+
+	if (type != q->type) {
+		dprintk(1, "invalid stream type\n");
+		return -EINVAL;
+	}
+
+	if (q->streaming) {
+		dprintk(3, "already streaming\n");
+		return 0;
+	}
+
+	if (!q->num_buffers) {
+		dprintk(1, "no buffers have been allocated\n");
+		return -EINVAL;
+	}
+
+	if (q->num_buffers < q->min_buffers_needed) {
+		dprintk(1, "need at least %u allocated buffers\n",
+				q->min_buffers_needed);
+		return -EINVAL;
+	}
+
+	/*
+	 * Tell driver to start streaming provided sufficient buffers
+	 * are available.
+	 */
+	if (q->queued_count >= q->min_buffers_needed) {
+		ret = v4l_vb2q_enable_media_source(q);
+		if (ret)
+			return ret;
+		ret = vb2_start_streaming(q);
+	}
+
+	q->streaming = 1;
+	q->streamoff_state = 0;
+
+	return 0;
+}
+
+int vb2_core_streamoff_ex(struct vb2_queue *q, unsigned int type, __u32 timeout)
+{
+	int drv_count = 0;
+	if (type != q->type) {
+		dprintk(1, "invalid stream type\n");
+		return -EINVAL;
+	}
+
+	q->streamoff_state = 1;
+
+	/*
+	 * Following lines are modified content of __vb2_queue_cancel(q).
+	 */
+	/*
+	 * Tell driver to stop all transactions and release all queued
+	 * buffers.
+	 */
+	if (q->start_streaming_called)
+		call_void_qop(q, stop_streaming, q); // "stop streaming" should be modified too, driver should not clean its queue in this case
+
+	q->streaming = 0;
+	q->start_streaming_called = 0;
+	q->error = 0;
+
+	q->waiting_for_buffers = !q->is_output;
+	q->last_buffer_dequeued = false;
+	q->streamoff_state = 2;
+
+	drv_count = atomic_read(&q->owned_by_drv_count);
+	return 0;
+}
+
 int vb2_core_streamon(struct vb2_queue *q, unsigned int type)
 {
 	int ret;
+	int drv_count = 0;
+
+	drv_count = atomic_read(&q->owned_by_drv_count);
 
 	if (type != q->type) {
 		dprintk(1, "invalid stream type\n");
@@ -1758,6 +1973,7 @@ int vb2_core_streamon(struct vb2_queue *q, unsigned int type)
 	}
 
 	q->streaming = 1;
+	q->streamoff_state = 0;
 
 	dprintk(3, "successful\n");
 	return 0;
@@ -1779,6 +1995,8 @@ int vb2_core_streamoff(struct vb2_queue *q, unsigned int type)
 		return -EINVAL;
 	}
 
+	q->streamoff_state = 1;
+
 	/*
 	 * Cancel will pause streaming and remove all buffers from the driver
 	 * and videobuf, effectively returning control over them to userspace.
@@ -1791,6 +2009,7 @@ int vb2_core_streamoff(struct vb2_queue *q, unsigned int type)
 	__vb2_queue_cancel(q);
 	q->waiting_for_buffers = !q->is_output;
 	q->last_buffer_dequeued = false;
+	q->streamoff_state = 2;
 
 	dprintk(3, "successful\n");
 	return 0;
diff --git a/drivers/media/v4l2-core/videobuf2-v4l2.c b/drivers/media/v4l2-core/videobuf2-v4l2.c
index 753eea5cc86a..754282bd8da4 100644
--- a/drivers/media/v4l2-core/videobuf2-v4l2.c
+++ b/drivers/media/v4l2-core/videobuf2-v4l2.c
@@ -558,7 +558,7 @@ int vb2_create_bufs(struct vb2_queue *q, struct v4l2_create_buffers *create)
 		if (requested_sizes[i] == 0)
 			return -EINVAL;
 	return ret ? ret : vb2_core_create_bufs(q, create->memory,
-		&create->count, requested_planes, requested_sizes);
+		&create->count, requested_planes, requested_sizes, false, 0);
 }
 EXPORT_SYMBOL_GPL(vb2_create_bufs);
 
@@ -665,6 +665,8 @@ int vb2_queue_init(struct vb2_queue *q)
 	 */
 	q->quirk_poll_must_check_waiting_for_buffers = true;
 
+	q->streamoff_state = 0;
+
 	return vb2_core_queue_init(q);
 }
 EXPORT_SYMBOL_GPL(vb2_queue_init);
diff --git a/include/media/avt_csi2_soc.h b/include/media/avt_csi2_soc.h
new file mode 100644
index 000000000000..e89c586e8a55
--- /dev/null
+++ b/include/media/avt_csi2_soc.h
@@ -0,0 +1,45 @@
+/*=============================================================================
+  Copyright (C) 2021 Allied Vision Technologies.  All Rights Reserved.
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+  -----------------------------------------------------------------------------
+File:        avt_csi2_soc.h
+version:     1.0.0
+=============================================================================*/
+
+////////////////////////////////////////////////////////////////////////////////
+// DEFINES
+////////////////////////////////////////////////////////////////////////////////
+
+#ifndef AVT_CSI2_SOC_H
+#define AVT_CSI2_SOC_H
+
+/* D-PHY 1.2 clock frequency range (up to 2.5 Gbps per lane, DDR) */
+#define CSI_HOST_CLK_MIN_FREQ	40000000
+#define CSI_HOST_CLK_MAX_FREQ	1250000000
+
+/* VI restrictions */
+#define FRAMESIZE_MIN_W     256
+#define FRAMESIZE_MAX_W     32768
+#define FRAMESIZE_INC_W     192
+#define FRAMESIZE_MIN_H     32
+#define FRAMESIZE_MAX_H     32768
+#define FRAMESIZE_INC_H     1
+
+#define OFFSET_INC_W        8       /* Tegra doesn't seem to accept offsets that are not divisible by 8. */
+#define OFFSET_INC_H        8
+
+/* Support only 0x31 datatype */
+#define DATA_IDENTIFIER_INQ_1   0x0002000000000000ull
+#define DATA_IDENTIFIER_INQ_2   0x0
+#define DATA_IDENTIFIER_INQ_3   0x0
+#define DATA_IDENTIFIER_INQ_4   0x0
+#define MIN_ANNOUNCED_FRAMES    1
+
+#endif /* AVT_CSI2_SOC_H */
\ No newline at end of file
diff --git a/include/media/v4l2-dev.h b/include/media/v4l2-dev.h
index e657614521e3..3d3584ff5fda 100644
--- a/include/media/v4l2-dev.h
+++ b/include/media/v4l2-dev.h
@@ -242,6 +242,10 @@ struct video_device
 	u16 num;
 	unsigned long flags;
 	int index;
+	char if_name[32];
+	char bus_info[32];
+	char flush;
+	int open_count;
 
 	/* V4L2 file handles */
 	spinlock_t		fh_lock;
diff --git a/include/media/v4l2-subdev.h b/include/media/v4l2-subdev.h
index d9f6f03d1f4f..81429ff26841 100644
--- a/include/media/v4l2-subdev.h
+++ b/include/media/v4l2-subdev.h
@@ -368,7 +368,11 @@ struct v4l2_mbus_frame_desc {
  * @s_stream: used to notify the driver that a video stream will start or has
  *	stopped.
  *
- * @g_pixelaspect: callback to return the pixelaspect ratio.
+ * @cropcap: callback for %VIDIOC_CROPCAP ioctl handler code.
+ *
+ * @g_crop: callback for %VIDIOC_G_CROP ioctl handler code.
+ *
+ * @s_crop: callback for %VIDIOC_S_CROP ioctl handler code.
  *
  * @g_parm: callback for %VIDIOC_G_PARM ioctl handler code.
  *
@@ -408,7 +412,9 @@ struct v4l2_subdev_video_ops {
 	int (*g_tvnorms_output)(struct v4l2_subdev *sd, v4l2_std_id *std);
 	int (*g_input_status)(struct v4l2_subdev *sd, u32 *status);
 	int (*s_stream)(struct v4l2_subdev *sd, int enable);
-	int (*g_pixelaspect)(struct v4l2_subdev *sd, struct v4l2_fract *aspect);
+	int (*cropcap)(struct v4l2_subdev *sd, struct v4l2_cropcap *cc);
+	int (*g_crop)(struct v4l2_subdev *sd, struct v4l2_crop *crop);
+	int (*s_crop)(struct v4l2_subdev *sd, const struct v4l2_crop *crop);
 	int (*g_parm)(struct v4l2_subdev *sd, struct v4l2_streamparm *param);
 	int (*s_parm)(struct v4l2_subdev *sd, struct v4l2_streamparm *param);
 	int (*g_frame_interval)(struct v4l2_subdev *sd,
diff --git a/include/media/videobuf2-core.h b/include/media/videobuf2-core.h
index ac5898a55fd9..94114e292995 100644
--- a/include/media/videobuf2-core.h
+++ b/include/media/videobuf2-core.h
@@ -529,9 +529,12 @@ struct vb2_queue {
 
 	struct device			*alloc_devs[VB2_MAX_PLANES];
 
+	unsigned int			streamoff_state;
+
 	unsigned int			streaming:1;
 	unsigned int			start_streaming_called:1;
 	unsigned int			error:1;
+	unsigned int			buffer_error:1;
 	unsigned int			waiting_for_buffers:1;
 	unsigned int			is_multiplanar:1;
 	unsigned int			is_output:1;
@@ -673,6 +676,8 @@ int vb2_core_reqbufs(struct vb2_queue *q, enum vb2_memory memory,
  * @count: requested buffer count
  * @requested_planes: number of planes requested
  * @requested_sizes: array with the size of the planes
+ * @req_index - true if specific index needs to be requested
+ * @index - number of requested index, only valid if req_index is true
  *
  * Should be called from VIDIOC_CREATE_BUFS() ioctl handler of a driver.
  * This function:
@@ -685,8 +690,12 @@ int vb2_core_reqbufs(struct vb2_queue *q, enum vb2_memory memory,
  * returned from VIDIOC_CREATE_BUFS() handler in driver.
  */
 int vb2_core_create_bufs(struct vb2_queue *q, enum vb2_memory memory,
-			 unsigned int *count, unsigned int requested_planes,
-			 const unsigned int requested_sizes[]);
+		unsigned int *count, unsigned requested_planes,
+		const unsigned requested_sizes[], bool req_index, int index);
+
+int vb2_core_create_single_buf(struct vb2_queue *q, enum vb2_memory memory,
+		unsigned int *count, unsigned requested_planes,
+		const unsigned requested_sizes[], bool req_index, int index);
 
 /**
  * vb2_core_prepare_buf() - Pass ownership of a buffer from userspace
@@ -758,6 +767,8 @@ int vb2_core_dqbuf(struct vb2_queue *q, unsigned int *pindex, void *pb,
 
 int vb2_core_streamon(struct vb2_queue *q, unsigned int type);
 int vb2_core_streamoff(struct vb2_queue *q, unsigned int type);
+int vb2_core_streamon_ex(struct vb2_queue *q, unsigned int type);
+int vb2_core_streamoff_ex(struct vb2_queue *q, unsigned int type, __u32 timeout);
 
 /**
  * vb2_core_expbuf() - Export a buffer as a file descriptor
@@ -798,6 +809,8 @@ int vb2_core_queue_init(struct vb2_queue *q);
  */
 void vb2_core_queue_release(struct vb2_queue *q);
 
+void vb2_core_queue_cancel(struct vb2_queue *q);
+
 /**
  * vb2_queue_error() - signal a fatal error on the queue
  * @q:		videobuf2 queue
diff --git a/include/media/videobuf2-v4l2.h b/include/media/videobuf2-v4l2.h
index 036127c54bbf..855e2e7346be 100644
--- a/include/media/videobuf2-v4l2.h
+++ b/include/media/videobuf2-v4l2.h
@@ -72,6 +72,14 @@ int vb2_reqbufs(struct vb2_queue *q, struct v4l2_requestbuffers *req);
  */
 int vb2_create_bufs(struct vb2_queue *q, struct v4l2_create_buffers *create);
 
+/**
+ * vb2_buffer_free() - Free single vb2 buffer
+ *
+ * @q:		videobuf2 queue
+ * @index:	index of the buffer to be freed
+ */
+int vb2_buffer_free(struct vb2_queue *q, unsigned int index);
+
 /**
  * vb2_prepare_buf() - Pass ownership of a buffer from userspace to the kernel
  *
diff --git a/include/uapi/linux/libcsi_ioctl.h b/include/uapi/linux/libcsi_ioctl.h
new file mode 100644
index 000000000000..ceb17021d9f9
--- /dev/null
+++ b/include/uapi/linux/libcsi_ioctl.h
@@ -0,0 +1,349 @@
+/*=============================================================================
+  Copyright (C) 2020 Allied Vision Technologies.  All Rights Reserved.
+
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+
+  -----------------------------------------------------------------------------
+
+File:        libcsi_ioctl.h
+
+version:     1.7.10
+=============================================================================*/
+
+
+
+////////////////////////////////////////////////////////////////////////////////
+// DEFINES
+////////////////////////////////////////////////////////////////////////////////
+#ifndef LIBCSI_IOCTL_H
+#define LIBCSI_IOCTL_H
+
+#include <linux/videodev2.h>
+
+/* Version of the libcsi - driver interface spec */
+#define LIBCSI_DRV_SPEC_VERSION_MAJOR       1
+#define LIBCSI_DRV_SPEC_VERSION_MINOR       0
+#define LIBCSI_DRV_SPEC_VERSION_PATCH       8
+
+/* Buffer status reported by driver for returned frames */
+#define V4L2_BUF_FLAG_INCOMPLETE            0x10000000
+#define V4L2_BUF_FLAG_UNUSED                0x20000000
+#define V4L2_BUF_FLAG_VALID                 0x40000000
+#define V4L2_BUF_FLAG_INVALID               0x80000000
+#define V4L2_BUF_FLAG_INVALIDINCOMPLETE     (V4L2_BUF_FLAG_INCOMPLETE | V4L2_BUF_FLAG_INVALID)
+/* Driver capabilities flags. See v4l2_csi_driver_info */
+#define AVT_DRVCAP_USRPTR                   0x00000001  
+#define AVT_DRVCAP_MMAP                     0x00000002
+
+////////////////////////////////////////////////////////////////////////////////
+// ENUMS
+////////////////////////////////////////////////////////////////////////////////
+enum v4l2_lane_counts
+{
+    V4L2_LANE_COUNT_1_LaneSupport       = 0x1,
+    V4L2_LANE_COUNT_2_LaneSupport       = 0x2,
+    V4L2_LANE_COUNT_3_LaneSupport       = 0x4,
+    V4L2_LANE_COUNT_4_LaneSupport       = 0x8,
+};
+
+enum v4l2_statistics_capability
+{
+    V4L2_STATISTICS_CAPABILITY_FrameCount           = 0x1,
+    V4L2_STATISTICS_CAPABILITY_PacketCRCError       = 0x2,
+    V4L2_STATISTICS_CAPABILITY_FramesUnderrun       = 0x4,
+    V4L2_STATISTICS_CAPABILITY_FramesIncomplete     = 0x8,
+    V4L2_STATISTICS_CAPABILITY_CurrentFrameCount    = 0x10,
+    V4L2_STATISTICS_CAPABILITY_CurrentFrameInterval = 0x20,
+};
+
+enum gencp_handshake_state
+{
+    GENCP_HANDSHAKE_BUFFER_CLEARED      = 0x0,
+    GENCP_HANDSHAKE_BUFFER_VALID        = 0x1,
+    GENCP_HANDSHAKE_BUFFER_PROCESSED    = 0x2,
+};
+
+enum manufacturer_id
+{
+    MANUFACTURER_ID_NXP                 = 0x00,
+    MANUFACTURER_ID_NVIDIA              = 0x01,
+};                                      
+                                        
+enum soc_family_id                      
+{                                       
+    SOC_FAMILY_ID_IMX6                  = 0x00,
+    SOC_FAMILY_ID_TEGRA                 = 0x01,
+    SOC_FAMILY_ID_IMX8                  = 0x02,
+    SOC_FAMILY_ID_IMX8M                 = 0x03,
+    SOC_FAMILY_ID_IMX8X                 = 0x04,
+};                                      
+                                        
+enum imx6_driver_id                     
+{                                       
+    IMX6_DRIVER_ID_NITROGEN             = 0x00,
+    IMX6_DRIVER_ID_WANDBOARD            = 0x01,
+};                                      
+                                        
+enum tegra_driver_id                    
+{                                       
+    TEGRA_DRIVER_ID_DEFAULT             = 0x00,
+};                                      
+                                        
+enum imx8_driver_id                     
+{                                       
+    IMX8_DRIVER_ID_DEFAULT              = 0x00,
+};                                      
+                                        
+enum imx8m_driver_id                    
+{                                       
+    IMX8M_DRIVER_ID_DEFAULT             = 0x00,
+};                                      
+                                        
+enum imx8x_driver_id                    
+{                                       
+    IMX8X_DRIVER_ID_DEFAULT             = 0x00,
+};
+
+enum v4l2_triggeractivation
+{
+    V4L2_TRIGGER_ACTIVATION_RISING_EDGE  = 0,
+    V4L2_TRIGGER_ACTIVATION_FALLING_EDGE = 1,
+    V4L2_TRIGGER_ACTIVATION_ANY_EDGE     = 2,
+    V4L2_TRIGGER_ACTIVATION_LEVEL_HIGH   = 3,
+    V4L2_TRIGGER_ACTIVATION_LEVEL_LOW    = 4
+};
+
+enum v4l2_triggersource
+{
+    V4L2_TRIGGER_SOURCE_LINE0    = 0,
+    V4L2_TRIGGER_SOURCE_LINE1    = 1,
+    V4L2_TRIGGER_SOURCE_LINE2    = 2,
+    V4L2_TRIGGER_SOURCE_LINE3    = 3,
+    V4L2_TRIGGER_SOURCE_SOFTWARE = 4
+};
+
+////////////////////////////////////////////////////////////////////////////////
+// STRUCTS
+////////////////////////////////////////////////////////////////////////////////
+struct v4l2_i2c
+{
+    __u32       register_address;       // Register
+    __u32       timeout;                // Timeout value
+    const char* ptr_buffer;             // I/O buffer
+    __u32       register_size;          // Register address size (should be 2 for AVT Alvium 1500 and 1800)
+    __u32       num_bytes;              // Bytes to read or write
+};
+
+struct v4l2_dma_mem
+{
+    __u32       index;                  // index of the buffer
+    __u32       type;                   // enum v4l2_buf_type
+    __u32       memory;                 // enum v4l2_memory
+};
+
+struct v4l2_statistics_capabilities
+{
+    __u64 statistics_capability;        // Bitmask with statistics capabilities enum (v4l2_statistics_capability)
+};
+
+struct v4l2_min_announced_frames
+{
+    __u32 min_announced_frames;         // Minimum number of announced frames
+};
+
+struct v4l2_range
+{
+    __u8  is_valid;                     // Indicates, if values are valid (1) or invalid (0)
+    __u32 min;                          // Minimum allowed value
+    __u32 max;                          // Maximum allowed value
+};
+
+struct v4l2_csi_host_clock_freq_ranges
+{
+    struct v4l2_range lane_range_1;     // Min and max value for 1 lane
+    struct v4l2_range lane_range_2;     // Min and max value for 2 lanes
+    struct v4l2_range lane_range_3;     // Min and max value for 3 lanes
+    struct v4l2_range lane_range_4;     // Min and max value for 4 lanes
+};
+
+struct v4l2_supported_lane_counts
+{
+    __u32 supported_lane_counts;        // Bitfield with the supported lane counts from v4l2_lane_counts
+};
+
+struct v4l2_restriction
+{
+    __u8  is_valid;                     // Indicates, if values are valid (1) or invalid (0)
+    __u32 min;                          // Minimum value
+    __u32 max;                          // Maximum value
+    __u32 inc;                          // Increment value
+};
+
+struct v4l2_ipu_restrictions
+{
+    struct v4l2_restriction ipu_x;      // X restriction
+    struct v4l2_restriction ipu_y;      // Y restriction
+};
+
+struct v4l2_streamoff_ex
+{
+    __u32 timeout;                      // Timeout value in ms
+};
+
+struct v4l2_gencp_buffer_sizes
+{
+    __u32 gencp_in_buffer_size;         // Size in bytes of the GenCP In buffer
+    __u32 gencp_out_buffer_size;        // Size in bytes of the GenCP Out buffer
+};
+
+struct v4l2_csi_data_identifiers_inq
+{
+    __u64 data_identifiers_inq_1;       // Inquiry for data identifiers 0-63
+    __u64 data_identifiers_inq_2;       // Inquiry for data identifiers 64-127
+    __u64 data_identifiers_inq_3;       // Inquiry for data identifiers 128-191
+    __u64 data_identifiers_inq_4;       // Inquiry for data identifiers 192-255
+};
+
+struct v4l2_stats_t
+{
+    __u64 frames_count;                 // Total number of frames received
+    __u64 packet_crc_error;             // Number of packets with CRC errors
+    __u64 frames_underrun;              // Number of frames dropped because of buffer underrun
+    __u64 frames_incomplete;            // Number of frames that were not completed
+    __u64 current_frame_count;          // Number of frames received within CurrentFrameInterval (nec. to calculate fps value)
+    __u64 current_frame_interval;       // Time interval between frames in µs
+};
+
+struct v4l2_csi_driver_info
+{
+    union _id
+    {
+        __u32 board_id;                 // 32 Bit board id
+        struct 
+        {
+            __u8 manufacturer_id;       // 0x00 = Boundary Devices, 0x01= NVIDIA
+            __u8 soc_family_id;         // 0x00 = i.MX6, 0x01=TEGRA, 0x02=i.MX8, 0x03=i.MX8X
+            __u8 driver_id;             // Driver identifier for a certain soc family 
+            __u8 reserved;              //
+        };
+    }id;
+    __u32 driver_version;               // Driver version
+    __u32 driver_interface_version;     // Used driver specification version
+    __u32 driver_caps;                  // Driver capabilities flags
+    __u32 usrptr_alignment;             // Buffer alignment for user pointer mode in bytes
+};
+
+struct v4l2_csi_config
+{
+    __u8  lane_count;                   // Number of lanes
+    __u32 csi_clock;                    // CSI clock in Hz
+};
+
+struct v4l2_trigger_status
+{
+    __u8 trigger_source;                // v4l2_triggersource enum value    
+    __u8 trigger_activation;            // v4l2_triggeractivation enum value  
+    __u8 trigger_mode_enabled;          // Enable (1) or disable (0) trigger mode
+};
+
+struct v4l2_trigger_rate
+{
+	__u64 frames_per_period;		    // Number of frames per period
+	__u64 period_sec;				    // Period in seconds
+};
+
+////////////////////////////////////////////////////////////////////////////////
+// DEFINES
+////////////////////////////////////////////////////////////////////////////////
+// Custom ioctl definitions
+/* i2c read */
+#define VIDIOC_R_I2C                        _IOWR('V', BASE_VIDIOC_PRIVATE + 0, struct v4l2_i2c)
+
+/* i2c write */
+#define VIDIOC_W_I2C                        _IOWR('V', BASE_VIDIOC_PRIVATE + 1, struct v4l2_i2c)
+
+/* Memory alloc for a frame */
+#define VIDIOC_MEM_ALLOC                    _IOWR('V', BASE_VIDIOC_PRIVATE + 2, struct v4l2_dma_mem)
+
+/* Memory free for a frame */
+#define VIDIOC_MEM_FREE                     _IOWR('V', BASE_VIDIOC_PRIVATE + 3, struct v4l2_dma_mem)
+
+/* Flush frames */
+#define VIDIOC_FLUSH_FRAMES                 _IO('V', BASE_VIDIOC_PRIVATE + 4)
+
+/* Stream statistics */
+#define VIDIOC_STREAMSTAT                   _IOR('V', BASE_VIDIOC_PRIVATE + 5, struct v4l2_stats_t)
+
+/* Reset Stream statistics */
+#define VIDIOC_RESET_STREAMSTAT             _IO('V', BASE_VIDIOC_PRIVATE + 6)
+
+/* Custom streamon */
+#define VIDIOC_STREAMON_EX                  _IO('V', BASE_VIDIOC_PRIVATE + 7)
+
+/* Custom streamoff */
+#define VIDIOC_STREAMOFF_EX                 _IOW('V', BASE_VIDIOC_PRIVATE + 8, struct v4l2_streamoff_ex)
+
+/* Get statistics capability */
+#define VIDIOC_G_STATISTICS_CAPABILITIES    _IOR('V', BASE_VIDIOC_PRIVATE + 9, struct v4l2_statistics_capabilities)
+
+/* Get min number of announced frames*/
+#define VIDIOC_G_MIN_ANNOUNCED_FRAMES       _IOR('V', BASE_VIDIOC_PRIVATE + 10, struct v4l2_min_announced_frames)
+
+/* Get supported lane value */
+#define VIDIOC_G_SUPPORTED_LANE_COUNTS      _IOR('V', BASE_VIDIOC_PRIVATE + 11, struct v4l2_supported_lane_counts)
+
+/* Get CSI Host clock frequencies */
+#define VIDIOC_G_CSI_HOST_CLK_FREQ          _IOR('V', BASE_VIDIOC_PRIVATE + 12, struct v4l2_csi_host_clock_freq_ranges)
+
+/* Get IPU restrictions */
+#define VIDIOC_G_IPU_RESTRICTIONS           _IOR('V', BASE_VIDIOC_PRIVATE + 13, struct v4l2_ipu_restrictions)
+
+/* Get GenCPIn and GenCPOut buffer sizes */
+#define VIDIOC_G_GENCP_BUFFER_SIZES         _IOWR('V', BASE_VIDIOC_PRIVATE + 14, struct v4l2_gencp_buffer_sizes)
+
+/* Retrieving the MIPI Data Identifier */
+#define VIDIOC_G_SUPPORTED_DATA_IDENTIFIERS _IOWR('V', BASE_VIDIOC_PRIVATE + 15, struct v4l2_csi_data_identifiers_inq)
+
+/* Retrieving i2c clock frequency */
+#define VIDIOC_G_I2C_CLOCK_FREQ             _IOWR('V', BASE_VIDIOC_PRIVATE + 16, int)
+
+/* Retrieving extended driver information */
+#define VIDIOC_G_DRIVER_INFO                _IOR('V', BASE_VIDIOC_PRIVATE + 17, struct v4l2_csi_driver_info)
+
+/* Get CSI configuration */
+#define VIDIOC_G_CSI_CONFIG                 _IOR('V', BASE_VIDIOC_PRIVATE + 18, struct v4l2_csi_config)
+
+/* Set CSI configuration */
+#define VIDIOC_S_CSI_CONFIG                 _IOWR('V', BASE_VIDIOC_PRIVATE + 19, struct v4l2_csi_config)
+
+/* Set the Trigger mode to OFF */
+#define VIDIOC_TRIGGER_MODE_OFF             _IO('V', BASE_VIDIOC_PRIVATE + 20)
+
+/* Set the Trigger mode to ON */
+#define VIDIOC_TRIGGER_MODE_ON              _IO('V', BASE_VIDIOC_PRIVATE + 21)
+
+/* Set the trigger activation */
+#define VIDIOC_S_TRIGGER_ACTIVATION         _IOW('V', BASE_VIDIOC_PRIVATE + 22, int)
+
+/* Get the trigger activation */
+#define VIDIOC_G_TRIGGER_ACTIVATION         _IOR('V', BASE_VIDIOC_PRIVATE + 23, int)
+
+/* Set the trigger source */
+#define VIDIOC_S_TRIGGER_SOURCE             _IOW('V', BASE_VIDIOC_PRIVATE + 24, int)
+
+/* Get the trigger source */
+#define VIDIOC_G_TRIGGER_SOURCE             _IOR('V', BASE_VIDIOC_PRIVATE + 25, int)
+
+/* Execute a software trigger */
+#define VIDIOC_TRIGGER_SOFTWARE             _IO('V', BASE_VIDIOC_PRIVATE + 26)
+
+
+#endif /* LIBCSI_IOCTL_H */
diff --git a/include/uapi/linux/media-bus-format.h b/include/uapi/linux/media-bus-format.h
index 0882827fcff8..7e4f16ce26d0 100644
--- a/include/uapi/linux/media-bus-format.h
+++ b/include/uapi/linux/media-bus-format.h
@@ -139,7 +139,8 @@
 /* JPEG compressed formats - next is	0x4002 */
 #define MEDIA_BUS_FMT_JPEG_1X8			0x4001
 
-/* Vendor specific formats - next is	0x5002 */
+/* Vendor specific formats - next is	0x5003 */
+#define MEDIA_BUS_FMT_CUSTOM        0x5002
 
 /* S5C73M3 sensor specific interleaved UYVY and JPEG */
 #define MEDIA_BUS_FMT_S5C_UYVY_JPEG_1X8		0x5001
diff --git a/include/uapi/linux/v4l2-subdev.h b/include/uapi/linux/v4l2-subdev.h
index dbce2b554e02..17da5fc9aafe 100644
--- a/include/uapi/linux/v4l2-subdev.h
+++ b/include/uapi/linux/v4l2-subdev.h
@@ -38,6 +38,18 @@ enum v4l2_subdev_format_whence {
 	V4L2_SUBDEV_FORMAT_ACTIVE = 1,
 };
 
+/**
+ * enum v4l2_subdev_format_whence - Media bus format type
+ * @V4L2_SUBDEV_FRMIVAL_TYPE_DISCRETE: discrete frame intervals
+ * @V4L2_SUBDEV_FRMIVAL_TYPE_CONTINUOUS: continuous frame intervals
+ * @V4L2_SUBDEV_FRMIVAL_TYPE_STEPWISE: stepwise frame intervals
+ */
+enum v4l2_subdev_frame_interval_type{
+	V4L2_SUBDEV_FRMIVAL_TYPE_DISCRETE	= 0,
+	V4L2_SUBDEV_FRMIVAL_TYPE_CONTINUOUS	= 1,
+	V4L2_SUBDEV_FRMIVAL_TYPE_STEPWISE	= 2,
+};
+
 /**
  * struct v4l2_subdev_format - Pad-level media bus format
  * @which: format type (from enum v4l2_subdev_format_whence)
@@ -116,8 +128,13 @@ struct v4l2_subdev_frame_interval {
  * @code: format code (MEDIA_BUS_FMT_ definitions)
  * @width: frame width in pixels
  * @height: frame height in pixels
- * @interval: frame interval in seconds
+ * @interval: frame interval in seconds, if the type is continuous or stepwise
+ * 		this field contains the minimum frame interval
  * @which: format type (from enum v4l2_subdev_format_whence)
+ * @type: frame interval type (from enum v4l2_subdev_frame_interval_type)
+ * @max_interval: maximum frame interval in seconds, only valid for types
+ * 		continuous and stepwise
+ * @step_interval: frame interval step in seconds, only valid for type stepwise
  */
 struct v4l2_subdev_frame_interval_enum {
 	__u32 index;
@@ -127,7 +144,10 @@ struct v4l2_subdev_frame_interval_enum {
 	__u32 height;
 	struct v4l2_fract interval;
 	__u32 which;
-	__u32 reserved[8];
+	__u32 type;
+	struct v4l2_fract max_interval;
+	struct v4l2_fract step_interval;
+	__u32 reserved[3];
 };
 
 /**
diff --git a/include/uapi/linux/videodev2.h b/include/uapi/linux/videodev2.h
index ae04e9e06600..fdfb3d55f116 100644
--- a/include/uapi/linux/videodev2.h
+++ b/include/uapi/linux/videodev2.h
@@ -664,6 +664,30 @@ struct v4l2_pix_format {
 /* Relative IR */
 #define V4L2_PIX_FMT_PAIR	v4l2_fourcc('P', 'A', 'I', 'R')
 
+#define V4L2_PIX_FMT_CUSTOM    v4l2_fourcc('T', 'P', '3', '1') /* 0x31 mipi datatype  */
+/* TX2 */
+#define V4L2_PIX_FMT_TX2_Y10     v4l2_fourcc('J', '2', 'Y', '0') /* 10  Greyscale     */
+#define V4L2_PIX_FMT_TX2_Y12     v4l2_fourcc('J', '2', 'Y', '2') /* 12  Greyscale     */
+#define V4L2_PIX_FMT_TX2_SBGGR10 v4l2_fourcc('J', '2', 'B', '0') /* 10  BGBG.. GRGR.. */
+#define V4L2_PIX_FMT_TX2_SGBRG10 v4l2_fourcc('J', '2', 'G', '0') /* 10  GBGB.. RGRG.. */
+#define V4L2_PIX_FMT_TX2_SGRBG10 v4l2_fourcc('J', '2', 'A', '0') /* 10  GRGR.. BGBG.. */
+#define V4L2_PIX_FMT_TX2_SRGGB10 v4l2_fourcc('J', '2', 'R', '0') /* 10  RGRG.. GBGB.. */
+#define V4L2_PIX_FMT_TX2_SBGGR12 v4l2_fourcc('J', '2', 'B', '2') /* 12  BGBG.. GRGR.. */
+#define V4L2_PIX_FMT_TX2_SGBRG12 v4l2_fourcc('J', '2', 'G', '2') /* 12  GBGB.. RGRG.. */
+#define V4L2_PIX_FMT_TX2_SGRBG12 v4l2_fourcc('J', '2', 'A', '2') /* 12  GRGR.. BGBG.. */
+#define V4L2_PIX_FMT_TX2_SRGGB12 v4l2_fourcc('J', '2', 'R', '2') /* 12  RGRG.. GBGB.. */
+/* Xavier */
+#define V4L2_PIX_FMT_XAVIER_Y10     v4l2_fourcc('J', 'X', 'Y', '0') /* 10  Greyscale     */
+#define V4L2_PIX_FMT_XAVIER_Y12     v4l2_fourcc('J', 'X', 'Y', '2') /* 12  Greyscale     */
+#define V4L2_PIX_FMT_XAVIER_SBGGR10 v4l2_fourcc('J', 'X', 'B', '0') /* 10  BGBG.. GRGR.. */
+#define V4L2_PIX_FMT_XAVIER_SGBRG10 v4l2_fourcc('J', 'X', 'G', '0') /* 10  GBGB.. RGRG.. */
+#define V4L2_PIX_FMT_XAVIER_SGRBG10 v4l2_fourcc('J', 'X', 'A', '0') /* 10  GRGR.. BGBG.. */
+#define V4L2_PIX_FMT_XAVIER_SRGGB10 v4l2_fourcc('J', 'X', 'R', '0') /* 10  RGRG.. GBGB.. */
+#define V4L2_PIX_FMT_XAVIER_SBGGR12 v4l2_fourcc('J', 'X', 'B', '2') /* 12  BGBG.. GRGR.. */
+#define V4L2_PIX_FMT_XAVIER_SGBRG12 v4l2_fourcc('J', 'X', 'G', '2') /* 12  GBGB.. RGRG.. */
+#define V4L2_PIX_FMT_XAVIER_SGRBG12 v4l2_fourcc('J', 'X', 'A', '2') /* 12  GRGR.. BGBG.. */
+#define V4L2_PIX_FMT_XAVIER_SRGGB12 v4l2_fourcc('J', 'X', 'R', '2') /* 12  RGRG.. GBGB.. */
+
 /* SDR formats - used only for Software Defined Radio devices */
 #define V4L2_SDR_FMT_CU8          v4l2_fourcc('C', 'U', '0', '8') /* IQ u8 */
 #define V4L2_SDR_FMT_CU16LE       v4l2_fourcc('C', 'U', '1', '6') /* IQ u16le */
diff --git a/nvidia/drivers/media/platform/tegra/camera/camera_common.c b/nvidia/drivers/media/platform/tegra/camera/camera_common.c
index ce1f254dd76d..1cb704235401 100644
--- a/nvidia/drivers/media/platform/tegra/camera/camera_common.c
+++ b/nvidia/drivers/media/platform/tegra/camera/camera_common.c
@@ -44,12 +44,12 @@ static const struct camera_common_colorfmt camera_common_color_fmts[] = {
 	{
 		MEDIA_BUS_FMT_SRGGB12_1X12,
 		V4L2_COLORSPACE_SRGB,
-		V4L2_PIX_FMT_SRGGB12,
+		V4L2_PIX_FMT_SRGGB16,
 	},
 	{
 		MEDIA_BUS_FMT_SGRBG12_1X12,
 		V4L2_COLORSPACE_SRGB,
-		V4L2_PIX_FMT_SGRBG12,
+		V4L2_PIX_FMT_SGRBG16,
 	},
 	{
 		MEDIA_BUS_FMT_SGBRG12_1X12,
@@ -59,12 +59,12 @@ static const struct camera_common_colorfmt camera_common_color_fmts[] = {
 	{
 		MEDIA_BUS_FMT_SRGGB10_1X10,
 		V4L2_COLORSPACE_SRGB,
-		V4L2_PIX_FMT_SRGGB10,
+		V4L2_PIX_FMT_SRGGB16,
 	},
 	{
 		MEDIA_BUS_FMT_SGRBG10_1X10,
 		V4L2_COLORSPACE_SRGB,
-		V4L2_PIX_FMT_SGRBG10,
+		V4L2_PIX_FMT_SGRBG16,
 	},
 	{
 		MEDIA_BUS_FMT_SGBRG10_1X10,
@@ -74,7 +74,7 @@ static const struct camera_common_colorfmt camera_common_color_fmts[] = {
 	{
 		MEDIA_BUS_FMT_SBGGR10_1X10,
 		V4L2_COLORSPACE_SRGB,
-		V4L2_PIX_FMT_SBGGR10,
+		V4L2_PIX_FMT_SBGGR16,
 	},
 	{
 		MEDIA_BUS_FMT_SRGGB8_1X8,
diff --git a/nvidia/drivers/media/platform/tegra/camera/csi/csi.c b/nvidia/drivers/media/platform/tegra/camera/csi/csi.c
index 8d546a42e1bf..2acd5d68328d 100644
--- a/nvidia/drivers/media/platform/tegra/camera/csi/csi.c
+++ b/nvidia/drivers/media/platform/tegra/camera/csi/csi.c
@@ -967,6 +967,9 @@ static int tegra_csi_channel_init_one(struct tegra_csi_channel *chan)
 			media_entity_cleanup(&sd->entity);
 		}
 	}
+
+	chan->packet_crc_error = 0;
+
 	return ret;
 }
 
diff --git a/nvidia/drivers/media/platform/tegra/camera/csi/csi2_fops.c b/nvidia/drivers/media/platform/tegra/camera/csi/csi2_fops.c
index f026d2359f43..74b45badb273 100644
--- a/nvidia/drivers/media/platform/tegra/camera/csi/csi2_fops.c
+++ b/nvidia/drivers/media/platform/tegra/camera/csi/csi2_fops.c
@@ -82,17 +82,29 @@ int tegra_csi_error(struct tegra_csi_channel *chan, int port_idx)
 	 * corrected automatically
 	 */
 	val = pp_read(port, TEGRA_CSI_PIXEL_PARSER_STATUS);
-	err |= val & 0x4000;
+	err |= val & (0x4000);
 	pp_write(port, TEGRA_CSI_PIXEL_PARSER_STATUS, val);
 
+    if (val) {
+        dev_dbg(chan->csi->dev,"pixel parser error %u",val);
+    }
+
 	val = cil_read(port, TEGRA_CSI_CIL_STATUS);
 	err |= val & 0x02;
 	cil_write(port, TEGRA_CSI_CIL_STATUS, val);
 
+    if (val) {
+        dev_dbg(chan->csi->dev,"cil status error %u",val);
+    }
+
 	val = cil_read(port, TEGRA_CSI_CILX_STATUS);
 	err |= val & 0x00020020;
 	cil_write(port, TEGRA_CSI_CILX_STATUS, val);
 
+    if (val) {
+        dev_dbg(chan->csi->dev,"cilx status error %u",val);
+    }
+
 	return err;
 }
 
@@ -372,6 +384,7 @@ static int csi2_start_streaming(struct tegra_csi_channel *chan, int port_idx)
 	pp_write(port, TEGRA_CSI_PIXEL_STREAM_PP_COMMAND,
 			(0xF << CSI_PP_START_MARKER_FRAME_MAX_OFFSET) |
 			CSI_PP_SINGLE_SHOT_ENABLE | CSI_PP_ENABLE);
+
 	return 0;
 }
 
diff --git a/nvidia/drivers/media/platform/tegra/camera/csi/csi4_fops.c b/nvidia/drivers/media/platform/tegra/camera/csi/csi4_fops.c
index 66557f12794a..1ba7f5003929 100644
--- a/nvidia/drivers/media/platform/tegra/camera/csi/csi4_fops.c
+++ b/nvidia/drivers/media/platform/tegra/camera/csi/csi4_fops.c
@@ -93,6 +93,15 @@ static void csi4_stream_init(struct tegra_csi_channel *chan, int csi_port)
 	csi4_stream_write(chan, csi_port, ERR_INTR_MASK, 0x0);
 }
 
+static void csi4_bypass_datatype(struct tegra_csi_channel *chan, int port_idx)
+{
+	if(chan->bypass_dt)
+		csi4_stream_write(chan, port_idx, VC0_DT_OVERRIDE,
+			CFG_VC0_DT_OVERRIDE_EN | 0x22);
+	else
+		csi4_stream_write(chan, port_idx, VC0_DT_OVERRIDE, 0);
+}
+
 static void csi4_stream_config(struct tegra_csi_channel *chan, int port_idx)
 {
 	struct tegra_csi_device *csi = chan->csi;
@@ -104,7 +113,7 @@ static void csi4_stream_config(struct tegra_csi_channel *chan, int port_idx)
 	csi4_stream_write(chan, port_idx, PH_CHK_CTRL,
 			CFG_PH_CRC_CHK_EN | CFG_PH_ECC_CHK_EN);
 	csi4_stream_write(chan, port_idx, VC0_DPCM_CTRL, 0);
-	csi4_stream_write(chan, port_idx, VC0_DT_OVERRIDE, 0);
+	csi4_bypass_datatype(chan, port_idx);
 
 	val = csi4_stream_read(chan, port_idx, VC0_DPCM_CTRL);
 	dev_dbg(csi->dev, "%s (%d) read VC0_DPCM_CTRL = %08x\n",
@@ -352,28 +361,40 @@ static void csi4_stream_check_status(struct tegra_csi_channel *chan,
 	dev_dbg(csi->dev, "%s\n", __func__);
 	if (!chan->pg_mode) {
 		status = csi4_stream_read(chan, port_idx, ERROR_STATUS2VI_VC0);
-		if (status)
+		if (status) {
 			dev_err(csi->dev,
 				"%s (%d) ERROR_STATUS2VI_VC0 = 0x%08x\n",
 				__func__, port_idx, status);
+			if (status & PD_CRC_ERR_VC0)
+				chan->packet_crc_error++;
+		}
 
 		status = csi4_stream_read(chan, port_idx, ERROR_STATUS2VI_VC1);
-		if (status)
+		if (status) {
 			dev_err(csi->dev,
 				"%s (%d) ERROR_STATUS2VI_VC1 = 0x%08x\n",
 				__func__, port_idx, status);
+			if (status & PD_CRC_ERR_VC0)
+				chan->packet_crc_error++;
+		}
 
 		status = csi4_stream_read(chan, port_idx, ERROR_STATUS2VI_VC2);
-		if (status)
+		if (status) {
 			dev_err(csi->dev,
 				"%s (%d) ERROR_STATUS2VI_VC2 = 0x%08x\n",
 				__func__, port_idx, status);
+			if (status & PD_CRC_ERR_VC0)
+				chan->packet_crc_error++;
+		}
 
 		status = csi4_stream_read(chan, port_idx, ERROR_STATUS2VI_VC3);
-		if (status)
+		if (status) {
 			dev_err(csi->dev,
 				"%s (%d) ERROR_STATUS2VI_VC2 = 0x%08x\n",
 				__func__, port_idx, status);
+			if (status & PD_CRC_ERR_VC0)
+				chan->packet_crc_error++;
+		}
 	}
 
 	status = csi4_stream_read(chan, port_idx, INTR_STATUS);
@@ -689,6 +710,7 @@ struct tegra_csi_fops csi4_fops = {
 	.csi_stop_streaming = csi4_stop_streaming,
 	.csi_override_format = csi4_override_format,
 	.csi_error_recover = csi4_error_recover,
+	.csi_check_status = csi4_stream_check_status,
 	.mipical = csi4_mipi_cal,
 	.hw_init = csi4_hw_init,
 };
diff --git a/nvidia/drivers/media/platform/tegra/camera/nvcsi/csi5_fops.c b/nvidia/drivers/media/platform/tegra/camera/nvcsi/csi5_fops.c
index 73b2ad7c4d0f..c86b467e23c0 100644
--- a/nvidia/drivers/media/platform/tegra/camera/nvcsi/csi5_fops.c
+++ b/nvidia/drivers/media/platform/tegra/camera/nvcsi/csi5_fops.c
@@ -126,6 +126,28 @@ static void csi5_stream_close(struct tegra_csi_channel *chan, u32 stream_id,
 	tegra_capture_ivc_control_submit(&msg, sizeof(msg));
 }
 
+static void csi5_bypass_datatype(struct tegra_csi_channel *chan, u32 stream_id)
+{
+	struct tegra_csi_port *port = &chan->ports[0];
+	struct CAPTURE_CONTROL_MSG msg;
+
+	memset(&msg, 0, sizeof(msg));
+	msg.header.msg_id = CAPTURE_CSI_STREAM_SET_PARAM_REQ;
+	msg.header.channel_id = TEMP_CHANNEL_ID;
+
+	msg.csi_stream_set_param_req.stream_id = stream_id;
+	msg.csi_stream_set_param_req.virtual_channel_id = port->virtual_channel_id;
+	msg.csi_stream_set_param_req.param_type = NVCSI_PARAM_TYPE_DT_OVERRIDE;
+
+	if(chan->bypass_dt) {
+		msg.csi_stream_set_param_req.dt_override_config.enable_override = 1;
+		msg.csi_stream_set_param_req.dt_override_config.override_type = NVCSI_DATATYPE_YUV422_8;
+	} else
+		msg.csi_stream_set_param_req.dt_override_config.enable_override = 0;
+
+	tegra_capture_ivc_control_submit(&msg, sizeof(msg));
+}
+
 static int csi5_stream_set_config(struct tegra_csi_channel *chan, u32 stream_id,
 	u32 csi_port, int csi_lanes)
 {
@@ -178,6 +200,8 @@ static int csi5_stream_set_config(struct tegra_csi_channel *chan, u32 stream_id,
 
 	tegra_capture_ivc_control_submit(&msg, sizeof(msg));
 
+	csi5_bypass_datatype(chan, stream_id);
+
 	return 0;
 }
 
diff --git a/nvidia/drivers/media/platform/tegra/camera/sensor_common.c b/nvidia/drivers/media/platform/tegra/camera/sensor_common.c
index 75f9ff4c9b5a..b569877be8e9 100644
--- a/nvidia/drivers/media/platform/tegra/camera/sensor_common.c
+++ b/nvidia/drivers/media/platform/tegra/camera/sensor_common.c
@@ -198,31 +198,31 @@ static int extract_pixel_format(
 	size_t size = strnlen(pixel_t, OF_MAX_STR_LEN);
 
 	if (strncmp(pixel_t, "bayer_bggr10", size) == 0)
-		*format = V4L2_PIX_FMT_SBGGR10;
+		*format = V4L2_PIX_FMT_SBGGR16;
 	else if (strncmp(pixel_t, "bayer_rggb10", size) == 0)
-		*format = V4L2_PIX_FMT_SRGGB10;
+		*format = V4L2_PIX_FMT_SRGGB16;
 	else if (strncmp(pixel_t, "bayer_grbg10", size) == 0)
-		*format = V4L2_PIX_FMT_SGRBG10;
+		*format = V4L2_PIX_FMT_SGRBG16;
 	else if (strncmp(pixel_t, "bayer_gbrg10", size) == 0)
-		*format = V4L2_PIX_FMT_SGBRG10;
+		*format = V4L2_PIX_FMT_SGRBG16;
 	else if (strncmp(pixel_t, "bayer_bggr12", size) == 0)
-		*format = V4L2_PIX_FMT_SBGGR12;
+		*format = V4L2_PIX_FMT_SBGGR16;
 	else if (strncmp(pixel_t, "bayer_rggb12", size) == 0)
-		*format = V4L2_PIX_FMT_SRGGB12;
+		*format = V4L2_PIX_FMT_SRGGB16;
 	else if (strncmp(pixel_t, "bayer_gbrg12", size) == 0)
-		*format = V4L2_PIX_FMT_SGBRG12;
+		*format = V4L2_PIX_FMT_SGBRG16;
 	else if (strncmp(pixel_t, "bayer_grbg12", size) == 0)
-		*format = V4L2_PIX_FMT_SGRBG12;
+		*format = V4L2_PIX_FMT_SGRBG16;
 	else if (strncmp(pixel_t, "rgb_rgb88824", size) == 0)
 		*format = V4L2_PIX_FMT_RGB24;
 	else if (strncmp(pixel_t, "bayer_wdr_pwl_rggb12", size) == 0)
-		*format = V4L2_PIX_FMT_SRGGB12;
+		*format = V4L2_PIX_FMT_SRGGB16;
 	else if (strncmp(pixel_t, "bayer_wdr_pwl_gbrg12", size) == 0)
-		*format = V4L2_PIX_FMT_SGBRG12;
+		*format = V4L2_PIX_FMT_SGBRG16;
 	else if (strncmp(pixel_t, "bayer_wdr_pwl_grbg12", size) == 0)
-		*format = V4L2_PIX_FMT_SGRBG12;
+		*format = V4L2_PIX_FMT_SGRBG16;
 	else if (strncmp(pixel_t, "bayer_wdr_dol_rggb10", size) == 0)
-		*format = V4L2_PIX_FMT_SRGGB10;
+		*format = V4L2_PIX_FMT_SRGGB16;
 	else if (strncmp(pixel_t, "bayer_xbggr10p", size) == 0)
 		*format = V4L2_PIX_FMT_XBGGR10P;
 	else if (strncmp(pixel_t, "bayer_xrggb10p", size) == 0)
diff --git a/nvidia/drivers/media/platform/tegra/camera/vi/capture.c b/nvidia/drivers/media/platform/tegra/camera/vi/capture.c
index 2d88b008d97c..1bbe3fafbe0f 100644
--- a/nvidia/drivers/media/platform/tegra/camera/vi/capture.c
+++ b/nvidia/drivers/media/platform/tegra/camera/vi/capture.c
@@ -1083,6 +1083,16 @@ int vi_capture_request(struct tegra_vi_channel *chan,
 	return 0;
 }
 
+int vi_stop_waiting(struct tegra_vi_channel *chan)
+{
+	struct vi_capture *capture = chan->capture_data;
+	struct completion *x = &capture->capture_resp;
+
+	x->done++;
+
+	return 0;
+}
+
 int vi_capture_status(struct tegra_vi_channel *chan,
 		int32_t timeout_ms)
 {
@@ -1106,7 +1116,17 @@ int vi_capture_status(struct tegra_vi_channel *chan,
 
 	/* negative timeout means wait forever */
 	if (timeout_ms < 0) {
-		wait_for_completion(&capture->capture_resp);
+		// This is workaround for issue on Xavier that was
+		// rebooting the device after about 3 minutes.
+		// When we are executing wait_for_completion without timeout,
+		// waiting thread is marked as stalled and whole system is rebooted.
+		// In case of wait_for_completion_timeout we are executing
+		// schedule() after timeout, that fixes this problem.
+		do {
+			ret = wait_for_completion_timeout(
+					&capture->capture_resp,
+					msecs_to_jiffies(120000)); // set timeout to 2min
+		} while (ret == 0); // wait until return value is not timeout
 	} else {
 		ret = wait_for_completion_timeout(
 				&capture->capture_resp,
diff --git a/nvidia/drivers/media/platform/tegra/camera/vi/channel.c b/nvidia/drivers/media/platform/tegra/camera/vi/channel.c
index dafb69740289..3896c56acd7a 100644
--- a/nvidia/drivers/media/platform/tegra/camera/vi/channel.c
+++ b/nvidia/drivers/media/platform/tegra/camera/vi/channel.c
@@ -24,6 +24,7 @@
 #include <linux/slab.h>
 #include <linux/semaphore.h>
 #include <linux/nospec.h>
+#include <linux/nvhost.h>
 
 #include <media/v4l2-ctrls.h>
 #include <media/v4l2-event.h>
@@ -39,6 +40,9 @@
 #include <media/v4l2-dv-timings.h>
 #include <media/vi.h>
 
+#include <uapi/linux/libcsi_ioctl.h>
+#include <media/avt_csi2_soc.h>
+
 #include <linux/clk/tegra.h>
 #define CREATE_TRACE_POINTS
 #include <trace/events/camera_common.h>
@@ -54,6 +58,25 @@
 
 static s64 queue_init_ts;
 
+struct camera_list_entry {
+  int channel_id;
+  struct list_head camera_list_head;
+};
+
+static struct list_head camera_list = LIST_HEAD_INIT(camera_list);
+
+enum flush_state {
+ FLUSH_NOT_INITIATED = 0,
+ FLUSH_IN_PROGRESS,
+ FLUSH_DONE,
+};
+
+static void update_flush_state(struct tegra_channel *chan,
+                enum flush_state new_state)
+{
+ sprintf(&chan->video->flush, "%d", new_state);
+}
+
 static bool tegra_channel_verify_focuser(struct tegra_channel *chan)
 {
 	char *str;
@@ -184,6 +207,10 @@ static void tegra_channel_fmt_align(struct tegra_channel *chan,
 
 	denominator = (!bpp->denominator) ? 1 : bpp->denominator;
 	numerator = (!bpp->numerator) ? 1 : bpp->numerator;
+
+  bpl = (*width * numerator) / denominator;
+ if (!*bytesperline)
+   *bytesperline = bpl;
 	/* The transfer alignment requirements are expressed in bytes. Compute
 	 * the minimum and maximum values, clamp the requested width and convert
 	 * it back to pixels.
@@ -195,10 +222,6 @@ static void tegra_channel_fmt_align(struct tegra_channel *chan,
 	align = align > 0 ? align : 1;
 	bpl = tegra_core_bytes_per_line(*width, align, vfmt);
 
-	/* Align stride */
-	if (chan->vi->fops->vi_stride_align)
-		chan->vi->fops->vi_stride_align(&bpl);
-
 	if (!*bytesperline)
 		*bytesperline = bpl;
 
@@ -260,10 +283,6 @@ static void tegra_channel_update_format(struct tegra_channel *chan,
 	u32 numerator = (!bpp->numerator) ? 1 : bpp->numerator;
 	u32 bytesperline = (width * numerator / denominator);
 
-	/* Align stride */
-	if (chan->vi->fops->vi_stride_align)
-		chan->vi->fops->vi_stride_align(&bytesperline);
-
 	chan->format.width = width;
 	chan->format.height = height;
 	chan->format.pixelformat = fourcc;
@@ -281,8 +300,9 @@ static void tegra_channel_update_format(struct tegra_channel *chan,
 				&chan->format.bytesperline);
 
 	/* Calculate the sizeimage per plane */
-	chan->format.sizeimage = get_aligned_buffer_size(chan,
-			chan->format.bytesperline, chan->format.height);
+  chan->format.sizeimage = get_aligned_buffer_size(chan,
+                            chan->format.bytesperline,
+                            chan->format.height);
 
 	tegra_channel_set_interlace_mode(chan);
 	/* Double the size of allocated buffer for interlaced sensor modes */
@@ -401,6 +421,10 @@ void release_buffer(struct tegra_channel *chan,
 	if (chan->capture_state != CAPTURE_GOOD || vbuf->sequence < 2)
 		buf->state = VB2_BUF_STATE_REQUEUEING;
 
+  if (atomic_read(&chan->stop_streaming) && chan->avt_cam_mode) {
+        buf->state = VB2_BUF_STATE_ERROR;
+    }
+
 	if (chan->sequence == 1) {
 		/*
 		 * Evaluate the initial capture latency between videobuf2 queue
@@ -519,8 +543,13 @@ void free_ring_buffers(struct tegra_channel *chan, int frames)
 				"%s: capture init latency is %lld ms\n",
 				__func__, (frame_arrived_ts - queue_init_ts));
 		}
-		vb2_buffer_done(&vbuf->vb2_buf,
-			chan->buffer_state[chan->free_index++]);
+		/* Enable single buffer use */
+   if (chan->capture_queue_depth == 2)
+     vb2_buffer_done(&vbuf->vb2_buf,
+       chan->buffer_state[chan->free_index]);
+   else
+     vb2_buffer_done(&vbuf->vb2_buf,
+       chan->buffer_state[chan->free_index++]);
 
 		if (chan->free_index >= chan->capture_queue_depth)
 			chan->free_index = 0;
@@ -539,7 +568,7 @@ static void add_buffer_to_ring(struct tegra_channel *chan,
 	spin_lock(&chan->buffer_lock);
 	chan->buffer_state[chan->save_index] = VB2_BUF_STATE_REQUEUEING;
 	chan->buffers[chan->save_index++] = vb;
-	if (chan->save_index >= chan->capture_queue_depth)
+	if ((chan->save_index >= chan->capture_queue_depth) || (chan->capture_queue_depth <= 2))
 		chan->save_index = 0;
 	chan->num_buffers++;
 	spin_unlock(&chan->buffer_lock);
@@ -547,17 +576,7 @@ static void add_buffer_to_ring(struct tegra_channel *chan,
 
 static void update_state_to_buffer(struct tegra_channel *chan, int state)
 {
-	int save_index = (chan->save_index - PREVIOUS_BUFFER_DEC_INDEX);
-
-	/* save index decrements by 2 as 3 bufs are added in ring buffer */
-	if (save_index < 0)
-		save_index += chan->capture_queue_depth;
-	/* update state for the previous buffer */
-	chan->buffer_state[save_index] = state;
-
-	/* for timeout/error case update the current buffer state as well */
-	if (chan->capture_state != CAPTURE_GOOD)
-		chan->buffer_state[chan->save_index] = state;
+	chan->buffer_state[chan->free_index] = state;
 }
 
 void tegra_channel_ring_buffer(struct tegra_channel *chan,
@@ -565,10 +584,9 @@ void tegra_channel_ring_buffer(struct tegra_channel *chan,
 					struct timespec *ts, int state)
 
 {
-	if (!chan->bfirst_fstart)
+	if (!chan->bfirst_fstart && (chan->capture_queue_depth > 3))
 		chan->bfirst_fstart = true;
-	else
-		update_state_to_buffer(chan, state);
+	update_state_to_buffer(chan, state);
 
 	/* Capture state is not GOOD, release all buffers and re-init state */
 	if (chan->capture_state != CAPTURE_GOOD) {
@@ -581,15 +599,39 @@ void tegra_channel_ring_buffer(struct tegra_channel *chan,
 		vb->timestamp.tv_sec = ts->tv_sec;
 		vb->timestamp.tv_usec = ts->tv_nsec / NSEC_PER_USEC;
 #else
-		/* TODO: granular time code information */
-		vb->timecode.seconds = ts->tv_sec;
+		vb->vb2_buf.timestamp = timespec_to_ns(ts);
 #endif
 	}
-
-	/* release buffer N at N+2 frame start event */
-	if (chan->num_buffers >= (chan->capture_queue_depth - 1))
-		free_ring_buffers(chan, 1);
-}
+	/* release buffer */
+   free_ring_buffers(chan, 1);
+}
+
+void tegra_channel_update_statistics(struct tegra_channel *chan)
+{
+    uint64_t curr_frame_jiffies = 0;
+
+    if (chan->capture_state != CAPTURE_GOOD) {
+   /* Mark frame as incomplete only after stopping stream */
+   if (!atomic_read(&chan->is_streaming))
+        {
+     chan->stream_stats.frames_incomplete++;
+     chan->incomplete_flag = true;
+   }
+        /* Frames counted as underrun doesn't have any flag, because they are considered as dropped */
+        else
+        {
+     chan->stream_stats.frames_underrun++;
+        }
+    }
+    else
+    {
+   chan->stream_stats.frames_count++;
+   curr_frame_jiffies = get_jiffies_64();
+   chan->stream_stats.current_frame_interval = jiffies_to_usecs(curr_frame_jiffies - chan->start_frame_jiffies);
+   chan->start_frame_jiffies = curr_frame_jiffies;
+
+    }
+ }
 
 void tegra_channel_ec_close(struct tegra_mc_vi *vi)
 {
@@ -682,6 +724,9 @@ tegra_channel_queue_setup(struct vb2_queue *vq,
 	sizes[0] = chan->format.sizeimage;
 	alloc_devs[0] = chan->vi->dev;
 
+  if (chan->avt_cam_mode && chan->created_bufs > 0)
+   *nbuffers = chan->created_bufs + 1;
+
 	if (vi->fops && vi->fops->vi_setup_queue)
 		return vi->fops->vi_setup_queue(chan, nbuffers);
 	else
@@ -769,6 +814,11 @@ static void tegra_channel_buffer_queue(struct vb2_buffer *vb)
 	struct tegra_channel *chan = vb2_get_drv_priv(vb->vb2_queue);
 	struct tegra_channel_buffer *buf = to_tegra_channel_buffer(vbuf);
 
+  /* Reset flush state, because new buffers
+  * are enqueued
+  */
+ update_flush_state(chan, FLUSH_NOT_INITIATED);
+
 	/* for bypass mode - do nothing */
 	if (chan->bypass)
 		return;
@@ -978,6 +1028,8 @@ static int tegra_channel_start_streaming(struct vb2_queue *vq, u32 count)
 	struct tegra_channel *chan = vb2_get_drv_priv(vq);
 	struct tegra_mc_vi *vi = chan->vi;
 
+  atomic_set(&chan->stop_streaming,0);
+
 	if (vi->fops) {
 		int ret = 0;
 
@@ -996,6 +1048,8 @@ static void tegra_channel_stop_streaming(struct vb2_queue *vq)
 	struct tegra_channel *chan = vb2_get_drv_priv(vq);
 	struct tegra_mc_vi *vi = chan->vi;
 
+  atomic_set(&chan->stop_streaming,1);
+
 	if (vi->fops) {
 		vi->fops->vi_stop_streaming(vq);
 		vi->fops->vi_power_off(chan);
@@ -1025,10 +1079,11 @@ tegra_channel_querycap(struct file *file, void *fh, struct v4l2_capability *cap)
 	struct tegra_channel *chan = video_drvdata(file);
 
 	cap->device_caps = V4L2_CAP_VIDEO_CAPTURE | V4L2_CAP_STREAMING;
+  cap->device_caps = V4L2_CAP_VIDEO_CAPTURE | V4L2_CAP_STREAMING | V4L2_CAP_READWRITE;
 	cap->device_caps |= V4L2_CAP_EXT_PIX_FORMAT;
 	cap->capabilities = cap->device_caps | V4L2_CAP_DEVICE_CAPS;
 
-	strlcpy(cap->driver, "tegra-video", sizeof(cap->driver));
+	strlcpy(cap->driver, "avt_tegra_csi2", sizeof(cap->driver));
 	strlcpy(cap->card, chan->video->name, sizeof(cap->card));
 	snprintf(cap->bus_info, sizeof(cap->bus_info), "platform:%s:%u",
 		 dev_name(chan->vi->dev), chan->port[0]);
@@ -1085,11 +1140,24 @@ tegra_channel_enum_frameintervals(struct file *file, void *fh,
 	ret = v4l2_subdev_call(sd, pad, enum_frame_interval, NULL, &fie);
 
 	if (!ret) {
-		intervals->type = V4L2_FRMIVAL_TYPE_DISCRETE;
-		intervals->discrete.numerator = fie.interval.numerator;
-		intervals->discrete.denominator = fie.interval.denominator;
+	 if (fie.type == V4L2_SUBDEV_FRMIVAL_TYPE_DISCRETE) {
+     intervals->type = V4L2_FRMIVAL_TYPE_DISCRETE;
+     intervals->discrete = fie.interval;
+   }
+   else if (fie.type == V4L2_SUBDEV_FRMIVAL_TYPE_STEPWISE) {
+     intervals->type = V4L2_FRMIVAL_TYPE_STEPWISE;
+     intervals->stepwise.min = fie.interval;
+     intervals->stepwise.max = fie.max_interval;
+     intervals->stepwise.step = fie.step_interval;
+   }
+   else if (fie.type == V4L2_SUBDEV_FRMIVAL_TYPE_CONTINUOUS) {
+     intervals->type = V4L2_FRMIVAL_TYPE_CONTINUOUS;
+     intervals->stepwise.min = fie.interval;
+     intervals->stepwise.max = fie.max_interval;
+     intervals->stepwise.step.denominator = 1;
+     intervals->stepwise.step.numerator = 1;
+   }
 	}
-
 	return ret;
 }
 
@@ -1799,6 +1867,8 @@ int tegra_channel_init_subdevices(struct tegra_channel *chan)
 	int grp_id = chan->pg_mode ? (TPG_CSI_GROUP_ID + chan->port[0] + 1)
 		: chan->port[0] + 1;
 
+  update_flush_state(chan, FLUSH_NOT_INITIATED);
+
 	/* set_stream of CSI */
 	pad = media_entity_remote_pad(&chan->pad);
 	if (!pad)
@@ -1812,9 +1882,8 @@ int tegra_channel_init_subdevices(struct tegra_channel *chan)
 	/* verify if the immediate subdevice is slvsec */
 	chan->is_slvsec = (strstr(sd->name, "slvs") != NULL) ? 1 : 0;
 
-	/* Add subdev name to this video dev name with vi-output tag*/
-	snprintf(chan->video->name, sizeof(chan->video->name), "%s, %s",
-		"vi-output", sd->name);
+	/* Add subdev name to this video dev name */
+  snprintf(chan->video->name, sizeof(chan->video->name), "%s", sd->name);
 	sd->grp_id = grp_id;
 	chan->grp_id = grp_id;
 	index = pad->index - 1;
@@ -1919,6 +1988,15 @@ tegra_channel_get_format(struct file *file, void *fh,
 	struct tegra_channel *chan = video_drvdata(file);
 	struct v4l2_pix_format *pix = &format->fmt.pix;
 
+  struct v4l2_subdev *sd = chan->subdev_on_csi;
+ struct v4l2_subdev_format fmt = {};
+ int ret;
+
+ ret = v4l2_subdev_call(sd, pad, get_fmt, NULL, &fmt);
+
+ tegra_channel_update_format(chan, fmt.format.width, fmt.format.height,
+   chan->fmtinfo->fourcc, &chan->fmtinfo->bpp, 0);
+
 	*pix = chan->format;
 
 	return 0;
@@ -1953,7 +2031,8 @@ __tegra_channel_try_format(struct tegra_channel *chan,
 	tegra_channel_fmt_align(chan, vfmt,
 				&pix->width, &pix->height, &pix->bytesperline);
 	pix->sizeimage = get_aligned_buffer_size(chan,
-			pix->bytesperline, pix->height);
+			pix->bytesperline,
+            pix->height);
 	if (chan->fmtinfo->fourcc == V4L2_PIX_FMT_NV16)
 		pix->sizeimage *= 2;
 
@@ -1969,6 +2048,21 @@ tegra_channel_try_format(struct file *file, void *fh,
 	return  __tegra_channel_try_format(chan, &format->fmt.pix);
 }
 
+static void tegra_channel_s_bypass_vi_dt_match(struct tegra_channel *chan, bool bypass)
+{
+ struct tegra_csi_device *csi = tegra_get_mc_csi();
+ struct tegra_csi_channel *csi_it;
+ int i = 0;
+
+ list_for_each_entry(csi_it, &csi->csi_chans, list) {
+   for (i = 0; i < chan->num_subdevs; i++)
+     if (chan->subdev[i] == &csi_it->subdev)
+       csi_it->bypass_dt = bypass;
+ }
+
+ chan->bypass_dt = bypass;
+}
+
 static int
 __tegra_channel_set_format(struct tegra_channel *chan,
 			struct v4l2_pix_format *pix)
@@ -1984,6 +2078,12 @@ __tegra_channel_set_format(struct tegra_channel *chan,
 	fmt.pad = 0;
 	v4l2_fill_mbus_format(&fmt.format, pix, vfmt->code);
 
+  if (chan->format.pixelformat == V4L2_PIX_FMT_CUSTOM) {
+    tegra_channel_s_bypass_vi_dt_match(chan, true);
+  } else {
+    tegra_channel_s_bypass_vi_dt_match(chan, false);
+  }
+
 	ret = v4l2_subdev_call(sd, pad, set_fmt, NULL, &fmt);
 	if (ret == -ENOIOCTLCMD)
 		return -ENOTTY;
@@ -2024,7 +2124,15 @@ tegra_channel_set_format(struct file *file, void *fh,
 	if (vb2_is_busy(&chan->queue))
 		return -EBUSY;
 
-	return __tegra_channel_set_format(chan, &format->fmt.pix);
+	ret = __tegra_channel_set_format(chan, &format->fmt.pix);
+ if (ret)
+   return ret;
+
+ if (chan->format.pixelformat == V4L2_PIX_FMT_CUSTOM)
+   chan->format.width = chan->format.width / 2;
+ ret = __tegra_channel_set_format(chan, &chan->format);
+
+ return ret;
 }
 
 static int tegra_channel_subscribe_event(struct v4l2_fh *fh,
@@ -2093,13 +2201,197 @@ static long tegra_channel_default_ioctl(struct file *file, void *fh,
 			bool use_prio, unsigned int cmd, void *arg)
 {
 	struct tegra_channel *chan = video_drvdata(file);
-	struct tegra_mc_vi *vi = chan->vi;
-	long ret = 0;
-
-	if (vi->fops && vi->fops->vi_default_ioctl)
-		ret = vi->fops->vi_default_ioctl(file, fh, use_prio, cmd, arg);
-
-	return ret;
+  struct v4l2_subdev *sd = chan->subdev_on_csi;
+  struct vb2_queue *q = &chan->queue;
+  struct video_device *vdev = chan->video;
+
+	switch(cmd) {
+  case VIDIOC_MEM_ALLOC: {
+    struct v4l2_dma_mem *mem = arg;
+    int ret = 0;
+    int count = 1;
+    int plane_size[1] = { 0 };
+
+   if (chan->queue.owner && chan->queue.owner != file->private_data)
+       return -EBUSY;
+
+   ret = vb2_core_create_single_buf(&chan->queue, mem->memory, &count, 1, plane_size, true, mem->index);
+   chan->queue.owner = file->private_data;
+   chan->created_bufs++;
+
+   if (ret < 0)
+     return ret;
+   return 0;
+
+   break;
+ }
+
+ case VIDIOC_MEM_FREE: {
+   struct v4l2_dma_mem *mem = arg;
+   int ret = 0;
+
+   if (chan->queue.owner && chan->queue.owner != file->private_data)
+       return -EBUSY;
+
+   ret = vb2_buffer_free(&chan->queue, mem->index);
+   if (ret < 0)
+         return ret;
+   chan->created_bufs = 0;
+   return 0;
+   break;
+ }
+
+ case VIDIOC_FLUSH_FRAMES: {
+   int i;
+   for (i = 0; i < q->num_buffers; ++i)
+     switch (q->bufs[i]->state) {
+     case VB2_BUF_STATE_PREPARED:
+     case VB2_BUF_STATE_QUEUED:
+     case VB2_BUF_STATE_ACTIVE:
+       /* The flags should be copied to the corresponding v4l2 buffer
+        * in __fill_v4l2_buffer */
+       to_vb2_v4l2_buffer(q->bufs[i])->flags |= V4L2_BUF_FLAG_UNUSED;
+       break;
+     default:
+       break;
+     }
+   update_flush_state(chan, FLUSH_IN_PROGRESS);
+   vb2_core_queue_cancel(q);
+   update_flush_state(chan, FLUSH_DONE);
+   sysfs_notify(&vdev->dev.kobj, NULL, "flush");
+   return 0;
+   break;
+ }
+
+ case VIDIOC_STREAMSTAT: {
+   struct v4l2_stats_t *stream_stats = arg;
+   chan->stream_stats.current_frame_count = 1;
+   *stream_stats = chan->stream_stats;
+   return 0;
+   break;
+ }
+
+ case VIDIOC_RESET_STREAMSTAT:
+   memset(&chan->stream_stats, 0x00, sizeof(struct v4l2_stats_t));
+   chan->qbuf_count = 0;
+   chan->dqbuf_count = 0;
+   return 0;
+   break;
+
+ case VIDIOC_STREAMON_EX: {
+   int ret = 0;
+
+   ret = vb2_core_streamon_ex(&chan->queue, chan->queue.type);
+
+   if (ret < 0)
+     return ret;
+
+   return 0;
+   break;
+ }
+
+ case VIDIOC_STREAMOFF_EX: {
+   struct v4l2_streamoff_ex *streamoff = arg;
+   int ret = 0;
+   unsigned long curr_timeout = chan->timeout;
+
+   chan->timeout = msecs_to_jiffies(streamoff->timeout);
+
+   ret = vb2_core_streamoff_ex(&chan->queue, chan->queue.type, streamoff->timeout);
+   sysfs_notify(&vdev->dev.kobj, NULL, "streamoff");
+
+   /* Get back to the default timeout value */
+   chan->timeout = curr_timeout;
+        /* Reset current values in order to reset the displayed current frame reate after stop*/
+        chan->stream_stats.current_frame_count = 0;
+        chan->stream_stats.current_frame_interval = 0;
+
+   return 0;
+   break;
+ }
+
+ case VIDIOC_G_STATISTICS_CAPABILITIES: {
+   struct v4l2_statistics_capabilities *statistics_capabilities = arg;
+   statistics_capabilities->statistics_capability = V4L2_STATISTICS_CAPABILITY_FrameCount |
+       V4L2_STATISTICS_CAPABILITY_FramesIncomplete |
+       V4L2_STATISTICS_CAPABILITY_PacketCRCError |
+       V4L2_STATISTICS_CAPABILITY_CurrentFrameInterval |
+       V4L2_STATISTICS_CAPABILITY_FramesUnderrun;
+   return 0;
+   break;
+ }
+
+ case VIDIOC_G_MIN_ANNOUNCED_FRAMES: {
+   struct v4l2_min_announced_frames *min_announced_frames = arg;
+   min_announced_frames->min_announced_frames = MIN_ANNOUNCED_FRAMES;
+   return 0;
+   break;
+ }
+
+ case VIDIOC_G_SUPPORTED_LANE_COUNTS: {
+
+   struct v4l2_supported_lane_counts *lane_counts = arg;
+
+   lane_counts->supported_lane_counts =
+     V4L2_LANE_COUNT_1_LaneSupport |
+     V4L2_LANE_COUNT_2_LaneSupport |
+     V4L2_LANE_COUNT_4_LaneSupport;
+
+   return 0;
+ }
+
+ case VIDIOC_G_CSI_HOST_CLK_FREQ: {
+   struct v4l2_csi_host_clock_freq_ranges *csi_clk_ranges = arg;
+
+   csi_clk_ranges->lane_range_1.is_valid =
+     csi_clk_ranges->lane_range_2.is_valid =
+     csi_clk_ranges->lane_range_4.is_valid = 1;
+   csi_clk_ranges->lane_range_1.min =
+     csi_clk_ranges->lane_range_2.min =
+     csi_clk_ranges->lane_range_4.min =
+         CSI_HOST_CLK_MIN_FREQ;
+   csi_clk_ranges->lane_range_1.max =
+     csi_clk_ranges->lane_range_2.max =
+     csi_clk_ranges->lane_range_4.max =
+         CSI_HOST_CLK_MAX_FREQ;
+
+   csi_clk_ranges->lane_range_3.is_valid = 0;
+   return 0;
+   break;
+ }
+
+ case VIDIOC_G_IPU_RESTRICTIONS: {
+   struct v4l2_ipu_restrictions *ipu_restrictions = arg;
+
+   ipu_restrictions->ipu_x.is_valid = 1;
+   ipu_restrictions->ipu_x.min   = FRAMESIZE_MIN_W;
+   ipu_restrictions->ipu_x.max   = FRAMESIZE_MAX_W;
+   ipu_restrictions->ipu_x.inc   = FRAMESIZE_INC_W;
+   ipu_restrictions->ipu_y.is_valid = 1;
+   ipu_restrictions->ipu_y.min   = FRAMESIZE_MIN_H;
+   ipu_restrictions->ipu_y.max   = FRAMESIZE_MAX_H;
+   ipu_restrictions->ipu_y.inc   = FRAMESIZE_INC_H;
+   return 0;
+   break;
+ }
+
+ case VIDIOC_G_SUPPORTED_DATA_IDENTIFIERS: {
+   struct v4l2_csi_data_identifiers_inq *data_ids = arg;
+
+   data_ids->data_identifiers_inq_1 = DATA_IDENTIFIER_INQ_1;
+   data_ids->data_identifiers_inq_2 = DATA_IDENTIFIER_INQ_2;
+   data_ids->data_identifiers_inq_3 = DATA_IDENTIFIER_INQ_3;
+   data_ids->data_identifiers_inq_4 = DATA_IDENTIFIER_INQ_4;
+   return 0;
+   break;
+ }
+
+ }
+
+ if (!v4l2_subdev_has_op(sd, core, ioctl))
+   return -ENOTTY;
+
+ return v4l2_subdev_call(sd, core, ioctl, cmd, arg);
 }
 
 #ifdef CONFIG_COMPAT
@@ -2125,6 +2417,205 @@ static long tegra_channel_compat_ioctl(struct file *filp,
 }
 #endif
 
+static int tegra_channel_vidioc_cropcap(struct file *file, void *fh,
+         struct v4l2_cropcap *a)
+{
+ struct tegra_channel *chan = video_drvdata(file);
+ struct v4l2_subdev *sd = chan->subdev_on_csi;
+
+ if (!v4l2_subdev_has_op(sd, video, cropcap))
+   return -ENOTTY;
+
+ return v4l2_subdev_call(sd, video, cropcap, a);
+}
+
+static int tegra_channel_vidioc_g_crop(struct file *file, void *fh,
+              struct v4l2_crop *a)
+{
+ struct tegra_channel *chan = video_drvdata(file);
+ struct v4l2_subdev *sd = chan->subdev_on_csi;
+
+ if (!v4l2_subdev_has_op(sd, video, g_crop))
+   return -ENOTTY;
+
+ return v4l2_subdev_call(sd, video, g_crop, a);
+}
+
+static int tegra_channel_vidioc_s_crop(struct file *file, void *fh,
+              const struct v4l2_crop *a)
+{
+ struct tegra_channel *chan = video_drvdata(file);
+ struct v4l2_subdev *sd = chan->subdev_on_csi;
+ struct v4l2_format format;
+ int retval;
+
+ if (!v4l2_subdev_has_op(sd, video, s_crop))
+   return -ENOTTY;
+
+ retval = v4l2_subdev_call(sd, video, s_crop, a);
+
+ (void) tegra_channel_get_format(file, fh, &format);
+
+ return retval;
+}
+
+
+static int tegra_channel_vidioc_g_selection(struct file *file, void *fh,
+             struct v4l2_selection *s)
+{
+ struct tegra_channel *chan = video_drvdata(file);
+ struct v4l2_subdev *sd = chan->subdev_on_csi;
+ struct v4l2_subdev_selection ss;
+ int retval;
+
+ if (!v4l2_subdev_has_op(sd, pad, get_selection))
+   return -ENOTTY;
+
+ if (s->type != V4L2_BUF_TYPE_VIDEO_CAPTURE)
+   return -EINVAL;
+
+ ss.target = s->target;
+ ss.flags = s->flags;
+ memcpy(&ss.r, &s->r, sizeof(struct v4l2_rect));
+
+ retval = v4l2_subdev_call(sd, pad, get_selection, NULL, &ss);
+
+ s->target = ss.target;
+ s->flags = ss.flags;
+ memcpy(&s->r, &ss.r, sizeof(struct v4l2_rect));
+
+ return retval;
+}
+
+static int tegra_channel_vidioc_s_selection(struct file *file, void *fh,
+             struct v4l2_selection *s)
+{
+ struct tegra_channel *chan = video_drvdata(file);
+ struct v4l2_subdev *sd = chan->subdev_on_csi;
+ struct v4l2_subdev_selection ss;
+ struct v4l2_format format;
+ int retval;
+
+ if (s->type != V4L2_BUF_TYPE_VIDEO_CAPTURE)
+   return -EINVAL;
+
+ if (!v4l2_subdev_has_op(sd, pad, set_selection))
+   return -ENOTTY;
+
+ ss.target = s->target;
+ ss.flags = s->flags;
+ memcpy(&ss.r, &s->r, sizeof(struct v4l2_rect));
+
+ retval = v4l2_subdev_call(sd, pad, set_selection, NULL, &ss);
+
+ (void) tegra_channel_get_format(file, fh, &format);
+
+ return retval;
+}
+
+static int tegra_channel_vidioc_g_parm(struct file *file, void *fh,
+            struct v4l2_streamparm *parm)
+{
+ struct tegra_channel *chan = video_drvdata(file);
+ struct v4l2_subdev *sd = chan->subdev_on_csi;
+
+ if (!v4l2_subdev_has_op(sd, video, g_parm))
+   return -ENOTTY;
+
+ return v4l2_subdev_call(sd, video, g_parm, parm);
+}
+
+static int tegra_channel_vidioc_s_parm(struct file *file, void *fh,
+            struct v4l2_streamparm *parm)
+{
+ struct tegra_channel *chan = video_drvdata(file);
+ struct v4l2_subdev *sd = chan->subdev_on_csi;
+
+ if (!v4l2_subdev_has_op(sd, video, s_parm))
+   return -ENOTTY;
+
+ return v4l2_subdev_call(sd, video, s_parm, parm);
+}
+
+int tegra_channel_ioctl_qbuf(struct file *file, void *priv, struct v4l2_buffer *p)
+{
+ struct tegra_channel *chan = video_drvdata(file);
+ int ret = 0;
+
+ ret = vb2_ioctl_qbuf(file, priv, p);
+
+ if (ret < 0)
+   return ret;
+
+ chan->qbuf_count++;
+
+ return 0;
+}
+
+int tegra_channel_ioctl_dqbuf(struct file *file, void *priv, struct v4l2_buffer *p)
+{
+ struct tegra_channel *chan = video_drvdata(file);
+ struct video_device *vdev = video_devdata(file);
+ int ret = 0;
+
+ ret = vb2_ioctl_dqbuf(file, priv, p);
+
+ /* The buffer error flag can be set even if ret == 0 */
+ if (vdev->queue->buffer_error) {
+   p->flags |= V4L2_BUF_FLAG_INVALID;
+ }
+
+ if (chan->incomplete_flag) {
+   p->flags |= V4L2_BUF_FLAG_INCOMPLETE;
+   chan->incomplete_flag = false;
+ }
+
+ if (ret < 0) {
+   return ret;
+ }
+
+ p->flags |= V4L2_BUF_FLAG_VALID;
+ chan->dqbuf_count++;
+
+ return 0;
+}
+
+int tegra_channel_streamoff(struct file *file, void *priv, enum v4l2_buf_type i)
+{
+ struct tegra_channel *chan = video_drvdata(file);
+ int ret;
+
+ ret = vb2_ioctl_streamoff(file, priv, i);
+ chan->pending_trigger = false;
+ return ret;
+}
+
+int tegra_channel_create_bufs(struct file *file, void *priv,
+             struct v4l2_create_buffers *p)
+{
+ int ret;
+ struct v4l2_format format = p->format;
+
+
+ ret = tegra_channel_try_format(file,priv,&format);
+ if (ret < 0)
+   return ret;
+
+ if (format.fmt.pix.width != p->format.fmt.pix.width)
+   return -EINVAL;
+
+ if (format.fmt.pix.height != p->format.fmt.pix.height)
+   return -EINVAL;
+
+ if (format.fmt.pix.bytesperline > p->format.fmt.pix.bytesperline)
+   return -EINVAL;
+
+ if (format.fmt.pix.sizeimage > p->format.fmt.pix.sizeimage)
+   return -EINVAL;
+
+ return vb2_ioctl_create_bufs(file,priv,p);
+}
+
 static const struct v4l2_ioctl_ops tegra_channel_ioctl_ops = {
 	.vidioc_querycap		= tegra_channel_querycap,
 	.vidioc_enum_framesizes		= tegra_channel_enum_framesizes,
@@ -2136,12 +2627,12 @@ static const struct v4l2_ioctl_ops tegra_channel_ioctl_ops = {
 	.vidioc_reqbufs			= vb2_ioctl_reqbufs,
 	.vidioc_prepare_buf		= vb2_ioctl_prepare_buf,
 	.vidioc_querybuf		= vb2_ioctl_querybuf,
-	.vidioc_qbuf			= vb2_ioctl_qbuf,
-	.vidioc_dqbuf			= vb2_ioctl_dqbuf,
-	.vidioc_create_bufs		= vb2_ioctl_create_bufs,
+	.vidioc_qbuf      = tegra_channel_ioctl_qbuf,
+  .vidioc_dqbuf     = tegra_channel_ioctl_dqbuf,
+  .vidioc_create_bufs   = tegra_channel_create_bufs,
 	.vidioc_expbuf			= vb2_ioctl_expbuf,
 	.vidioc_streamon		= vb2_ioctl_streamon,
-	.vidioc_streamoff		= vb2_ioctl_streamoff,
+	.vidioc_streamoff    = tegra_channel_streamoff,
 	.vidioc_g_edid			= tegra_channel_g_edid,
 	.vidioc_s_edid			= tegra_channel_s_edid,
 	.vidioc_s_dv_timings		= tegra_channel_s_dv_timings,
@@ -2156,6 +2647,13 @@ static const struct v4l2_ioctl_ops tegra_channel_ioctl_ops = {
 	.vidioc_s_input			= tegra_channel_s_input,
 	.vidioc_log_status		= tegra_channel_log_status,
 	.vidioc_default			= tegra_channel_default_ioctl,
+  .vidioc_cropcap      = tegra_channel_vidioc_cropcap,
+  .vidioc_g_crop      = tegra_channel_vidioc_g_crop,
+  .vidioc_s_crop      = tegra_channel_vidioc_s_crop,
+  .vidioc_s_selection   = tegra_channel_vidioc_s_selection,
+  .vidioc_g_selection   = tegra_channel_vidioc_g_selection,
+  .vidioc_g_parm      = tegra_channel_vidioc_g_parm,
+  .vidioc_s_parm      = tegra_channel_vidioc_s_parm,
 };
 
 static int tegra_channel_close(struct file *fp);
@@ -2167,6 +2665,27 @@ static int tegra_channel_open(struct file *fp)
 	struct tegra_mc_vi *vi;
 	struct tegra_csi_device *csi;
 
+  struct v4l2_subdev *sd;
+ struct v4l2_subdev_fh* subdev_fh;
+ struct camera_list_entry *cam_new_entry, *cam_iter_entry;
+ struct list_head *cam_list_head_iter;
+ struct v4l2_format format;
+
+ /* Multiple opens not allowed */
+
+ // check if camera has already been opened
+ list_for_each(cam_list_head_iter, &camera_list) {
+   cam_iter_entry = list_entry(cam_list_head_iter, struct camera_list_entry, camera_list_head);
+   if(cam_iter_entry->channel_id == chan->id && chan->avt_cam_mode) {
+     return -EBUSY;
+   }
+ }
+
+ // create list entry
+ cam_new_entry = kmalloc(sizeof(struct camera_list_entry), GFP_KERNEL);
+ cam_new_entry->channel_id = chan->id;
+ list_add(&cam_new_entry->camera_list_head, &camera_list);
+
 	trace_tegra_channel_open(vdev->name);
 	mutex_lock(&chan->video_lock);
 	ret = v4l2_fh_open(fp);
@@ -2185,6 +2704,20 @@ static int tegra_channel_open(struct file *fp)
 
 	chan->fh = (struct v4l2_fh *)fp->private_data;
 
+  subdev_fh = to_v4l2_subdev_fh(chan->fh);
+
+ // call open callback in subdevice
+ sd = chan->subdev_on_csi;
+
+ if (sd->internal_ops && sd->internal_ops->open) {
+   ret = sd->internal_ops->open(sd, subdev_fh);
+   if (ret < 0)
+     goto fail;
+ }
+
+ // dummy call to call tegra_channel_update_format
+ tegra_channel_get_format(fp, chan->fh, &format);
+
 	if (tegra_channel_verify_focuser(chan)) {
 		ret = tegra_channel_set_power(chan, true);
 		if (ret < 0)
@@ -2207,13 +2740,32 @@ static int tegra_channel_close(struct file *fp)
 	struct video_device *vdev = video_devdata(fp);
 	struct tegra_channel *chan = video_drvdata(fp);
 	struct tegra_mc_vi *vi = chan->vi;
+  struct v4l2_subdev *sd = chan->subdev_on_csi;
+
 	bool is_singular;
+  struct camera_list_entry *cam_entry_to_delete = NULL, *cam_iter_entry;
+ struct list_head *cam_list_head_iter;
+ int was_streaming = atomic_read(&chan->is_streaming);
+ bool was_owner = chan->queue.owner == fp->private_data;
+
+ // get the list entry for this camera
+ list_for_each(cam_list_head_iter, &camera_list) {
+   cam_iter_entry = list_entry(cam_list_head_iter, struct camera_list_entry, camera_list_head);
+   if(cam_iter_entry->channel_id == chan->id) {
+     cam_entry_to_delete = cam_iter_entry;
+   }
+ }
 
 	trace_tegra_channel_close(vdev->name);
 	mutex_lock(&chan->video_lock);
 	is_singular = v4l2_fh_is_singular_file(fp);
 	ret = _vb2_fop_release(fp, NULL);
 
+  if (was_owner && was_streaming && chan->avt_cam_mode)
+ {
+   v4l2_subdev_call(sd,core,reset,0);
+ }
+
 	if (!is_singular) {
 		mutex_unlock(&chan->video_lock);
 		return ret;
@@ -2226,6 +2778,19 @@ static int tegra_channel_close(struct file *fp)
 	}
 
 	mutex_unlock(&chan->video_lock);
+
+   // delete entry from list
+ if(cam_entry_to_delete) {
+   list_del(&cam_entry_to_delete->camera_list_head);
+   kfree(cam_entry_to_delete);
+ }
+
+    if (chan->format.pixelformat == V4L2_PIX_FMT_CUSTOM)
+    {
+        struct v4l2_format format;
+        format.fmt.pix = chan->prev_format;
+        tegra_channel_set_format(fp,NULL,&format);
+    }
 	return ret;
 }
 
@@ -2390,6 +2955,11 @@ int tegra_channel_init(struct tegra_channel *chan)
 	/* Init bpl factor to 1, will be overidden based on interlace_type */
 	chan->interlace_bplfactor = 1;
 
+  chan->trigger_mode = false;
+ chan->pending_trigger = false;
+ chan->avt_cam_mode = 0;
+
+
 #if defined(CONFIG_VIDEOBUF2_DMA_CONTIG)
 	/* get the buffers queue... */
 	ret = tegra_vb2_dma_init(vi->dev, &chan->alloc_ctx,
@@ -2410,6 +2980,8 @@ int tegra_channel_init(struct tegra_channel *chan)
 #endif
 	chan->queue.timestamp_flags = V4L2_BUF_FLAG_TIMESTAMP_MONOTONIC
 				   | V4L2_BUF_FLAG_TSTAMP_SRC_EOF;
+
+  chan->queue.min_buffers_needed = 1;
 	ret = vb2_queue_init(&chan->queue);
 	if (ret < 0) {
 		dev_err(chan->vi->dev, "failed to initialize VB2 queue\n");
@@ -2423,6 +2995,10 @@ int tegra_channel_init(struct tegra_channel *chan)
 		goto deskew_ctx_err;
 	}
 
+  chan->incomplete_flag = false;
+  chan->timeout = msecs_to_jiffies(CAPTURE_TIMEOUT_MS);
+  chan->created_bufs = 0;
+
 	chan->init_done = true;
 
 	return 0;
diff --git a/nvidia/drivers/media/platform/tegra/camera/vi/graph.c b/nvidia/drivers/media/platform/tegra/camera/vi/graph.c
index 6c14896add90..f4e243584f65 100644
--- a/nvidia/drivers/media/platform/tegra/camera/vi/graph.c
+++ b/nvidia/drivers/media/platform/tegra/camera/vi/graph.c
@@ -410,6 +410,22 @@ static int tegra_vi_graph_notify_complete(struct v4l2_async_notifier *notifier)
 
 	chan->link_status++;
 
+	if (chan->subdev_on_csi->flags & V4L2_SUBDEV_FL_IS_I2C) {
+		struct i2c_client *client = v4l2_get_subdevdata(chan->subdev_on_csi);
+		/* libcsi library requires this format,
+		 * hence doubled adapter number
+		 */
+		sprintf(chan->video->bus_info, "%d:%d:%x",
+				client->adapter->nr,
+				client->adapter->nr,
+				client->addr);
+	}
+
+	/* libcsi library requires interface with number 1,
+	 * this may be subject to change in future
+	 */
+	sprintf(chan->video->if_name, "avt_csi2_if%d", chan->port[0] + 1);
+
 	return 0;
 
 graph_error:
diff --git a/nvidia/drivers/media/platform/tegra/camera/vi/vi2_fops.c b/nvidia/drivers/media/platform/tegra/camera/vi/vi2_fops.c
index 2efb40c2b1a0..fa49eed37228 100644
--- a/nvidia/drivers/media/platform/tegra/camera/vi/vi2_fops.c
+++ b/nvidia/drivers/media/platform/tegra/camera/vi/vi2_fops.c
@@ -142,9 +142,9 @@ static int vi2_add_ctrls(struct tegra_channel *chan)
 static int vi2_channel_setup_queue(struct tegra_channel *chan,
 	unsigned int *nbuffers)
 {
-	/* Make sure minimum number of buffers are passed */
-	if (*nbuffers < (QUEUED_BUFFERS - 1))
-		*nbuffers = QUEUED_BUFFERS - 1;
+	if (*nbuffers < QUEUED_BUFFERS - 1) {
+		return tegra_channel_alloc_buffer_queue(chan, *nbuffers + 1);
+	}
 
 	return tegra_channel_alloc_buffer_queue(chan, QUEUED_BUFFERS);
 }
@@ -176,6 +176,11 @@ static int tegra_channel_capture_setup(struct tegra_channel *chan)
 	u32 bypass_pixel_transform = 1;
 	int index;
 
+    //DLA: Multiple width by 2 to revert the division by 2 from channel.c(2072)
+    if (chan->format.pixelformat == V4L2_PIX_FMT_CUSTOM){
+        width *= 2;
+    }
+
 	if (chan->valid_ports > 1) {
 		height = chan->gang_height;
 		width = chan->gang_width;
@@ -226,7 +231,6 @@ static void tegra_channel_ec_init(struct tegra_channel *chan)
 	 * Time limit allow CSI to capture good frames and drop error frames
 	 * TODO: Get frame rate from sub-device and adopt timeout
 	 */
-	chan->timeout = msecs_to_jiffies(200);
 
 	/*
 	 * Sync point FIFO full blocks host interface
@@ -303,8 +307,7 @@ static void tegra_channel_vi_csi_recover(struct tegra_channel *chan)
 		csi->fops->csi_start_streaming(csi_chan, index);
 		nvhost_syncpt_set_min_eq_max_ext(chan->vi->ndev,
 						chan->syncpt[index][0]);
-		if (chan->low_latency)
-			nvhost_syncpt_set_min_eq_max_ext(chan->vi->ndev,
+        nvhost_syncpt_set_min_eq_max_ext(chan->vi->ndev,
 						chan->syncpt[index][1]);
 	}
 }
@@ -351,12 +354,25 @@ static int tegra_channel_error_status(struct tegra_channel *chan)
 		/* Ignore error based on resolution but reset status */
 		val = csi_read(chan, index, TEGRA_VI_CSI_ERROR_STATUS);
 		csi_write(chan, index, TEGRA_VI_CSI_ERROR_STATUS, val);
-		err = tegra_csi_error(csi_chan, index);
+
+        if (val) {
+            dev_dbg(chan->vi->dev, "%s:error %x frame %d\n",
+                    __func__, val, chan->sequence);
+        }
+
+        err = tegra_csi_error(csi_chan, index);
+
+        if (err & TEGRA_CSI_PIXEL_PARSER_PL_CRC_ERR) {
+            chan->stream_stats.packet_crc_error++;
+        }
+
+        if (err) {
+            dev_dbg(chan->vi->dev, "%s:error %x frame %d\n",
+                    __func__, err, chan->sequence);
+        }
 	}
 
-	if (err)
-		dev_err(chan->vi->dev, "%s:error %x frame %d\n",
-				__func__, err, chan->sequence);
+
 	return err;
 }
 
@@ -367,10 +383,11 @@ static int tegra_channel_capture_frame_single_thread(
 	struct vb2_v4l2_buffer *vb = &buf->buf;
 	struct timespec ts;
 	int err = 0;
-	u32 val, frame_start;
+	u32 val, frame_start, mw_ack_done;
 	int bytes_per_line = chan->format.bytesperline;
 	int index = 0;
-	u32 thresh[TEGRA_CSI_BLOCKS] = { 0 };
+	u32 start_thresh[TEGRA_CSI_BLOCKS] = { 0 };
+    u32 release_thresh[TEGRA_CSI_BLOCKS] = { 0 };
 	int valid_ports = chan->valid_ports;
 	int state = VB2_BUF_STATE_DONE;
 
@@ -401,19 +418,24 @@ static int tegra_channel_capture_frame_single_thread(
 				TEGRA_VI_CSI_SURFACE1_STRIDE, bytes_per_line);
 		}
 
-		/* Program syncpoints */
-		thresh[index] = nvhost_syncpt_incr_max_ext(chan->vi->ndev,
-					chan->syncpt[index][0], 1);
-		/* Do not arm sync points if FIFO had entries before */
-		if (!chan->syncpoint_fifo[index][0]) {
-			frame_start = VI_CSI_PP_FRAME_START(chan->port[index]);
-			val = VI_CFG_VI_INCR_SYNCPT_COND(frame_start) |
-				chan->syncpt[index][0];
-			tegra_channel_write(chan,
-				TEGRA_VI_CFG_VI_INCR_SYNCPT, val);
-		} else
-			chan->syncpoint_fifo[index][0]--;
-	}
+        /* Program syncpoints */
+        start_thresh[index] = nvhost_syncpt_incr_max_ext(chan->vi->ndev, chan->syncpt[index][0], 1);
+        release_thresh[index] = nvhost_syncpt_incr_max_ext(chan->vi->ndev, chan->syncpt[index][1], 1);
+
+
+
+        /* Do not arm sync points if FIFO had entries before */
+        if (!chan->syncpoint_fifo[index][0]) {
+            frame_start = VI_CSI_PP_FRAME_START(chan->port[index]);
+            val = VI_CFG_VI_INCR_SYNCPT_COND(frame_start) | chan->syncpt[index][0];
+            tegra_channel_write(chan, TEGRA_VI_CFG_VI_INCR_SYNCPT, val);
+
+            mw_ack_done = VI_CSI_MW_ACK_DONE(chan->port[index]);
+            val = VI_CFG_VI_INCR_SYNCPT_COND(mw_ack_done) | chan->syncpt[index][1];
+            tegra_channel_write(chan, TEGRA_VI_CFG_VI_INCR_SYNCPT, val);
+        } else
+            chan->syncpoint_fifo[index][0]--;
+    }
 
 	/* enable input stream once the VI registers are configured */
 	if (!chan->bfirst_fstart) {
@@ -438,25 +460,36 @@ static int tegra_channel_capture_frame_single_thread(
 		csi_write(chan, index,
 			TEGRA_VI_CSI_SINGLE_SHOT, SINGLE_SHOT_CAPTURE);
 
-	chan->capture_state = CAPTURE_GOOD;
-	for (index = 0; index < valid_ports; index++) {
-		err = nvhost_syncpt_wait_timeout_ext(chan->vi->ndev,
-			chan->syncpt[index][0], thresh[index],
-			chan->timeout, NULL, &ts);
-		if (err) {
-			dev_err(&chan->video->dev,
-				"frame start syncpt timeout!%d\n", index);
-			state = VB2_BUF_STATE_REQUEUEING;
-			/* perform error recovery for timeout */
-			tegra_channel_ec_recover(chan);
-			chan->capture_state = CAPTURE_TIMEOUT;
-			break;
-		}
-	}
 
-	getrawmonotonic(&ts);
+    chan->capture_state = CAPTURE_GOOD;
+    for (index = 0; index < valid_ports; index++) {
+
+        err = nvhost_syncpt_wait_timeout_ext(chan->vi->ndev,
+                                             chan->syncpt[index][0], start_thresh[index],
+                                             chan->timeout, NULL, &ts);
 
-	if (!err && !chan->pg_mode) {
+        if (err == -ECANCELED) {
+            dev_dbg(&chan->video->dev,
+                    "frame SOF syncpt cancelled!\n");
+
+            state = VB2_BUF_STATE_ERROR;
+            goto capture_end;
+        }
+        else if (err) {
+            dev_err(&chan->video->dev,
+                    "frame SOF syncpt timeout!\n");
+
+            tegra_channel_error_status(chan);
+
+            state = VB2_BUF_STATE_REQUEUEING;
+            /* perform error recovery for timeout */
+            tegra_channel_ec_recover(chan);
+            chan->capture_state = CAPTURE_TIMEOUT;
+            goto capture_end;
+        }
+    }
+
+	if (!chan->pg_mode) {
 		/* Marking error frames and resume capture */
 		/* TODO: TPG has frame height short error always set */
 		err = tegra_channel_error_status(chan);
@@ -464,11 +497,49 @@ static int tegra_channel_capture_frame_single_thread(
 			state = VB2_BUF_STATE_REQUEUEING;
 			chan->capture_state = CAPTURE_ERROR;
 			/* do we have to run recover here ?? */
-			/* tegra_channel_ec_recover(chan); */
+            tegra_channel_ec_recover(chan);
+
+            goto capture_end;
 		}
 	}
 
-	set_timestamp(buf, &ts);
+    for (index = 0; index < valid_ports; index++) {
+        err = nvhost_syncpt_wait_timeout_ext(chan->vi->ndev,
+                                             chan->syncpt[index][1], release_thresh[index],
+                                             500, NULL, &ts);
+
+        if (err) {
+            dev_err(&chan->video->dev,
+                    "frame EOF syncpt timeout!%d\n", index);
+
+            tegra_channel_error_status(chan);
+
+            state = VB2_BUF_STATE_REQUEUEING;
+            /* perform error recovery for timeout */
+            tegra_channel_ec_recover(chan);
+            chan->capture_state = CAPTURE_TIMEOUT;
+
+            goto capture_end;
+        }
+    }
+
+    if (!chan->pg_mode) {
+        /* Marking error frames and resume capture */
+        /* TODO: TPG has frame height short error always set */
+        err = tegra_channel_error_status(chan);
+        if (err) {
+            state = VB2_BUF_STATE_REQUEUEING;
+            chan->capture_state = CAPTURE_ERROR;
+            /* do we have to run recover here ?? */
+            tegra_channel_ec_recover(chan);
+        }
+    }
+
+capture_end:
+    getrawmonotonic(&ts);
+
+    set_timestamp(buf, &ts);
+    tegra_channel_update_statistics(chan);
 	tegra_channel_ring_buffer(chan, vb, &ts, state);
 	trace_tegra_channel_capture_frame("sof", ts);
 	return 0;
@@ -573,6 +644,11 @@ static int tegra_channel_capture_frame_multi_thread(
 	up_read(&chan->reset_lock);
 
 	chan->capture_state = CAPTURE_GOOD;
+	for (index = 0; index < valid_ports; index++) {
+		nvhost_syncpt_remember_stream_id_ext(chan->vi->ndev,
+			chan->syncpt[index][0]);
+	}
+
 	getrawmonotonic(&ts);
 	set_timestamp(buf, &ts);
 
@@ -674,110 +750,6 @@ static int tegra_channel_kthread_release(void *data)
 	return 0;
 }
 
-static void tegra_channel_capture_done(struct tegra_channel *chan)
-{
-	struct timespec ts;
-	int index, err;
-	int bytes_per_line = chan->format.bytesperline;
-	u32 val, mw_ack_done;
-	u32 thresh[TEGRA_CSI_BLOCKS] = { 0 };
-	struct tegra_channel_buffer *buf;
-	int state = VB2_BUF_STATE_DONE;
-
-	/* dequeue buffer and return if no buffer exists */
-	buf = dequeue_buffer(chan, !chan->low_latency);
-	if (!buf)
-		return;
-
-	for (index = 0; index < chan->valid_ports; index++) {
-		/* Program buffer address by using surface 0 */
-		csi_write(chan, index, TEGRA_VI_CSI_SURFACE0_OFFSET_MSB,
-			((u64)buf->addr + chan->buffer_offset[index]) >> 32);
-		csi_write(chan, index, TEGRA_VI_CSI_SURFACE0_OFFSET_LSB,
-			(buf->addr + chan->buffer_offset[index]));
-		csi_write(chan, index,
-			TEGRA_VI_CSI_SURFACE0_STRIDE, bytes_per_line);
-
-		if (chan->fmtinfo->fourcc == V4L2_PIX_FMT_NV16) {
-			/*
-			 * Program surface 1 for UV plane,
-			 * with offset sizeimage from Y plane
-			 */
-			csi_write(chan, index,
-				TEGRA_VI_CSI_SURFACE1_OFFSET_MSB,
-				((u64)buf->addr + chan->format.sizeimage / 2 +
-				chan->buffer_offset[index]) >> 32);
-			csi_write(chan, index,
-				TEGRA_VI_CSI_SURFACE1_OFFSET_LSB,
-				(buf->addr + chan->format.sizeimage / 2 +
-				chan->buffer_offset[index]));
-			csi_write(chan, index,
-				TEGRA_VI_CSI_SURFACE1_STRIDE, bytes_per_line);
-		}
-
-		if (chan->low_latency) {
-			/* Program syncpoints */
-			thresh[index] = nvhost_syncpt_incr_max_ext(
-				chan->vi->ndev,
-				chan->syncpt[index][1], 1);
-			mw_ack_done = VI_CSI_MW_ACK_DONE(chan->port[index]);
-			val = VI_CFG_VI_INCR_SYNCPT_COND(mw_ack_done) |
-				chan->syncpt[index][1];
-		} else {
-			/* Program syncpoints */
-			thresh[index] = nvhost_syncpt_incr_max_ext(
-				chan->vi->ndev,
-				chan->syncpt[index][0], 1);
-			mw_ack_done = VI_CSI_MW_ACK_DONE(chan->port[index]);
-			val = VI_CFG_VI_INCR_SYNCPT_COND(mw_ack_done) |
-				chan->syncpt[index][0];
-		}
-
-		tegra_channel_write(chan, TEGRA_VI_CFG_VI_INCR_SYNCPT, val);
-		if (!csi_read(chan, index, TEGRA_VI_CSI_SINGLE_SHOT)) {
-			csi_write(chan, index,
-				TEGRA_VI_CSI_SINGLE_SHOT, SINGLE_SHOT_CAPTURE);
-		} else {
-			dev_dbg(&chan->video->dev,
-				"Syncpoint already enabled at capture done!%d\n", index);
-		}
-	}
-
-	for (index = 0; index < chan->valid_ports; index++) {
-		if (chan->low_latency) {
-			err = nvhost_syncpt_wait_timeout_ext(chan->vi->ndev,
-				chan->syncpt[index][1], thresh[index],
-				chan->timeout, NULL, &ts);
-		} else {
-			err = nvhost_syncpt_wait_timeout_ext(chan->vi->ndev,
-				chan->syncpt[index][0], thresh[index],
-				chan->timeout, NULL, &ts);
-		}
-		if (err) {
-			dev_err(&chan->video->dev,
-				"%s: MW_ACK_DONE syncpoint time out!%d\n",
-				__func__, index);
-			state = VB2_BUF_STATE_REQUEUEING;
-			/* perform error recovery for timeout */
-			tegra_channel_ec_recover(chan);
-			chan->capture_state = CAPTURE_TIMEOUT;
-			break;
-		}
-	}
-
-	set_timestamp(buf, &ts);
-	/* Mark capture state to IDLE as capture is finished */
-	chan->capture_state = CAPTURE_IDLE;
-
-	if (chan->low_latency) {
-		buf->state = VB2_BUF_STATE_DONE;
-		release_buffer(chan, buf);
-	} else
-		tegra_channel_ring_buffer(chan, &buf->buf, &ts, state);
-
-	trace_tegra_channel_capture_done("mw_ack_done", ts);
-}
-
 static int tegra_channel_kthread_capture_start(void *data)
 {
 	struct tegra_channel *chan = data;
@@ -867,17 +839,15 @@ static int vi2_channel_start_streaming(struct vb2_queue *vq, u32 count)
 	/* Find connected csi_channel */
 	csi_chan = find_linked_csi_channel(chan, csi);
 
-	if (!csi_chan)
+    if (!csi_chan)
 		goto error_set_stream;
 	for (i = 0; i < chan->valid_ports; i++) {
 		/* csi2_start_streaming(csi_chan, i); */
 		/* ensure sync point state is clean */
 		nvhost_syncpt_set_min_eq_max_ext(chan->vi->ndev,
 							chan->syncpt[i][0]);
-		if (chan->low_latency) {
-			nvhost_syncpt_set_min_eq_max_ext(chan->vi->ndev,
-						chan->syncpt[i][1]);
-		}
+        nvhost_syncpt_set_min_eq_max_ext(chan->vi->ndev,
+                            chan->syncpt[i][1]);
 	}
 
 	/* Note: Program VI registers after TPG, sensors and CSI streaming */
@@ -939,16 +909,19 @@ static int vi2_channel_stop_streaming(struct vb2_queue *vq)
 {
 	struct tegra_channel *chan = vb2_get_drv_priv(vq);
 	int index;
-	bool is_streaming = atomic_read(&chan->is_streaming);
 	struct tegra_csi_channel *csi_chan = NULL;
 	struct tegra_csi_device *csi = chan->vi->csi;
 	int err = 0;
 
+	if (chan->avt_cam_mode || chan->trigger_mode) {
+		for (index = 0; index < chan->valid_ports; index++) {
+			nvhost_syncpt_stop_waiting_ext(chan->vi->ndev, chan->syncpt[index][0]);
+		}
+	}
+
 	if (!chan->bypass) {
 		tegra_channel_stop_kthreads(chan);
-		/* wait for last frame memory write ack */
-		if (!chan->low_latency && is_streaming && chan->capture_state == CAPTURE_GOOD)
-			tegra_channel_capture_done(chan);
+
 		if (!chan->low_latency) {
 			/* free all the ring buffers */
 			free_ring_buffers(chan, 0);
@@ -974,6 +947,13 @@ static int vi2_channel_stop_streaming(struct vb2_queue *vq)
 	}
 
 	tegra_channel_set_stream(chan, false);
+
+	if (chan->avt_cam_mode || chan->trigger_mode) {
+		for (index = 0; index < chan->valid_ports; index++) {
+			nvhost_syncpt_restart_waiting_ext(chan->vi->ndev, chan->syncpt[index][0]);
+		}
+	}
+
 	err = tegra_channel_write_blobs(chan);
 	if (err)
 		return err;
diff --git a/nvidia/drivers/media/platform/tegra/camera/vi/vi2_formats.h b/nvidia/drivers/media/platform/tegra/camera/vi/vi2_formats.h
index fed27b9bfe85..7ca6bb4ef475 100644
--- a/nvidia/drivers/media/platform/tegra/camera/vi/vi2_formats.h
+++ b/nvidia/drivers/media/platform/tegra/camera/vi/vi2_formats.h
@@ -68,11 +68,17 @@ enum tegra_image_format {
 };
 
 static const struct tegra_video_format vi2_video_formats[] = {
+	/* CUSTOM MIPI DATATYPE */
+    TEGRA_VIDEO_FORMAT(RAW8, 8, CUSTOM, 1, 1, T_L8,
+                ARB_DT2, CUSTOM, "0x31 MIPI DATATYPE"),
+
 	/* RAW 6: TODO */
 
 	/* RAW 7: TODO */
 
 	/* RAW 8 */
+	TEGRA_VIDEO_FORMAT(RAW8, 8, Y8_1X8, 1, 1, T_L8,
+				RAW8, GREY, "GREY 8"),
 	TEGRA_VIDEO_FORMAT(RAW8, 8, SRGGB8_1X8, 1, 1, T_L8,
 				RAW8, SRGGB8, "RGRG.. GBGB.."),
 	TEGRA_VIDEO_FORMAT(RAW8, 8, SGRBG8_1X8, 1, 1, T_L8,
@@ -83,6 +89,8 @@ static const struct tegra_video_format vi2_video_formats[] = {
 				RAW8, SBGGR8, "BGBG.. GRGR.."),
 
 	/* RAW 10 */
+	TEGRA_VIDEO_FORMAT(RAW10, 10, Y10_1X10, 2, 1, T_R16_I,
+				RAW10, Y10, "GREY 10"),
 	TEGRA_VIDEO_FORMAT(RAW10, 10, SRGGB10_1X10, 2, 1, T_R16_I,
 				RAW10, SRGGB10, "RGRG.. GBGB.."),
 	TEGRA_VIDEO_FORMAT(RAW10, 10, SGRBG10_1X10, 2, 1, T_R16_I,
@@ -92,13 +100,9 @@ static const struct tegra_video_format vi2_video_formats[] = {
 	TEGRA_VIDEO_FORMAT(RAW10, 10, SBGGR10_1X10, 2, 1, T_R16_I,
 				RAW10, SBGGR10, "BGBG.. GRGR.."),
 
-	/* RAW 10 Packed format */
-	TEGRA_VIDEO_FORMAT(RAW10, 10, XBGGR10P_3X10, 4, 3, T_X2Lc10Lb10La10,
-				RAW10, XBGGR10P, "BGBG.. GRGR.."),
-	TEGRA_VIDEO_FORMAT(RAW10, 10, XRGGB10P_3X10, 4, 3, T_X2Lc10Lb10La10,
-				RAW10, XRGGB10P, "RGRG.. GBGB.."),
-
 	/* RAW 12 */
+	TEGRA_VIDEO_FORMAT(RAW12, 12, Y12_1X12, 2, 1, T_R16_I,
+				RAW12, Y12, "GREY 12"),
 	TEGRA_VIDEO_FORMAT(RAW12, 12, SRGGB12_1X12, 2, 1, T_R16_I,
 				RAW12, SRGGB12, "RGRG.. GBGB.."),
 	TEGRA_VIDEO_FORMAT(RAW12, 12, SGRBG12_1X12, 2, 1, T_R16_I,
@@ -108,13 +112,34 @@ static const struct tegra_video_format vi2_video_formats[] = {
 	TEGRA_VIDEO_FORMAT(RAW12, 12, SBGGR12_1X12, 2, 1, T_R16_I,
 				RAW12, SBGGR12, "BGBG.. GRGR.."),
 
+	/* RGB444 */
+	TEGRA_VIDEO_FORMAT(RGB444, 16, RGB444_1X12, 2, 1, T_A4B4G4R4,
+				RGB444, ARGB444, "RGB-4-4-4"),
+
+	/* RGB565 */
+	TEGRA_VIDEO_FORMAT(RGB565, 16, RGB565_1X16, 2, 1, T_B5G6R5,
+				RGB565, RGB565, "RGB-5-6-5"),
+
 	/* RGB888 */
-	TEGRA_VIDEO_FORMAT(RGB888, 24, RGB888_1X24, 4, 1, T_A8R8G8B8,
-				RGB888, ABGR32, "BGRA-8-8-8-8"),
-	TEGRA_VIDEO_FORMAT(RGB888, 24, RGB888_1X32_PADHI, 4, 1, T_A8B8G8R8,
-				RGB888, RGB32, "RGB-8-8-8-8"),
+	TEGRA_VIDEO_FORMAT(RGB888, 24, RGB888_1X24, 4, 1, T_B8G8R8A8,
+				RGB888, XRGB32, "RGB-8-8-8"),
+	TEGRA_VIDEO_FORMAT(RGB888, 24, BGR888_1X24, 4, 1, T_A8R8G8B8,
+				RGB888, XBGR32, "BGR-8-8-8"),
+
+	/* RGB666 */
+	TEGRA_VIDEO_FORMAT(RGB666, 24, RGB666_1X18, 4, 1, T_A8B8G8R8,
+				RGB666, ABGR32, "BGRA-8-8-8-8"),
+
 
 	/* YUV422 */
+	TEGRA_VIDEO_FORMAT(YUV422, 16, UYVY8_2X8, 2, 1, T_U8_Y8__V8_Y8,
+				YUV422_8, UYVY, "YUV 4:2:2 UYVY"),
+	TEGRA_VIDEO_FORMAT(YUV422, 16, VYUY8_2X8, 2, 1, T_V8_Y8__U8_Y8,
+				YUV422_8, VYUY, "YUV 4:2:2 VYUY"),
+	TEGRA_VIDEO_FORMAT(YUV422, 16, YUYV8_2X8, 2, 1, T_Y8_U8__Y8_V8,
+				YUV422_8, YUYV, "YUV 4:2:2 YUYV"),
+	TEGRA_VIDEO_FORMAT(YUV422, 16, YVYU8_2X8, 2, 1, T_Y8_V8__Y8_U8,
+				YUV422_8, YVYU, "YUV 4:2:2 YVYU"),
 	TEGRA_VIDEO_FORMAT(YUV422, 16, UYVY8_1X16, 2, 1, T_U8_Y8__V8_Y8,
 				YUV422_8, UYVY, "YUV 4:2:2"),
 	TEGRA_VIDEO_FORMAT(YUV422, 16, VYUY8_1X16, 2, 1, T_V8_Y8__U8_Y8,
@@ -125,13 +150,5 @@ static const struct tegra_video_format vi2_video_formats[] = {
 				YUV422_8, YVYU, "YUV 4:2:2"),
 	TEGRA_VIDEO_FORMAT(YUV422, 16, UYVY8_1X16, 1, 1, T_Y8__V8U8_N422,
 				YUV422_8, NV16, "NV16"),
-	TEGRA_VIDEO_FORMAT(YUV422, 16, UYVY8_2X8, 2, 1, T_U8_Y8__V8_Y8,
-				YUV422_8, UYVY, "YUV 4:2:2 UYVY"),
-	TEGRA_VIDEO_FORMAT(YUV422, 16, VYUY8_2X8, 2, 1, T_V8_Y8__U8_Y8,
-				YUV422_8, VYUY, "YUV 4:2:2 VYUY"),
-	TEGRA_VIDEO_FORMAT(YUV422, 16, YUYV8_2X8, 2, 1, T_Y8_U8__Y8_V8,
-				YUV422_8, YUYV, "YUV 4:2:2 YUYV"),
-	TEGRA_VIDEO_FORMAT(YUV422, 16, YVYU8_2X8, 2, 1, T_Y8_V8__Y8_U8,
-				YUV422_8, YVYU, "YUV 4:2:2 YVYU"),
 };
 #endif
diff --git a/nvidia/drivers/media/platform/tegra/camera/vi/vi4_fops.c b/nvidia/drivers/media/platform/tegra/camera/vi/vi4_fops.c
index 5278a4d47f82..97e08697ec05 100644
--- a/nvidia/drivers/media/platform/tegra/camera/vi/vi4_fops.c
+++ b/nvidia/drivers/media/platform/tegra/camera/vi/vi4_fops.c
@@ -25,6 +25,8 @@
 #include "vi4_fops.h"
 #include <media/sensor_common.h>
 #include <trace/events/camera_common.h>
+#include <host1x/host1x.h>
+
 #define BPP_MEM		2
 #define MAX_VI_CHANNEL 12
 #define NUM_FIELDS_INTERLACED 2
@@ -140,10 +142,9 @@ static int vi4_add_ctrls(struct tegra_channel *chan)
 static int vi4_channel_setup_queue(struct tegra_channel *chan,
 	unsigned int *nbuffers)
 {
-	/* Make sure minimum number of buffers are passed */
-	if (*nbuffers < (QUEUED_BUFFERS - 1))
-		*nbuffers = QUEUED_BUFFERS - 1;
-
+	if (*nbuffers < QUEUED_BUFFERS - 1) {
+		return tegra_channel_alloc_buffer_queue(chan, *nbuffers + 1);
+	}
 	return tegra_channel_alloc_buffer_queue(chan, QUEUED_BUFFERS);
 }
 
@@ -173,7 +174,25 @@ static bool vi4_check_status(struct tegra_channel *chan)
 	return true;
 }
 
-static bool vi_notify_wait(struct tegra_channel *chan,
+static struct tegra_csi_channel *find_linked_csi_channel(
+	struct tegra_channel *chan, struct tegra_csi_device *csi)
+{
+	struct tegra_csi_channel *csi_it;
+	struct tegra_csi_channel *csi_chan = NULL;
+	int i;
+	/* Find connected csi_channel */
+	list_for_each_entry(csi_it, &csi->csi_chans, list) {
+		for (i = 0; i < chan->num_subdevs; i++) {
+			if (chan->subdev[i] == &csi_it->subdev) {
+				csi_chan = csi_it;
+				break;
+			}
+		}
+	}
+	return csi_chan;
+}
+
+static int vi_notify_wait(struct tegra_channel *chan,
 		struct tegra_channel_buffer *buf,
 		struct timespec *ts)
 {
@@ -207,13 +226,33 @@ static bool vi_notify_wait(struct tegra_channel *chan,
 	 * Use the syncpt max value we just set as threshold
 	 */
 	for (i = 0; i < chan->valid_ports; i++) {
-		err = nvhost_syncpt_wait_timeout_ext(chan->vi->ndev,
-				chan->syncpt[i][SOF_SYNCPT_IDX], thresh[i],
-				chan->timeout, NULL, NULL);
-		if (unlikely(err)) {
+		nvhost_syncpt_remember_stream_id_ext(chan->vi->ndev,
+				chan->syncpt[i][SOF_SYNCPT_IDX]);
+		nvhost_syncpt_remember_stream_id_ext(chan->vi->ndev,
+				chan->syncpt[i][FE_SYNCPT_IDX]);
+        if (chan->low_latency)
+        {
+            err = nvhost_syncpt_wait_timeout_ext(chan->vi->ndev,
+                chan->syncpt[i][SOF_SYNCPT_IDX], thresh[i],
+                chan->timeout, NULL, NULL);
+        }
+        else
+        {
+            err = nvhost_syncpt_wait_timeout_ext(chan->vi->ndev,
+                chan->syncpt[i][FE_SYNCPT_IDX], buf->thresh[i],
+                chan->timeout, NULL, NULL);
+        }
+
+        if (err == -ECANCELED) {
+            dev_dbg(chan->vi->dev,
+                    "PXL_SOF syncpt canceled! err = %d\n", err);
+
+            return err;
+        }
+		else if (unlikely(err)) {
 			dev_err(chan->vi->dev,
 				"PXL_SOF syncpt timeout! err = %d\n", err);
-			return false;
+			return -ETIMEDOUT;
 		} else {
 			struct vi_capture_status status;
 
@@ -237,7 +276,7 @@ static bool vi_notify_wait(struct tegra_channel *chan,
 		}
 	}
 
-	return true;
+	return 0;
 }
 
 static void tegra_channel_surface_setup(
@@ -347,7 +386,6 @@ static int tegra_channel_notify_enable(
 {
 	struct tegra_vi4_syncpts_req req;
 	int i, err;
-
 	chan->vnc_id[index] = -1;
 	for (i = 0; i < MAX_VI_CHANNEL; i++) {
 		chan->vnc[index] = vi_notify_channel_open(i);
@@ -383,7 +421,6 @@ static int tegra_channel_notify_enable(
 			chan->vi->ndev, chan->syncpt[index][SOF_SYNCPT_IDX]);
 		return -EFAULT;
 	}
-
 	nvhost_syncpt_set_min_eq_max_ext(
 		chan->vi->ndev, chan->syncpt[index][SOF_SYNCPT_IDX]);
 	nvhost_syncpt_set_min_eq_max_ext(
@@ -452,13 +489,30 @@ static int tegra_channel_notify_disable(
 	return ret;
 }
 
+static void vi4_bypass_datatype(struct tegra_channel *chan,
+		unsigned int index)
+{
+	u32 vnc_id = chan->vnc_id[index];
+	u32 data_type = chan->fmtinfo->img_dt;
+
+	if(chan->bypass_dt) {
+		vi4_channel_write(chan, vnc_id, MATCH_DATATYPE, 0x0);
+		vi4_channel_write(chan, vnc_id, DT_OVERRIDE,
+				DT_OVRD_EN | (data_type << OVRD_DT_SHIFT));
+	} else {
+		vi4_channel_write(chan, vnc_id, MATCH_DATATYPE,
+				((data_type << DATATYPE_SHIFT) & DATATYPE) |
+				DATATYPE_MASK);
+		vi4_channel_write(chan, vnc_id, DT_OVERRIDE, 0x0);
+	}
+}
+
 static int tegra_channel_capture_setup(struct tegra_channel *chan,
 		unsigned int index)
 {
 	u32 height = chan->format.height;
 	u32 width = chan->format.width;
 	u32 format = chan->fmtinfo->img_fmt;
-	u32 data_type = chan->fmtinfo->img_dt;
 	u32 csi_port = chan->port[index];
 	u32 stream = 1U << csi_port;
 	u32 virtual_ch = 1U << chan->virtual_channel;
@@ -489,11 +543,7 @@ static int tegra_channel_capture_setup(struct tegra_channel *chan,
 			VIRTUAL_CHANNEL)  |
 			VIRTUAL_CHANNEL_MASK);
 
-	vi4_channel_write(chan, vnc_id, MATCH_DATATYPE,
-			((data_type << DATATYPE_SHIFT) & DATATYPE) |
-			DATATYPE_MASK);
-
-	vi4_channel_write(chan, vnc_id, DT_OVERRIDE, 0x0);
+	vi4_bypass_datatype(chan, index);
 
 	vi4_channel_write(chan, vnc_id, MATCH_FRAMEID,
 			((0 << FRAMEID_SHIFT) & FRAMEID) | 0);
@@ -602,8 +652,13 @@ static int tegra_channel_capture_frame_single_thread(
 				CONTROL, SINGLESHOT | MATCH_STATE_EN);
 		}
 
+        err = vi_notify_wait(chan, buf, &ts);
+
 		/* wait for vi notifier events */
-		if (!vi_notify_wait(chan, buf, &ts)) {
+        if (err == -ECANCELED) {
+            state = VB2_BUF_STATE_ERROR;
+        }
+        else if (err) {
 			tegra_channel_error_recovery(chan);
 
 			state = VB2_BUF_STATE_REQUEUEING;
@@ -622,9 +677,12 @@ static int tegra_channel_capture_frame_single_thread(
 		spin_unlock_irqrestore(&chan->capture_state_lock, flags);
 	}
 
-	set_timestamp(buf, &ts);
-	tegra_channel_ring_buffer(chan, vb, &ts, state);
-	trace_tegra_channel_capture_frame("sof", ts);
+
+    set_timestamp(buf, &ts);
+    tegra_channel_update_statistics(chan);
+    tegra_channel_ring_buffer(chan, vb, &ts, state);
+    trace_tegra_channel_capture_frame("sof", ts);
+
 	return 0;
 }
 
@@ -709,6 +767,10 @@ static void tegra_channel_release_frame(struct tegra_channel *chan,
 	int i;
 	int err = 0;
 	int restart_version = 0;
+	struct tegra_csi_device *csi = tegra_get_mc_csi();
+	struct tegra_csi_channel *csi_chan;
+
+	csi_chan = find_linked_csi_channel(chan, csi);
 
 	buf->state = VB2_BUF_STATE_DONE;
 
@@ -735,12 +797,20 @@ static void tegra_channel_release_frame(struct tegra_channel *chan,
 				chan->syncpt[i][FE_SYNCPT_IDX],
 				buf->thresh[i],
 				chan->timeout, NULL, NULL);
-		if (unlikely(err))
-			dev_err(chan->vi->dev,
-				"ATOMP_FE syncpt timeout! err = %d\n", err);
-		else
+        if (err == -ECANCELED) {
+            dev_dbg(chan->vi->dev,
+                    "ATOMP_FE syncpt canceled! err = %d\n", err);
+        }
+        else if (unlikely(err)) {
+            dev_err(chan->vi->dev,
+                    "ATOMP_FE syncpt timeout! err = %d\n", err);
+        }
+        else {
 			dev_dbg(&chan->video->dev,
-			"%s: vi4 got EOF syncpt buf[%p]\n", __func__, buf);
+				"%s: vi4 got EOF syncpt buf[%p]\n", __func__, buf);
+			csi->fops->csi_check_status(csi_chan, i);
+			chan->stream_stats.packet_crc_error += csi_chan->packet_crc_error;
+		}
 	}
 
 	if (err) {
@@ -748,6 +818,7 @@ static void tegra_channel_release_frame(struct tegra_channel *chan,
 		atomic_inc(&chan->restart_version);
 	}
 
+    tegra_channel_update_statistics(chan);
 	release_buffer(chan, buf);
 }
 
@@ -804,13 +875,16 @@ static void tegra_channel_capture_done(struct tegra_channel *chan)
 	struct timespec ts;
 	struct tegra_channel_buffer *buf;
 	int state = VB2_BUF_STATE_DONE;
-	u32 thresh[TEGRA_CSI_BLOCKS];
-	int i, err;
+	int i;
+
+    return;
 
 	/* dequeue buffer and return if no buffer exists */
 	buf = dequeue_buffer(chan, !chan->low_latency);
 	if (!buf)
 		return;
+	if (chan->trigger_mode)
+		return;
 
 	/* make sure to read the last frame out before exit */
 	for (i = 0; i < chan->valid_ports; i++) {
@@ -820,47 +894,6 @@ static void tegra_channel_capture_done(struct tegra_channel *chan)
 			CONTROL, SINGLESHOT | MATCH_STATE_EN);
 	}
 
-	for (i = 0; i < chan->valid_ports; i++) {
-		/*
-		 * Increment syncpt for ATOMP_FE
-		 *
-		 * Increment and retrieve ATOMP_FE syncpt max value.
-		 * This value will be used to wait for next syncpt
-		 */
-		struct vi_capture_status status;
-		thresh[i] = nvhost_syncpt_incr_max_ext(chan->vi->ndev,
-					chan->syncpt[i][FE_SYNCPT_IDX], 1);
-
-		/* Wait for ATOMP_FE syncpt
-		 *
-		 * This is to make sure we don't exit the capture thread
-		 * before the last frame is done writing to memory
-		 */
-		err = nvhost_syncpt_wait_timeout_ext(chan->vi->ndev,
-					chan->syncpt[i][FE_SYNCPT_IDX],
-					thresh[i],
-					chan->timeout, NULL, NULL);
-		if (unlikely(err)) {
-			dev_err(chan->vi->dev, "ATOMP_FE syncpt timeout!\n");
-			break;
-		}
-
-		err = vi_notify_get_capture_status(chan->vnc[i],
-				chan->vnc_id[i],
-				thresh[i], &status);
-		if (unlikely(err)) {
-			dev_err(chan->vi->dev,
-					"no capture status! err = %d\n", err);
-			break;
-		}
-		ts = ns_to_timespec((s64)status.eof_ts);
-	}
-
-	if (err) {
-		tegra_channel_error_recovery(chan);
-		state = VB2_BUF_STATE_REQUEUEING;
-	}
-
 	set_timestamp(buf, &ts);
 	/* Mark capture state to IDLE as capture is finished */
 	chan->capture_state = CAPTURE_IDLE;
@@ -868,7 +901,10 @@ static void tegra_channel_capture_done(struct tegra_channel *chan)
 	if (chan->low_latency)
 		release_buffer(chan, buf);
 	else
+    {
+        tegra_channel_update_statistics(chan);
 		tegra_channel_ring_buffer(chan, &buf->buf, &ts, state);
+    }
 
 	trace_tegra_channel_capture_done("eof", ts);
 }
@@ -976,7 +1012,7 @@ static void tegra_channel_stop_kthreads(struct tegra_channel *chan)
 			if (!list_empty(&chan->release)) {
 				buf = dequeue_inflight(chan);
 				if (buf)
-					tegra_channel_release_frame(chan, buf);
+                    tegra_channel_release_frame(chan, buf);
 			}
 			kthread_stop(chan->kthread_release);
 			chan->kthread_release = NULL;
@@ -985,6 +1021,38 @@ static void tegra_channel_stop_kthreads(struct tegra_channel *chan)
 	mutex_unlock(&chan->stop_kthread_lock);
 }
 
+void vi4_csi_channel_off(struct tegra_channel *chan)
+{
+	struct tegra_mc_vi *vi;
+	vi = chan->vi;
+
+	if (atomic_dec_and_test(&chan->power_on_refcnt)) {
+		if (tegra_channel_set_power(chan, 0) < 0)
+			dev_err(vi->dev, "Failed to power off subdevices\n");
+	}
+}
+
+int vi4_csi_channel_on(struct tegra_channel *chan)
+{
+	int ret = 0;
+	struct tegra_mc_vi *vi;
+	vi = chan->vi;
+
+	if (atomic_read(&chan->power_on_refcnt) == 1) {
+		//skip channel power on, if it is already on
+		return 0;
+	}
+
+	if (atomic_add_return(1, &chan->power_on_refcnt) == 1) {
+		ret = tegra_channel_set_power(chan, 1);
+		if (ret < 0) {
+			dev_err(vi->dev, "Failed to power on subdevices\n");
+			return ret;
+		}
+	}
+	return 0;
+}
+
 static int vi4_channel_start_streaming(struct vb2_queue *vq, u32 count)
 {
 	struct tegra_channel *chan = vb2_get_drv_priv(vq);
@@ -1000,12 +1068,27 @@ static int vi4_channel_start_streaming(struct vb2_queue *vq, u32 count)
 	struct sensor_mode_properties *sensor_mode;
 	struct camera_common_data *s_data;
 	unsigned int emb_buf_size = 0;
+    struct v4l2_ctrl *low_latency_ctrl;
 
 #if LINUX_VERSION_CODE < KERNEL_VERSION(4, 9, 0)
 	ret = media_entity_pipeline_start(&chan->video->entity, pipe);
 	if (ret < 0)
 		goto error_pipeline_start;
 #endif
+    low_latency_ctrl = v4l2_ctrl_find(&chan->ctrl_handler,TEGRA_CAMERA_CID_LOW_LATENCY);
+
+    if (NULL != low_latency_ctrl)
+    {
+        v4l2_ctrl_s_ctrl(low_latency_ctrl,true);
+    }
+    else
+    {
+        dev_warn(chan->vi->dev,"Low latency ctrl not found!");
+    }
+
+	ret = vi4_csi_channel_on(chan);
+	if (ret < 0)
+		goto error_csi_channel_on;
 
 	if (chan->bypass) {
 		ret = tegra_channel_set_stream(chan, true);
@@ -1086,7 +1169,6 @@ static int vi4_channel_start_streaming(struct vb2_queue *vq, u32 count)
 	}
 
 	chan->sequence = 0;
-	chan->timeout = msecs_to_jiffies(200);
 	if (!chan->low_latency)
 		tegra_channel_init_ring_buffer(chan);
 
@@ -1129,6 +1211,7 @@ static int vi4_channel_start_streaming(struct vb2_queue *vq, u32 count)
 	media_entity_pipeline_stop(&chan->video->entity);
 error_pipeline_start:
 #endif
+error_csi_channel_on:
 	vq->start_streaming_called = 0;
 	tegra_channel_queued_buf_done(chan, VB2_BUF_STATE_QUEUED,
 		chan->low_latency);
@@ -1151,10 +1234,17 @@ static int vi4_channel_stop_streaming(struct vb2_queue *vq)
 	cancel_work_sync(&chan->status_work);
 	cancel_work_sync(&chan->error_work);
 
+	if (chan->avt_cam_mode || chan->trigger_mode) {
+		for (i = 0; i < chan->valid_ports; i++) {
+			nvhost_syncpt_stop_waiting_ext(chan->vi->ndev, chan->syncpt[i][SOF_SYNCPT_IDX]);
+			nvhost_syncpt_stop_waiting_ext(chan->vi->ndev, chan->syncpt[i][FE_SYNCPT_IDX]);
+		}
+	}
+
 	if (!chan->bypass) {
 		tegra_channel_stop_kthreads(chan);
 		/* wait for last frame memory write ack */
-		if (is_streaming && chan->capture_state == CAPTURE_GOOD)
+		if (is_streaming && chan->capture_state == CAPTURE_GOOD && !chan->avt_cam_mode)
 			tegra_channel_capture_done(chan);
 		for (i = 0; i < chan->valid_ports; i++) {
 			vi4_channel_write(chan, chan->vnc_id[i], CONTROL, 0);
@@ -1170,9 +1260,17 @@ static int vi4_channel_stop_streaming(struct vb2_queue *vq)
 		tegra_channel_queued_buf_done(chan, VB2_BUF_STATE_ERROR,
 			chan->low_latency);
 	}
+	vi4_csi_channel_off(chan);
 
 	tegra_channel_set_stream(chan, false);
 
+	if (chan->avt_cam_mode || chan->trigger_mode) {
+		for (i = 0; i < chan->valid_ports; i++) {
+			nvhost_syncpt_restart_waiting_ext(chan->vi->ndev, chan->syncpt[i][SOF_SYNCPT_IDX]);
+			nvhost_syncpt_restart_waiting_ext(chan->vi->ndev, chan->syncpt[i][FE_SYNCPT_IDX]);
+		}
+	}
+
 	err = tegra_channel_write_blobs(chan);
 	if (err < 0)
 		return err;
diff --git a/nvidia/drivers/media/platform/tegra/camera/vi/vi4_formats.h b/nvidia/drivers/media/platform/tegra/camera/vi/vi4_formats.h
index de33c42fbf79..f37d63f0372f 100644
--- a/nvidia/drivers/media/platform/tegra/camera/vi/vi4_formats.h
+++ b/nvidia/drivers/media/platform/tegra/camera/vi/vi4_formats.h
@@ -86,7 +86,13 @@ static const struct tegra_video_format vi4_video_formats[] = {
 
 	/* RAW 7: TODO */
 
+	/* CUSTOM MIPI DATATYPE */
+	TEGRA_VIDEO_FORMAT(RAW8, 32, CUSTOM, 1, 1, T_U8_Y8__V8_Y8,
+				YUV422_8, CUSTOM, "0x31 MIPI DATATYPE"),
+
 	/* RAW 8 */
+	TEGRA_VIDEO_FORMAT(RAW8, 8, Y8_1X8, 1, 1, T_L8,
+				RAW8, GREY, "GREY 8"),
 	TEGRA_VIDEO_FORMAT(RAW8, 8, SRGGB8_1X8, 1, 1, T_L8,
 				RAW8, SRGGB8, "RGRG.. GBGB.."),
 	TEGRA_VIDEO_FORMAT(RAW8, 8, SGRBG8_1X8, 1, 1, T_L8,
@@ -97,32 +103,57 @@ static const struct tegra_video_format vi4_video_formats[] = {
 				RAW8, SBGGR8, "BGBG.. GRGR.."),
 
 	/* RAW 10 */
+	TEGRA_VIDEO_FORMAT(RAW10, 10, Y10_1X10, 2, 1, T_R16_I,
+				RAW10, TX2_Y10, "GREY 10"),
 	TEGRA_VIDEO_FORMAT(RAW10, 10, SRGGB10_1X10, 2, 1, T_R16_I,
-				RAW10, SRGGB10, "RGRG.. GBGB.."),
+				RAW10, TX2_SRGGB10, "RGRG.. GBGB.."),
 	TEGRA_VIDEO_FORMAT(RAW10, 10, SGRBG10_1X10, 2, 1, T_R16_I,
-				RAW10, SGRBG10, "GRGR.. BGBG.."),
+				RAW10, TX2_SGRBG10, "GRGR.. BGBG.."),
 	TEGRA_VIDEO_FORMAT(RAW10, 10, SGBRG10_1X10, 2, 1, T_R16_I,
-				RAW10, SGBRG10, "GBGB.. RGRG.."),
+				RAW10, TX2_SGBRG10, "GBGB.. RGRG.."),
 	TEGRA_VIDEO_FORMAT(RAW10, 10, SBGGR10_1X10, 2, 1, T_R16_I,
-				RAW10, SBGGR10, "BGBG.. GRGR.."),
+				RAW10, TX2_SBGGR10, "BGBG.. GRGR.."),
 
 	/* RAW 12 */
+	TEGRA_VIDEO_FORMAT(RAW12, 12, Y12_1X12, 2, 1, T_R16_I,
+				RAW12, TX2_Y12, "GREY 12"),
 	TEGRA_VIDEO_FORMAT(RAW12, 12, SRGGB12_1X12, 2, 1, T_R16_I,
-				RAW12, SRGGB12, "RGRG.. GBGB.."),
+				RAW12, TX2_SRGGB12, "RGRG.. GBGB.."),
 	TEGRA_VIDEO_FORMAT(RAW12, 12, SGRBG12_1X12, 2, 1, T_R16_I,
-				RAW12, SGRBG12, "GRGR.. BGBG.."),
+				RAW12, TX2_SGRBG12, "GRGR.. BGBG.."),
 	TEGRA_VIDEO_FORMAT(RAW12, 12, SGBRG12_1X12, 2, 1, T_R16_I,
-				RAW12, SGBRG12, "GBGB.. RGRG.."),
+				RAW12, TX2_SGBRG12, "GBGB.. RGRG.."),
 	TEGRA_VIDEO_FORMAT(RAW12, 12, SBGGR12_1X12, 2, 1, T_R16_I,
-				RAW12, SBGGR12, "BGBG.. GRGR.."),
+				RAW12, TX2_SBGGR12, "BGBG.. GRGR.."),
+
+	/* RGB444 */
+	TEGRA_VIDEO_FORMAT(RGB444, 16, RGB444_1X12, 2, 1, T_A4B4G4R4,
+				RGB444, ARGB444, "RGB-4-4-4"),
+
+	/* RGB565 */
+	TEGRA_VIDEO_FORMAT(RGB565, 16, RGB565_1X16, 2, 1, T_B5G6R5,
+				RGB565, RGB565, "RGB-5-6-5"),
 
 	/* RGB888 */
-	TEGRA_VIDEO_FORMAT(RGB888, 24, RGB888_1X24, 4, 1, T_A8R8G8B8,
-				RGB888, ABGR32, "BGRA-8-8-8-8"),
-	TEGRA_VIDEO_FORMAT(RGB888, 24, RGB888_1X32_PADHI, 4, 1, T_A8B8G8R8,
-				RGB888, RGB32, "RGB-8-8-8-8"),
+	TEGRA_VIDEO_FORMAT(RGB888, 24, RGB888_1X24, 4, 1, T_B8G8R8A8,
+				RGB888, XRGB32, "RGB-8-8-8"),
+	TEGRA_VIDEO_FORMAT(RGB888, 24, BGR888_1X24, 4, 1, T_A8R8G8B8,
+				RGB888, XBGR32, "BGR-8-8-8"),
+
+	/* RGB666 */
+	TEGRA_VIDEO_FORMAT(RGB666, 24, RGB666_1X18, 4, 1, T_A8B8G8R8,
+				RGB666, ABGR32, "BGRA-8-8-8-8"),
+
 
 	/* YUV422 */
+	TEGRA_VIDEO_FORMAT(YUV422, 16, UYVY8_2X8, 2, 1, T_U8_Y8__V8_Y8,
+				YUV422_8, UYVY, "YUV 4:2:2 UYVY"),
+	TEGRA_VIDEO_FORMAT(YUV422, 16, VYUY8_2X8, 2, 1, T_V8_Y8__U8_Y8,
+				YUV422_8, VYUY, "YUV 4:2:2 VYUY"),
+	TEGRA_VIDEO_FORMAT(YUV422, 16, YUYV8_2X8, 2, 1, T_Y8_U8__Y8_V8,
+				YUV422_8, YUYV, "YUV 4:2:2 YUYV"),
+	TEGRA_VIDEO_FORMAT(YUV422, 16, YVYU8_2X8, 2, 1, T_Y8_V8__Y8_U8,
+				YUV422_8, YVYU, "YUV 4:2:2 YVYU"),
 	TEGRA_VIDEO_FORMAT(YUV422, 16, UYVY8_1X16, 2, 1, T_U8_Y8__V8_Y8,
 				YUV422_8, UYVY, "YUV 4:2:2"),
 	TEGRA_VIDEO_FORMAT(YUV422, 16, VYUY8_1X16, 2, 1, T_V8_Y8__U8_Y8,
@@ -133,14 +164,6 @@ static const struct tegra_video_format vi4_video_formats[] = {
 				YUV422_8, YVYU, "YUV 4:2:2"),
 	TEGRA_VIDEO_FORMAT(YUV422, 16, UYVY8_1X16, 1, 1, T_Y8__V8U8_N422,
 				YUV422_8, NV16, "NV16"),
-	TEGRA_VIDEO_FORMAT(YUV422, 16, UYVY8_2X8, 2, 1, T_U8_Y8__V8_Y8,
-				YUV422_8, UYVY, "YUV 4:2:2 UYVY"),
-	TEGRA_VIDEO_FORMAT(YUV422, 16, VYUY8_2X8, 2, 1, T_V8_Y8__U8_Y8,
-				YUV422_8, VYUY, "YUV 4:2:2 VYUY"),
-	TEGRA_VIDEO_FORMAT(YUV422, 16, YUYV8_2X8, 2, 1, T_Y8_U8__Y8_V8,
-				YUV422_8, YUYV, "YUV 4:2:2 YUYV"),
-	TEGRA_VIDEO_FORMAT(YUV422, 16, YVYU8_2X8, 2, 1, T_Y8_V8__Y8_U8,
-				YUV422_8, YVYU, "YUV 4:2:2 YVYU"),
 };
 
 #endif
diff --git a/nvidia/drivers/media/platform/tegra/camera/vi/vi5_fops.c b/nvidia/drivers/media/platform/tegra/camera/vi/vi5_fops.c
index 129df2e6f901..e4beddca011f 100644
--- a/nvidia/drivers/media/platform/tegra/camera/vi/vi5_fops.c
+++ b/nvidia/drivers/media/platform/tegra/camera/vi/vi5_fops.c
@@ -40,7 +40,6 @@
 #define VI_CHANNEL_DEV "/dev/capture-vi-channel"
 #define VI_CHAN_PATH_MAX 40
 
-#define CAPTURE_TIMEOUT_MS	2500
 #define CAPTURE_CORRECTABLE_ERRORS	\
 	(CAPTURE_STATUS_SUCCESS \
 	| CAPTURE_STATUS_CSIMUX_FRAME \
@@ -306,6 +305,22 @@ static int vi5_channel_setup_queue(struct tegra_channel *chan,
 	return ret;
 }
 
+static void vi5_bypass_datatype(struct tegra_channel *chan,struct capture_descriptor *desc)
+{
+ u32 data_type = chan->fmtinfo->img_dt;
+
+ if(chan->bypass_dt) {
+   desc->ch_cfg.match.datatype = 0x0;
+   desc->ch_cfg.match.datatype_mask = 0x0;
+   desc->ch_cfg.dt_enable = 1;
+   desc->ch_cfg.dt_override = data_type;
+ } else {
+   desc->ch_cfg.match.datatype = data_type;
+   desc->ch_cfg.match.datatype_mask = 0x3f;
+   desc->ch_cfg.dt_enable = 0;
+ }
+}
+
 static int tegra_channel_capture_setup(struct tegra_channel *chan, unsigned int vi_port )
 {
 	struct vi_capture_setup setup = default_setup;
@@ -347,7 +362,6 @@ static void vi5_setup_surface(struct tegra_channel *chan,
 	u32 width = chan->format.width;
 	u32 format = chan->fmtinfo->img_fmt;
 	u32 bpl = chan->format.bytesperline;
-	u32 data_type = chan->fmtinfo->img_dt;
 	u32 nvcsi_stream = chan->port[vi_port];
 	struct capture_descriptor *desc = &chan->request[vi_port][descr_index];
 	struct capture_descriptor_memoryinfo *desc_memoryinfo =
@@ -367,11 +381,11 @@ static void vi5_setup_surface(struct tegra_channel *chan,
 	desc->ch_cfg.match.vc = (1u << chan->virtual_channel); /* one-hot bit encoding */
 	desc->ch_cfg.frame.frame_x = width;
 	desc->ch_cfg.frame.frame_y = height;
-	desc->ch_cfg.match.datatype = data_type;
-	desc->ch_cfg.match.datatype_mask = 0x3f;
 	desc->ch_cfg.pixfmt_enable = 1;
 	desc->ch_cfg.pixfmt.format = format;
 
+  vi5_bypass_datatype(chan, desc);
+
 	desc_memoryinfo->surface[0].base_address = offset;
 	desc_memoryinfo->surface[0].size = chan->format.bytesperline * height;
 	desc->ch_cfg.atomp.surface_stride[0] = bpl;
@@ -479,12 +493,12 @@ static void vi5_capture_dequeue(struct tegra_channel *chan,
 			goto rel_buf;
 
 		/* Dequeue a frame and check its capture status */
-		err = vi_capture_status(chan->tegra_vi_channel[vi_port], CAPTURE_TIMEOUT_MS);
+		err = vi_capture_status(chan->tegra_vi_channel[vi_port], jiffies_to_msecs(chan->timeout));
 		if (err) {
 			if (err == -ETIMEDOUT) {
 				dev_err(vi->dev,
 					"uncorr_err: request timed out after %d ms\n",
-					CAPTURE_TIMEOUT_MS);
+					jiffies_to_msecs(chan->timeout));
 			} else {
 				dev_err(vi->dev, "uncorr_err: request err %d\n", err);
 			}
@@ -548,6 +562,7 @@ static void vi5_capture_dequeue(struct tegra_channel *chan,
 	buf->vb2_state = VB2_BUF_STATE_ERROR;
 
 rel_buf:
+  tegra_channel_update_statistics(chan);
 	vi5_release_buffer(chan, buf);
 }
 
@@ -915,6 +930,11 @@ static int vi5_channel_stop_streaming(struct vb2_queue *vq)
 	struct tegra_channel *chan = vb2_get_drv_priv(vq);
 	long err;
 	int vi_port = 0;
+
+  for (vi_port = 0; vi_port < chan->valid_ports; vi_port++) {
+    vi_stop_waiting(chan->tegra_vi_channel[vi_port]);
+  }
+
 	if (!chan->bypass)
 		vi5_channel_stop_kthreads(chan);
 
diff --git a/nvidia/drivers/media/platform/tegra/camera/vi/vi5_formats.h b/nvidia/drivers/media/platform/tegra/camera/vi/vi5_formats.h
index 51cbbad5ba25..550fa6634fe3 100644
--- a/nvidia/drivers/media/platform/tegra/camera/vi/vi5_formats.h
+++ b/nvidia/drivers/media/platform/tegra/camera/vi/vi5_formats.h
@@ -82,11 +82,17 @@ enum tegra_image_format {
 };
 
 static const struct tegra_video_format vi5_video_formats[] = {
+
+  /* CUSTOM MIPI DATATYPE */
+  TEGRA_VIDEO_FORMAT(RAW8, 32, CUSTOM, 1, 1, T_U8_Y8__V8_Y8,
+        YUV422_8, CUSTOM, "0x31 MIPI DATATYPE"),
 	/* RAW 6: TODO */
 
 	/* RAW 7: TODO */
 
 	/* RAW 8 */
+  TEGRA_VIDEO_FORMAT(RAW8, 8, Y8_1X8, 1, 1, T_R8,
+       RAW8, GREY, "GREY 8"),
 	TEGRA_VIDEO_FORMAT(RAW8, 8, SRGGB8_1X8, 1, 1, T_R8,
 				RAW8, SRGGB8, "RGRG.. GBGB.."),
 	TEGRA_VIDEO_FORMAT(RAW8, 8, SGRBG8_1X8, 1, 1, T_R8,
@@ -97,32 +103,56 @@ static const struct tegra_video_format vi5_video_formats[] = {
 				RAW8, SBGGR8, "BGBG.. GRGR.."),
 
 	/* RAW 10 */
-	TEGRA_VIDEO_FORMAT(RAW10, 10, SRGGB10_1X10, 2, 1, T_R16,
-				RAW10, SRGGB10, "RGRG.. GBGB.."),
-	TEGRA_VIDEO_FORMAT(RAW10, 10, SGRBG10_1X10, 2, 1, T_R16,
-				RAW10, SGRBG10, "GRGR.. BGBG.."),
-	TEGRA_VIDEO_FORMAT(RAW10, 10, SGBRG10_1X10, 2, 1, T_R16,
-				RAW10, SGBRG10, "GBGB.. RGRG.."),
-	TEGRA_VIDEO_FORMAT(RAW10, 10, SBGGR10_1X10, 2, 1, T_R16,
-				RAW10, SBGGR10, "BGBG.. GRGR.."),
+	TEGRA_VIDEO_FORMAT(RAW10, 10, Y10_1X10, 2, 1, T_R16_I,
+       RAW10, XAVIER_Y10, "GREY 10"),
+  TEGRA_VIDEO_FORMAT(RAW10, 10, SRGGB10_1X10, 2, 1, T_R16_I,
+       RAW10, XAVIER_SRGGB10, "RGRG.. GBGB.."),
+  TEGRA_VIDEO_FORMAT(RAW10, 10, SGRBG10_1X10, 2, 1, T_R16_I,
+       RAW10, XAVIER_SGRBG10, "GRGR.. BGBG.."),
+  TEGRA_VIDEO_FORMAT(RAW10, 10, SGBRG10_1X10, 2, 1, T_R16_I,
+       RAW10, XAVIER_SGBRG10, "GBGB.. RGRG.."),
+  TEGRA_VIDEO_FORMAT(RAW10, 10, SBGGR10_1X10, 2, 1, T_R16_I,
+       RAW10, XAVIER_SBGGR10, "BGBG.. GRGR.."),
 
 	/* RAW 12 */
-	TEGRA_VIDEO_FORMAT(RAW12, 12, SRGGB12_1X12, 2, 1, T_R16,
-				RAW12, SRGGB12, "RGRG.. GBGB.."),
-	TEGRA_VIDEO_FORMAT(RAW12, 12, SGRBG12_1X12, 2, 1, T_R16,
-				RAW12, SGRBG12, "GRGR.. BGBG.."),
-	TEGRA_VIDEO_FORMAT(RAW12, 12, SGBRG12_1X12, 2, 1, T_R16,
-				RAW12, SGBRG12, "GBGB.. RGRG.."),
-	TEGRA_VIDEO_FORMAT(RAW12, 12, SBGGR12_1X12, 2, 1, T_R16,
-				RAW12, SBGGR12, "BGBG.. GRGR.."),
+	TEGRA_VIDEO_FORMAT(RAW12, 12, Y12_1X12, 2, 1, T_R16_I,
+       RAW12, XAVIER_Y12, "GREY 12"),
+  TEGRA_VIDEO_FORMAT(RAW12, 12, SRGGB12_1X12, 2, 1, T_R16_I,
+       RAW12, XAVIER_SRGGB12, "RGRG.. GBGB.."),
+  TEGRA_VIDEO_FORMAT(RAW12, 12, SGRBG12_1X12, 2, 1, T_R16_I,
+       RAW12, XAVIER_SGRBG12, "GRGR.. BGBG.."),
+  TEGRA_VIDEO_FORMAT(RAW12, 12, SGBRG12_1X12, 2, 1, T_R16_I,
+       RAW12, XAVIER_SGBRG12, "GBGB.. RGRG.."),
+  TEGRA_VIDEO_FORMAT(RAW12, 12, SBGGR12_1X12, 2, 1, T_R16_I,
+       RAW12, XAVIER_SBGGR12, "BGBG.. GRGR.."),
+
+  /* RGB444 */
+  TEGRA_VIDEO_FORMAT(RGB444, 16, RGB444_1X12, 2, 1, T_A4B4G4R4,
+       RGB444, ARGB444, "RGB-4-4-4"),
+
+  /* RGB565 */
+  TEGRA_VIDEO_FORMAT(RGB565, 16, RGB565_1X16, 2, 1, T_B5G6R5,
+       RGB565, RGB565, "RGB-5-6-5"),
 
 	/* RGB888 */
-	TEGRA_VIDEO_FORMAT(RGB888, 24, RGB888_1X24, 4, 1, T_A8R8G8B8,
-				RGB888, ABGR32, "BGRA-8-8-8-8"),
-	TEGRA_VIDEO_FORMAT(RGB888, 24, RGB888_1X32_PADHI, 4, 1, T_A8B8G8R8,
-				RGB888, RGB32, "RGB-8-8-8-8"),
+	TEGRA_VIDEO_FORMAT(RGB888, 24, RGB888_1X24, 4, 1, T_B8G8R8A8,
+       RGB888, XRGB32, "RGB-8-8-8"),
+  TEGRA_VIDEO_FORMAT(RGB888, 24, BGR888_1X24, 4, 1, T_A8R8G8B8,
+       RGB888, XBGR32, "BGR-8-8-8"),
+
+  /* RGB666 */
+  TEGRA_VIDEO_FORMAT(RGB666, 24, RGB666_1X18, 4, 1, T_A8B8G8R8,
+       RGB666, ABGR32, "BGRA-8-8-8-8"),
 
 	/* YUV422 */
+  TEGRA_VIDEO_FORMAT(YUV422, 16, UYVY8_2X8, 2, 1, T_U8_Y8__V8_Y8,
+       YUV422_8, UYVY, "YUV 4:2:2 UYVY"),
+  TEGRA_VIDEO_FORMAT(YUV422, 16, VYUY8_2X8, 2, 1, T_V8_Y8__U8_Y8,
+       YUV422_8, VYUY, "YUV 4:2:2 VYUY"),
+  TEGRA_VIDEO_FORMAT(YUV422, 16, YUYV8_2X8, 2, 1, T_Y8_U8__Y8_V8,
+       YUV422_8, YUYV, "YUV 4:2:2 YUYV"),
+  TEGRA_VIDEO_FORMAT(YUV422, 16, YVYU8_2X8, 2, 1, T_Y8_V8__Y8_U8,
+       YUV422_8, YVYU, "YUV 4:2:2 YVYU"),
 	TEGRA_VIDEO_FORMAT(YUV422, 16, UYVY8_1X16, 2, 1, T_U8_Y8__V8_Y8,
 				YUV422_8, UYVY, "YUV 4:2:2"),
 	TEGRA_VIDEO_FORMAT(YUV422, 16, VYUY8_1X16, 2, 1, T_V8_Y8__U8_Y8,
@@ -133,14 +163,6 @@ static const struct tegra_video_format vi5_video_formats[] = {
 				YUV422_8, YVYU, "YUV 4:2:2"),
 	TEGRA_VIDEO_FORMAT(YUV422, 16, UYVY8_1X16, 1, 1, T_Y8__V8U8_N422,
 				YUV422_8, NV16, "NV16"),
-	TEGRA_VIDEO_FORMAT(YUV422, 16, UYVY8_2X8, 2, 1, T_U8_Y8__V8_Y8,
-				YUV422_8, UYVY, "YUV 4:2:2 UYVY"),
-	TEGRA_VIDEO_FORMAT(YUV422, 16, VYUY8_2X8, 2, 1, T_V8_Y8__U8_Y8,
-				YUV422_8, VYUY, "YUV 4:2:2 VYUY"),
-	TEGRA_VIDEO_FORMAT(YUV422, 16, YUYV8_2X8, 2, 1, T_Y8_U8__Y8_V8,
-				YUV422_8, YUYV, "YUV 4:2:2 YUYV"),
-	TEGRA_VIDEO_FORMAT(YUV422, 16, YVYU8_2X8, 2, 1, T_Y8_V8__Y8_U8,
-				YUV422_8, YVYU, "YUV 4:2:2 YVYU"),
 };
 
 #endif
diff --git a/nvidia/drivers/video/tegra/host/nvhost_syncpt.c b/nvidia/drivers/video/tegra/host/nvhost_syncpt.c
index cb7f9769e9a4..0cf421be92a2 100644
--- a/nvidia/drivers/video/tegra/host/nvhost_syncpt.c
+++ b/nvidia/drivers/video/tegra/host/nvhost_syncpt.c
@@ -214,10 +214,19 @@ static bool syncpt_update_min_is_expired(
 	u32 id,
 	u32 thresh)
 {
+	if (atomic_read(&sp->stop_stream_called[id]))
+		return true;
+
+
 	syncpt_op().update_min(sp, id);
 	return nvhost_syncpt_is_expired(sp, id, thresh);
 }
 
+static bool syncpt_stop_waiting(struct nvhost_syncpt *sp,u32 id)
+{
+	return atomic_read(&sp->stop_stream_called[id]) ? true : false;
+}
+
 /**
  * Main entrypoint for syncpoint value waits.
  */
@@ -234,6 +243,9 @@ int nvhost_syncpt_wait_timeout(struct nvhost_syncpt *sp, u32 id,
 	bool (*syncpt_is_expired)(struct nvhost_syncpt *sp,
 			u32 id,
 			u32 thresh);
+	bool (*syncpt_stop)(struct nvhost_syncpt *sp,u32 id);
+
+	syncpt_stop = syncpt_stop_waiting;
 
 	sp = nvhost_get_syncpt_owner_struct(id, sp);
 	host = syncpt_to_dev(sp);
@@ -349,6 +361,10 @@ int nvhost_syncpt_wait_timeout(struct nvhost_syncpt *sp, u32 id,
 			remain = wait_event_interruptible_timeout(waiter->wq,
 				syncpt_is_expired(sp, id, thresh),
 				check);
+		else if (id == sp->stream_id)
+			remain = wait_event_timeout(waiter->wq,
+				(syncpt_is_expired(sp, id, thresh) || syncpt_stop(sp, id)),
+				check);
 		else
 			remain = wait_event_timeout(waiter->wq,
 				syncpt_is_expired(sp, id, thresh),
@@ -367,41 +383,48 @@ int nvhost_syncpt_wait_timeout(struct nvhost_syncpt *sp, u32 id,
 				}
 			}
 
-			err = 0;
-			break;
-		}
-		if (remain < 0) {
-			err = remain;
-			break;
+            if (syncpt_stop(sp,id) && remain > 0)
+                err = -ECANCELED;
+            else
+			    err = 0;
+
+            break;
 		}
-		if (timeout != NVHOST_NO_TIMEOUT)
+
+		if (timeout != NVHOST_NO_TIMEOUT) {
 			timeout -= check;
-		if (timeout && check_count <= MAX_STUCK_CHECK_COUNT) {
-			new_val = syncpt_op().update_min(sp, id);
-			if (old_val == new_val) {
-				dev_warn(&syncpt_to_dev(sp)->dev->dev,
-					"%s: syncpoint id %d (%s) stuck waiting %d, timeout=%d\n",
-					 current->comm, id,
-					 syncpt_op().name(sp, id),
-					 thresh, timeout);
-				nvhost_syncpt_debug(sp);
-			} else {
-				old_val = new_val;
-				dev_info(&syncpt_to_dev(sp)->dev->dev,
-					"%s: syncpoint id %d (%s) progressing slowly %d, timeout=%d\n",
-					 current->comm, id,
-					 syncpt_op().name(sp, id),
-					 thresh, timeout);
+
+			if (remain < 0) {
+				err = remain;
+				break;
 			}
-			if (check_count == MAX_STUCK_CHECK_COUNT) {
-				if (low_timeout) {
+			if (timeout && check_count <= MAX_STUCK_CHECK_COUNT) {
+				new_val = syncpt_op().update_min(sp, id);
+				if (old_val == new_val) {
 					dev_warn(&syncpt_to_dev(sp)->dev->dev,
-						"is timeout %d too low?\n",
-						low_timeout);
+						"%s: syncpoint id %d (%s) stuck waiting %d, timeout=%d\n",
+						 current->comm, id,
+						 syncpt_op().name(sp, id),
+						 thresh, timeout);
+					nvhost_syncpt_debug(sp);
+				} else {
+					old_val = new_val;
+					dev_info(&syncpt_to_dev(sp)->dev->dev,
+						"%s: syncpoint id %d (%s) progressing slowly %d, timeout=%d\n",
+						 current->comm, id,
+						 syncpt_op().name(sp, id),
+						 thresh, timeout);
+				}
+				if (check_count == MAX_STUCK_CHECK_COUNT) {
+					if (low_timeout) {
+						dev_warn(&syncpt_to_dev(sp)->dev->dev,
+							"is timeout %d too low?\n",
+							low_timeout);
+					}
+					nvhost_debug_dump(syncpt_to_dev(sp));
 				}
-				nvhost_debug_dump(syncpt_to_dev(sp));
+				check_count++;
 			}
-			check_count++;
 		}
 	}
 
@@ -1132,6 +1155,7 @@ int nvhost_syncpt_init(struct platform_device *dev,
 	sp->last_used_by = kzalloc(sizeof(char *) * nb_pts, GFP_KERNEL);
 	sp->min_val = kzalloc(sizeof(atomic_t) * nb_pts, GFP_KERNEL);
 	sp->max_val = kzalloc(sizeof(atomic_t) * nb_pts, GFP_KERNEL);
+	sp->stop_stream_called = kzalloc(sizeof(atomic_t) * nb_pts, GFP_KERNEL);
 	sp->lock_counts =
 		kzalloc(sizeof(atomic_t) * nvhost_syncpt_nb_mlocks(sp),
 			GFP_KERNEL);
@@ -1313,6 +1337,9 @@ void nvhost_syncpt_deinit(struct nvhost_syncpt *sp)
 	kfree(sp->assigned);
 	sp->assigned = NULL;
 
+	kfree(sp->stop_stream_called);
+	sp->stop_stream_called = NULL;
+
 	nvhost_syncpt_deinit_timeline(sp);
 }
 
@@ -1460,6 +1487,42 @@ int nvhost_syncpt_wait_timeout_ext(struct platform_device *dev, u32 id,
 }
 EXPORT_SYMBOL(nvhost_syncpt_wait_timeout_ext);
 
+int nvhost_syncpt_stop_waiting_ext(struct platform_device *dev, u32 id)
+{
+	struct nvhost_master *master = nvhost_get_host(dev);
+	struct nvhost_syncpt *sp =
+		nvhost_get_syncpt_owner_struct(id, &master->syncpt);
+
+	atomic_set(&sp->stop_stream_called[id],1);
+
+	return 0;
+}
+EXPORT_SYMBOL(nvhost_syncpt_stop_waiting_ext);
+
+int nvhost_syncpt_restart_waiting_ext(struct platform_device *dev, u32 id)
+{
+	struct nvhost_master *master = nvhost_get_host(dev);
+	struct nvhost_syncpt *sp =
+		nvhost_get_syncpt_owner_struct(id, &master->syncpt);
+
+	atomic_set(&sp->stop_stream_called[id],0);
+
+	return 0;
+}
+EXPORT_SYMBOL(nvhost_syncpt_restart_waiting_ext);
+
+int nvhost_syncpt_remember_stream_id_ext(struct platform_device *dev, u32 id)
+{
+	struct nvhost_master *master = nvhost_get_host(dev);
+	struct nvhost_syncpt *sp =
+		nvhost_get_syncpt_owner_struct(id, &master->syncpt);
+
+	sp->stream_id = id;
+
+	return 0;
+}
+EXPORT_SYMBOL(nvhost_syncpt_remember_stream_id_ext);
+
 int nvhost_syncpt_create_fence_single_ext(struct platform_device *dev,
 	u32 id, u32 thresh, const char *name, int *fence_fd)
 {
diff --git a/nvidia/drivers/video/tegra/host/nvhost_syncpt.h b/nvidia/drivers/video/tegra/host/nvhost_syncpt.h
index 1d23ced31525..868d42882e3e 100644
--- a/nvidia/drivers/video/tegra/host/nvhost_syncpt.h
+++ b/nvidia/drivers/video/tegra/host/nvhost_syncpt.h
@@ -69,13 +69,15 @@ struct nvhost_syncpt {
 	struct nvhost_syncpt_attr invalid_syncpt_type_attr;
 	struct nvhost_syncpt_attr invalid_assigned_attr;
 #endif
+	atomic_t *stop_stream_called;
+	u32 stream_id;
 };
 
 int nvhost_syncpt_init(struct platform_device *, struct nvhost_syncpt *);
 void nvhost_syncpt_deinit(struct nvhost_syncpt *);
 
 #define syncpt_to_dev(sp) container_of(sp, struct nvhost_master, syncpt)
-#define SYNCPT_CHECK_PERIOD (6 * HZ)
+#define SYNCPT_CHECK_PERIOD (20 * HZ)
 #define SYNCPT_POLL_PERIOD 1 /* msecs */
 #define MAX_STUCK_CHECK_COUNT 15
 
diff --git a/nvidia/include/linux/nvhost.h b/nvidia/include/linux/nvhost.h
index aefb46cebb4b..34de5fb3fd81 100644
--- a/nvidia/include/linux/nvhost.h
+++ b/nvidia/include/linux/nvhost.h
@@ -771,6 +771,9 @@ void nvhost_syncpt_cpu_incr_ext(struct platform_device *dev, u32 id);
 int nvhost_syncpt_read_ext_check(struct platform_device *dev, u32 id, u32 *val);
 int nvhost_syncpt_wait_timeout_ext(struct platform_device *dev, u32 id, u32 thresh,
 	u32 timeout, u32 *value, struct timespec *ts);
+int nvhost_syncpt_stop_waiting_ext(struct platform_device *dev, u32 id);
+int nvhost_syncpt_restart_waiting_ext(struct platform_device *dev, u32 id);
+int nvhost_syncpt_remember_stream_id_ext(struct platform_device *dev, u32 id);
 int nvhost_syncpt_create_fence_single_ext(struct platform_device *dev,
 	u32 id, u32 thresh, const char *name, int *fence_fd);
 int nvhost_syncpt_is_expired_ext(struct platform_device *dev,
diff --git a/nvidia/include/media/capture.h b/nvidia/include/media/capture.h
index fa929fc6d85d..caeb7fc07bb4 100644
--- a/nvidia/include/media/capture.h
+++ b/nvidia/include/media/capture.h
@@ -156,6 +156,7 @@ int vi_capture_request(struct tegra_vi_channel *chan,
 		struct vi_capture_req *req);
 int vi_capture_status(struct tegra_vi_channel *chan,
 		int32_t timeout_ms);
+int vi_stop_waiting(struct tegra_vi_channel *chan);
 int vi_capture_set_compand(struct tegra_vi_channel *chan,
 		struct vi_capture_compand *compand);
 long vi_capture_ioctl(struct file *file, void *fh,
diff --git a/nvidia/include/media/csi.h b/nvidia/include/media/csi.h
index 9a2dd7a61bed..59dcf21cb140 100644
--- a/nvidia/include/media/csi.h
+++ b/nvidia/include/media/csi.h
@@ -120,6 +120,9 @@ struct tegra_csi_channel {
 	atomic_t is_streaming;
 
 	struct device_node *of_node;
+	unsigned int packet_crc_error;
+
+	bool bypass_dt;
 };
 
 static inline struct tegra_csi_channel *to_csi_chan(struct v4l2_subdev *subdev)
diff --git a/nvidia/include/media/mc_common.h b/nvidia/include/media/mc_common.h
index 85888dbde138..9892d43dbb36 100644
--- a/nvidia/include/media/mc_common.h
+++ b/nvidia/include/media/mc_common.h
@@ -34,6 +34,7 @@
 #include <linux/workqueue.h>
 #include <linux/semaphore.h>
 #include <linux/rwsem.h>
+#include <uapi/linux/libcsi_ioctl.h>
 
 #define MAX_FORMAT_NUM	64
 #define	MAX_SUBDEVICES	4
@@ -48,6 +49,8 @@
 #define TEGRA_MEM_FORMAT 0
 #define TEGRA_ISP_FORMAT 1
 
+#define CAPTURE_TIMEOUT_MS  12000
+
 enum channel_capture_state {
 	CAPTURE_IDLE = 0,
 	CAPTURE_GOOD,
@@ -262,8 +265,23 @@ struct tegra_channel {
 	enum interlaced_type interlace_type;
 	int interlace_bplfactor;
 
-	atomic_t syncpt_depth;
-	struct rw_semaphore reset_lock;
+  atomic_t syncpt_depth;
+  struct rw_semaphore reset_lock;
+
+  struct v4l2_stats_t stream_stats;
+  uint64_t qbuf_count;
+  uint64_t dqbuf_count;
+  bool incomplete_flag;
+
+  bool trigger_mode;
+  bool pending_trigger;
+  uint64_t start_frame_jiffies;
+  unsigned int avt_cam_mode;
+  int created_bufs;
+    struct v4l2_pix_format prev_format;
+    atomic_t stop_streaming;
+
+  bool bypass_dt;
 };
 
 #define to_tegra_channel(vdev) \
@@ -381,8 +399,12 @@ void tegra_channel_queued_buf_done(struct tegra_channel *chan,
 int tegra_channel_set_stream(struct tegra_channel *chan, bool on);
 int tegra_channel_write_blobs(struct tegra_channel *chan);
 void tegra_channel_ring_buffer(struct tegra_channel *chan,
-			       struct vb2_v4l2_buffer *vb,
-			       struct timespec *ts, int state);
+             struct vb2_v4l2_buffer *vb,
+             struct timespec *ts, int state);
+void d(struct tegra_channel *chan);
+
+void tegra_channel_update_statistics(struct tegra_channel *chan);
+
 struct tegra_channel_buffer *dequeue_buffer(struct tegra_channel *chan,
 	bool requeue);
 struct tegra_channel_buffer *dequeue_dequeue_buffer(struct tegra_channel *chan);
@@ -429,6 +451,8 @@ struct tegra_csi_fops {
 		int port_idx);
 	void (*csi_override_format)(struct tegra_csi_channel *chan,
 		int port_idx);
+  void (*csi_check_status)(struct tegra_csi_channel *chan,
+    int port_idx);
 	int (*csi_error_recover)(struct tegra_csi_channel *chan, int port_idx);
 	int (*mipical)(struct tegra_csi_channel *chan);
 	int (*hw_init)(struct tegra_csi_device *csi);
diff --git a/nvidia/include/media/tegra_camera_core.h b/nvidia/include/media/tegra_camera_core.h
index 788cf77dc5b1..2a76b16b5c35 100644
--- a/nvidia/include/media/tegra_camera_core.h
+++ b/nvidia/include/media/tegra_camera_core.h
@@ -56,6 +56,11 @@ enum tegra_image_dt {
 	TEGRA_IMAGE_DT_RAW10,
 	TEGRA_IMAGE_DT_RAW12,
 	TEGRA_IMAGE_DT_RAW14,
+
+    TEGRA_IMAGE_DT_ARB_DT1 = 48,
+    TEGRA_IMAGE_DT_ARB_DT2,
+    TEGRA_IMAGE_DT_ARB_DT3,
+    TEGRA_IMAGE_DT_ARB_DT4,
 };
 
 /* Supported CSI to VI Data Formats */
diff --git a/nvidia/include/media/vi2_registers.h b/nvidia/include/media/vi2_registers.h
index a50df952cc9e..e6fc3b25a520 100644
--- a/nvidia/include/media/vi2_registers.h
+++ b/nvidia/include/media/vi2_registers.h
@@ -133,6 +133,8 @@
 #define TEGRA_CSI_PIXEL_PARSER_STATUS                   0x01c
 #define TEGRA_CSI_CSI_SW_SENSOR_RESET                   0x020
 
+#define TEGRA_CSI_PIXEL_PARSER_PL_CRC_ERR               (0x1 << 4)
+
 /* CSI PHY registers */
 /* CSI_PHY_CIL_COMMAND_0 offset 0x0d0 from TEGRA_CSI_PIXEL_PARSER_0_BASE */
 #define TEGRA_CSI_PHY_CIL_COMMAND                       0x0d0
diff --git a/nvidia/include/media/vi4_registers.h b/nvidia/include/media/vi4_registers.h
index 43869d56c488..26cffd5fa3cc 100644
--- a/nvidia/include/media/vi4_registers.h
+++ b/nvidia/include/media/vi4_registers.h
@@ -157,6 +157,7 @@
 
 #define DT_OVERRIDE					0x02c
 #define OVRD_DT						(0x3f << 1)
+#define OVRD_DT_SHIFT				1
 #define DT_OVRD_EN					(0x1 << 0)
 
 #define FRAME_X						0x030
-- 
2.34.1

